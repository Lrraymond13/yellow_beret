{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import aamc data, merge all times together and look at unique npi numbers\n",
    "# match to NIH applicants data set and check matches\n",
    "import funcy\n",
    "from collections import Counter\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from dev import AMA_DIR, APP_DATA_DIR, CORRECTIONS_DIR, NAME_COLS, AMA_MERGE_IMPORTANT_COLS\n",
    "ama_match_corrections_filename = 'manual_ama_matches.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AMA_cols = ['person_uuid', 'person_uuid_match', 'AMA_fname', 'AMA_mname', 'AMA_lname', 'abs_grad_diff', 'abs_birth_diff',\n",
    "            'AMA_grad_yr', 'medschool_year_grad', 'birth_year', 'AMA_med_school', 'medical_school',\n",
    "            'AMA_stschgrad', 'AMA_research_id', 'fname_sim', 'reverse_fname_sim', 'mname_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AMA_DATA_DIR = os.path.join(AMA_DIR, 'data')\n",
    "AMA_DATA_DICT_DIR =  os.path.join(AMA_DIR, 'data_dictionary')\n",
    "med_schools_fname = 'dbo_LU_AMA_Schools.txt'\n",
    "res_fname = 'dbo_res_train.txt'\n",
    "top_codes = 'PRIMARY TOP.xls' \n",
    "mpa_codes = 'Major Professional Activity.txt'\n",
    "pe_codes = 'PRESEMP.txt'\n",
    "names_ids = 'names_ids.txt'\n",
    "middle_names_ids = 'middle_names_ids.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nih_df = pd.read_csv(os.path.join(APP_DATA_DIR, 'NIH_AAMC_index_cards_grant_standardized.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, merge in manual ama corrections\n",
    "ama_manual_df = pd.read_csv(os.path.join(CORRECTIONS_DIR, ama_match_corrections_filename))\n",
    "# person uuid is the id to match the data set, \n",
    "# person_uuid_match is the id matching to the ama dataset\n",
    "# ama research id is the internal AMA id per person\n",
    "# ama_match has 1 for correct matches and 0 if none\n",
    "\n",
    "manual_matches = pd.merge(left=nih_df, right=ama_manual_df[\n",
    "        ['person_uuid', 'AMA_research_id', 'ama_match']],\n",
    "                   on=['person_uuid'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if not a match (ama_match=0), then replace ama research id with null\n",
    "manual_matches.loc[manual_matches.ama_match==0, 'AMA_research_id'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace nonsensical year grad values\n",
    "nih_df.medschool_year_grad.replace({15232: 1972, 11969: 1969}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_date(raw_str, delim, pos):\n",
    "    # note that pos is 0 indexed\n",
    "    vals = raw_str.split(delim)\n",
    "    if pos >= len(vals):\n",
    "        return np.nan\n",
    "    try:\n",
    "        ret_val = float(vals[pos])\n",
    "        if ret_val < 100:\n",
    "            return 1900+ret_val\n",
    "        return ret_val\n",
    "    except TypeError:\n",
    "        return np.nan\n",
    "\n",
    "#need to strip leading 0 from top code coding\n",
    "def strip_leading_zero(raw_str):\n",
    "    raw_str1 = str(raw_str)\n",
    "    if raw_str1.startswith('0'):\n",
    "        return int(raw_str[1:])\n",
    "    return int(raw_str)\n",
    "    \n",
    "def avoid_null_wrapper(x, fnc, **kwargs):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    return fnc(x, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# internship dates are actually strings for a couple people (data error) ie: Medicine or Str. Medicine\n",
    "# delete the string, take internship dates from intership_dates_NIH and then update internship start and end\n",
    "bad_res_strs = ['Starting July 1,1962', 'not known',  '\"Open\"', '1971-?', '1 Year', '1967-1968 (pending)']\n",
    "bad_res_mask = nih_df.residency_dates.isin(bad_res_strs)\n",
    "nih_df.loc[bad_res_mask, 'residency_dates'] = nih_df.loc[bad_res_mask, 'residency_dates_NIH']\n",
    "bad_res_mask_nih = nih_df.residency_dates_NIH.isin(bad_res_strs)\n",
    "nih_df.loc[bad_res_mask_nih, 'residency_dates_NIH'] = nih_df.loc[bad_res_mask_nih, 'residency_dates']\n",
    "# fix data entry error\n",
    "nih_df.loc[nih_df.residency_dates=='1972073', ['residency_start', 'residency_end']] = [1972, 1973]\n",
    "\n",
    "multiple_entries = lambda x: (len(str(x).split('&')) > 1) | (len(str(x).split(',')) > 1) | (len(str(x).split('-')) > 2)\n",
    "bad_nih_internship = nih_df.internship_dates_NIH.apply(multiple_entries)\n",
    "bad_nih_res = nih_df.residency_dates_NIH.apply(multiple_entries)\n",
    "bad_nih_res2 = nih_df.residency_dates_NIH.apply(lambda x: len(str(x).split('/')) > 1) \n",
    "bad_nih_res3 = nih_df.residency_dates.apply(lambda x: len(str(x).split('/')) > 1) \n",
    "bad_internship_mask = nih_df.internship_start.isin(['Medicine', 'Str. Medicine'])\n",
    "nih_df.loc[bad_internship_mask, 'internship_dates'] = nih_df.loc[bad_internship_mask, 'internship_dates_NIH']\n",
    "nih_df.loc[\n",
    "    (bad_internship_mask | bad_nih_internship), 'internship_start'] = nih_df.loc[\n",
    "        bad_internship_mask, 'internship_dates'].apply(\n",
    "                lambda x: avoid_null_wrapper(x, get_date, delim='-', pos=0))\n",
    "nih_df.loc[\n",
    "   bad_internship_mask, 'internship_end'] = nih_df.loc[\n",
    "        bad_internship_mask, 'internship_dates_NIH'].apply(\n",
    "            lambda x: avoid_null_wrapper(x, get_date, delim='-', pos=1))\n",
    "nih_df.loc[\n",
    "   bad_nih_internship, 'internship_end'] = nih_df.loc[\n",
    "        bad_internship_mask, 'internship_dates_NIH'].apply(\n",
    "            lambda x: avoid_null_wrapper(x, get_date, delim='-', pos=2))\n",
    "nih_df.loc[\n",
    "   (bad_nih_res | bad_res_mask | bad_res_mask_nih), 'residency_start'] = nih_df.loc[\n",
    "         (bad_nih_res | bad_res_mask | bad_res_mask_nih), 'residency_dates_NIH'].apply(\n",
    "                lambda x: avoid_null_wrapper(x, get_date, delim='-', pos=0))\n",
    "nih_df.loc[\n",
    "   (bad_nih_res | bad_res_mask | bad_res_mask_nih | bad_nih_res2), 'residency_end'] = nih_df.loc[\n",
    "        (bad_nih_res | bad_res_mask | bad_res_mask_nih | bad_nih_res2), 'residency_dates_NIH'].apply(\n",
    "            lambda x: avoid_null_wrapper(x, get_date, delim='-', pos=2))\n",
    "\n",
    "nih_df.loc[\n",
    "   bad_nih_res3, 'residency_start'] = nih_df.loc[\n",
    "        bad_nih_res3, 'residency_dates_NIH'].apply(\n",
    "            lambda x: avoid_null_wrapper(x, get_date, delim='-', pos=0))\n",
    "nih_df.loc[\n",
    "   bad_nih_res3, 'residency_end'] = nih_df.loc[\n",
    "        bad_nih_res3, 'residency_dates_NIH'].apply(\n",
    "            lambda x: avoid_null_wrapper(x, get_date, delim='-', pos=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert internship start, residency start and ends to floats\n",
    "# nih_df[[ 'residency_end' ]].astype(float)\n",
    "year_cols = ['internship_start', 'internship_end', 'residency_start', 'residency_end', 'birth_year']\n",
    "nih_df[year_cols] = nih_df[year_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lname_counter = Counter(nih_df.clean_last_name)\n",
    "nih_df['lname_freq'] = nih_df.clean_last_name.apply(lambda x: lname_counter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# should have 5 text files for 1978, 1985, 1995, 2005, 2015\n",
    "ama_data_files = [\n",
    "    file_name for file_name in os.listdir(AMA_DATA_DIR) if file_name.startswith(\n",
    "                'QUO-161256-FS8YTU-')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# defined na values in codes\n",
    "na_values = {'MPA': ['NCL'], 'TOP': [100, 'X', '100'], 'PE': [110, 100, 12], 'STSCHGRAD': [0, 0.0], 'MEDTRINST': [0, 0.0]}\n",
    "\n",
    "file_list = []\n",
    "for f_name in ama_data_files:\n",
    "    new_f = pd.read_csv(os.path.join(AMA_DATA_DIR, f_name), na_values=na_values)\n",
    "    new_f['observation_year'] = int(f_name.split('.txt')[0][-4:])\n",
    "    file_list.append(new_f.copy())\n",
    "    \n",
    "ama_dfs_raw = pd.concat(file_list, axis=0)\n",
    "\n",
    "# import names and ids and merge into main AMA files \n",
    "# note fname and lname columns are in propercase format\n",
    "names_ids_df = pd.read_csv(os.path.join(AMA_DATA_DIR, names_ids))\n",
    "middle_df = pd.read_csv(os.path.join(AMA_DATA_DIR, middle_names_ids))\n",
    "fname_ids_df = pd.merge(left=names_ids_df, right=middle_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_names = fname_ids_df.drop_duplicates('RESEARCH ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.average(pd.isnull(unique_names.MNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# research ids should be an int64\n",
    "ama_dfs = pd.merge(left=ama_dfs_raw, right=fname_ids_df, on=['RESEARCH ID'], how='left')\n",
    "\n",
    "# check for any missing first and last names\n",
    "ama_dfs.loc[(pd.isnull(ama_dfs.FNAME)) | (pd.isnull(ama_dfs.LNAME)), ['FNAME', 'MNAME', 'LNAME', 'RESEARCH ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variable definitions\n",
    "# \n",
    "# LIC_year = license year\n",
    "# locum tenes = short term/flexible staffing position\n",
    "# MPA = major professional activity\n",
    "            # OFF=Office-based\n",
    "            # HPI=interns(discontinued in 1992)\n",
    "            # HPR=hospital based-all other years resident\n",
    "            # HPP=hospital based physician\n",
    "            # MTC=medical teacher\n",
    "            # ADM=administration physician\n",
    "            # RES=research physician\n",
    "            # OTH=other physician\n",
    "            # INA=inactive physician\n",
    "            # NCL=Not classified\n",
    "            # UNA=address unknown physician\n",
    "            # TFG=temporary foreign physician\n",
    "            # CUT=cut physician\n",
    "            # LOC=locum tenes (began in 1996)\n",
    "# dead = deceased indicator\n",
    "# TOP = type of practice \n",
    "#             Code\tDescription\n",
    "#             012\tResident\n",
    "#             020\tDirect Patient Care\n",
    "#             030\tAdministration\n",
    "#             040\tMedical Teaching\n",
    "#             050\tMedical Research\n",
    "#             062\tNon-Patient Care\n",
    "#             071\tRetired\n",
    "#             072\tSemi-Retired\n",
    "#             074\tTemporarily not in Practice\n",
    "#             075\tNot active for other reasons\n",
    "#             100\tNo classification\n",
    "# PE = present employment\n",
    "#             \"010\",\"SELF EMPLOYED\"\n",
    "#             \"011\",\"SELF EMPLOYED SOLO PRACTICE\"\n",
    "#             \"013\",\"TWO PHYSICIAN PRACTICE - OWNER\"\n",
    "#             \"014\",\"TWO PHYSICIAN PRACTICE - EMPL.\"\n",
    "#             \"021\",\"OTHER PATIENT CARE\"\n",
    "#             \"022\",\"Locum Tenens\"\n",
    "#             \"030\",\"GROUP PRACTICE\"\n",
    "#             \"035\",\"HMO\"\n",
    "#             \"040\",\"MEDICAL SCHOOL\"\n",
    "#             \"050\",\"NON-GOVERNMENT HOSPITAL\"\n",
    "#             \"060\",\"-CITY/COUNTY/STATE GOVERNMENT-\"\n",
    "#             \"063\",\"CITY/COUNTY/STATE GOVT HOSP\"\n",
    "#             \"064\",\"CITY/COUNTY/STATE GOVT OTHER\"\n",
    "#             \"080\",\"-FEDERAL GOVERNMENT HOSPITAL-\"\n",
    "#             \"081\",\"FEDERAL GOVT HOSP ARMY\"\n",
    "#             \"082\",\"FEDERAL GOVT HOSP NAVY\"\n",
    "#             \"083\",\"FEDERAL GOVT HOSP AIR FORCE\"\n",
    "#             \"084\",\"FEDERAL GOVT HOSP U.S.P.H.S.\"\n",
    "#             \"085\",\"FEDERAL GOVT HOSP VET ADMIN\"\n",
    "#             \"086\",\"FEDERAL GOVT HOSP OTHER\"\n",
    "#             \"090\",\"-FEDERAL GOVERNMENT NON-HOSP-\"\n",
    "#             \"091\",\"FEDERAL GOVT N-H ARMY\"\n",
    "#             \"092\",\"FEDERAL GOVT N-H NAVY\"\n",
    "#             \"093\",\"FEDERAL GOVT N-H AIR FORCE\"\n",
    "#             \"094\",\"FEDERAL GOVT N-H U.S.P.H.S.\"\n",
    "#             \"095\",\"FEDERAL GOVT N-H VET ADMIN\"\n",
    "#             \"096\",\"FEDERAL GOVT N-H OTHER\"\n",
    "#             \"101\",\"OTHER NON-PATIENT CARE\"\n",
    "#             \"110\",\"NO CLASSIFICATION\"\n",
    "\n",
    "# MED_TRFROM = date of medical training start/end. The date the physician entered \n",
    "        # the current graduate medical training program and the anticipated completion date.\n",
    "        # 000000000000 is the same as 00  0000  00. All 0’s = not reported.\n",
    "        # For years 1978, 1985, 1995, the date is formatted MMYYYYMMYYYY, no spaces. \n",
    "        # For 2005, the date is formatted M YYYYM YYYY for single digit months and MMYYYYMMYYYY for\n",
    "        # double digit months. 2015 is just a year. It’s not clear whether it is the start year or \n",
    "        # the completion year.\n",
    "\n",
    "# MEDTRINST = Medical Training Institution Code - dbo_res_train.txt file contains codes \n",
    "# STSCHGRAD = school of graduation; corresponds to Dbo_LU_AMA_Schools.txt\n",
    "# ECFMG = Education Commision for Foreign Medical Graduates. A unique identifying number \n",
    "#     assigned by the Education Commission for Foreign Medical Graduates to foreign medical \n",
    "#     graduates applying for ECFMG certification. 000000 = no ECFMG # reported.\n",
    "# GRAD_YR = med school graduation year (range from 1955-1975)\n",
    "# FED_CODE = federal code, 1 = federal physician, 0 = non federal physician\n",
    "# B_DATE = birth_date\n",
    "# spec1 = specialty 1\n",
    "# spec2 = specialty 2\n",
    "# B_PLACE = birth place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import and merge TOP codes, mpa, pe codes\n",
    "# top codes should be integers with no leading 0s, MPA should be a string\n",
    "# pe codes must be floats since column contains missing values\n",
    "\n",
    "top_df = pd.read_excel(os.path.join(AMA_DATA_DICT_DIR, top_codes))\n",
    "top_df.columns = ['TOP', 'TOP_description']\n",
    "top_df['TOP'] = top_df['TOP'].astype(int)\n",
    "mpa_df = pd.read_csv(os.path.join(AMA_DATA_DICT_DIR, mpa_codes))\n",
    "mpa_df.columns = ['MPA', 'MPA_description']\n",
    "pe_df = pd.read_csv(os.path.join(AMA_DATA_DICT_DIR, pe_codes))\n",
    "pe_df.columns = ['PE', 'PE_description']\n",
    "pe_df['PE'] = pe_df['PE'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zero_fnc = funcy.rpartial(avoid_null_wrapper, strip_leading_zero)\n",
    "float_fnc = funcy.rpartial(avoid_null_wrapper, int)\n",
    "clean_str_fnc = funcy.rpartial(avoid_null_wrapper, funcy.rcompose(string.upper, string.strip))\n",
    "\n",
    "ama_dfs['TOP'] = ama_dfs['TOP'].apply(zero_fnc)\n",
    "ama_dfs['PE'] = ama_dfs['PE'].apply(float_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama1 = pd.merge(left=ama_dfs, right=top_df, on=['TOP'], how='left')\n",
    "ama2 = pd.merge(left=ama1, right=mpa_df, on=['MPA'], how='left')\n",
    "ama3 = pd.merge(left=ama2, right=pe_df, on=['PE'], how='left')\n",
    "\n",
    "# print ama3['TOP_description'].unique()\n",
    "# print ama3['MPA_description'].unique()\n",
    "# print ama3['PE_description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for places in the data set that have a top, mpa or pe code and don't merge correctly\n",
    "missing_top = (~pd.isnull(ama3['TOP'])) & (pd.isnull(ama3['TOP_description']))\n",
    "missing_mpa = (~pd.isnull(ama3['MPA'])) & (pd.isnull(ama3['MPA_description']))\n",
    "missing_pe = (~pd.isnull(ama3['PE'])) & (pd.isnull(ama3['PE_description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_mpa_arr = ama3.loc[(missing_mpa)].MPA.unique()\n",
    "missing_top_arr = ama3.loc[(missing_top)].TOP.unique()\n",
    "missing_pe_arr = ama3.loc[(missing_pe)].PE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set 0 values to np.nan\n",
    "ama3.loc[ama3.MEDTRINST==0, 'MEDTRINST'] = np.nan\n",
    "ama3.loc[ama3.STSCHGRAD==0, 'STSCHGRAD'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import med school and med training institution strings\n",
    "med_school_df = pd.read_csv(os.path.join(AMA_DATA_DICT_DIR, med_schools_fname))\n",
    "med_school_df.columns = ['STSCHGRAD', 'MED_SCHOOL', 'MED_SCHOOL_STATE']\n",
    "train_school_df = pd.read_csv(os.path.join(AMA_DATA_DICT_DIR, res_fname))\n",
    "train_school_df.columns = [\n",
    "    'MEDTRINST', 'MEDTRINST_NAME',\n",
    "    'MEDTRINST_ADD1', 'MEDTRINST_ADD2', \n",
    "    'MEDTRINST_CITY', 'MEDTRINST_ST', \n",
    "    'MEDTRINST_ZIP']\n",
    "train_school_df.MEDTRINST = train_school_df.MEDTRINST.astype(float)\n",
    "med_school_df.STSCHGRAD = med_school_df.STSCHGRAD.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama3.STSCHGRAD = ama3.STSCHGRAD.astype(float)\n",
    "ama3.MEDTRINST = ama3.MEDTRINST.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge in medical school and train inst and check for data values not in the dictionary\n",
    "ama4 = pd.merge(left=ama3, right=med_school_df, how='left')\n",
    "ama5 = pd.merge(left=ama4, right=train_school_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find codes not in corresponding data dictionaries\n",
    "missing_med_schools = (~pd.isnull(ama5.STSCHGRAD) & pd.isnull(ama5.MED_SCHOOL))\n",
    "missing_tr_schools = (~pd.isnull(ama5.MEDTRINST) & pd.isnull(ama5.MEDTRINST_NAME))\n",
    "print missing_med_schools.sum()\n",
    "print missing_tr_schools.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing school and training codes\n",
    "missing_med_schools_arr = ama5[missing_med_schools]['STSCHGRAD'].sort_values().unique()\n",
    "missing_tr_schools_arr = ama5[missing_tr_schools]['MEDTRINST'].sort_values().unique()\n",
    "\n",
    "# output missing values to csv \n",
    "missing_dict = {\n",
    "        'missing_MPA_codes': missing_mpa_arr, 'missing_TOP_codes': missing_top_arr,\n",
    "        'missing_PE_codes': missing_pe_arr, 'missing_STSCHGRAD_codes': missing_med_schools_arr,\n",
    "        'missing_MEDTRINST': missing_tr_schools_arr\n",
    "}\n",
    "\n",
    "missing_data_dict = pd.DataFrame.from_dict(missing_dict, orient='index').T\n",
    "# output missing AMA data dictionary to files\n",
    "missing_data_dict.to_csv(os.path.join(AMA_DIR, 'missing_MMS_data_dictionary_codes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean and upcase first and last names\n",
    "ama5[['FNAME', 'MNAME', 'LNAME']] = ama5[['FNAME', 'MNAME', 'LNAME']].applymap(clean_str_fnc)\n",
    "\n",
    "#rename ama_dfs columns\n",
    "ama5['birth_year'] = ama5['B_DATE'].apply(lambda x: int(str(x)[-4:]))\n",
    "ama_merge_df = ama5.drop(['first_initial', 'clean_last_name', 'hash_id', 'match_id', 'dno'], axis=1)\n",
    "ama_merge_df.columns = ['person_uuid']+['AMA_{}'.format(x.lower()) for x in ama_merge_df.columns if x != 'person_uuid']\n",
    "ama_merge_df.rename(columns={'AMA_research id': 'AMA_research_id', 'person_uuid': 'old_uuid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a version of the ama data set with 1 observation per unique id, with a column for first and last obs year\n",
    "ama_merge_df2 = ama_merge_df.sort_values(\n",
    "    ['AMA_research_id', 'AMA_observation_year']).groupby('AMA_research_id')['AMA_observation_year'].agg(\n",
    "        {'AMA_obs_year_min': min, 'AMA_obs_year_max': max})\n",
    "ama_merge_df3 = ama_merge_df.join(ama_merge_df2, on='AMA_research_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama_merge_df3.loc[(pd.isnull(ama_merge_df3['AMA_obs_year_min'])) | (pd.isnull(ama_merge_df3['AMA_obs_year_max']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_id = '2001591012'\n",
    "ama_merge_df3.loc[ama_merge_df3.AMA_research_id==int(r_id),AMA_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nih_df['person_uuid_match'] = nih_df['person_uuid']\n",
    "nih_df.loc[(nih_df.clean_last_name=='CAHAN') & (nih_df.clean_first_name=='LESLIE'), 'person_uuid_match'] = 2270\n",
    "\n",
    "ama_merge_df3['person_uuid_match'] = ama_merge_df3['old_uuid']\n",
    "convert_mask = (ama_merge_df3['person_uuid_match'] >= 200) & (ama_merge_df3['person_uuid_match'] < 300)\n",
    "convert_mask2 = (ama_merge_df3['person_uuid_match'] > 2270) & (ama_merge_df3['person_uuid_match'] < 4145)\n",
    "ama_merge_df3.loc[convert_mask, 'person_uuid_match'] = ama_merge_df3[convert_mask]['person_uuid_match'] + 1\n",
    "ama_merge_df3.loc[convert_mask2, 'person_uuid_match'] = ama_merge_df3[convert_mask2]['person_uuid_match'] + 1\n",
    "\n",
    "\n",
    "ama_merge_df3.loc[\n",
    "    (ama_merge_df3.AMA_lname=='CAHAN'), 'person_uuid_match'] = 2270\n",
    "# 4151 -> 4149\n",
    "ama_merge_df3.loc[\n",
    "    (ama_merge_df3.AMA_lname=='GARFIN') & (ama_merge_df3.AMA_fname=='STEVEN'), 'person_uuid_match'] = 4149\n",
    "#4152 -> 4151\n",
    "ama_merge_df3.loc[\n",
    "    (ama_merge_df3.AMA_lname=='BULL') & (ama_merge_df3.AMA_fname=='BRIAN'), 'person_uuid_match'] = 4151\n",
    "# 4148 -> 4147\n",
    "ama_merge_df3.loc[\n",
    "    (ama_merge_df3.AMA_lname=='HERSH') & (ama_merge_df3.AMA_fname=='EVAN'), 'person_uuid_match'] = 4147\n",
    "#make sure list is 4150\n",
    "ama_merge_df3.loc[\n",
    "    (ama_merge_df3.AMA_lname=='LIST') & (ama_merge_df3.AMA_fname=='NOEL'), 'person_uuid_match'] = 4150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optionally output data set\n",
    "# ama_merge_df3.to_csv(os.path.join(AMA_DIR, 'full_ama.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove manual matches from nih_data set and merge with ama seperately\n",
    "nih_df_m = nih_df.loc[~(nih_df.person_uuid.isin(manual_matches.person_uuid)), :]\n",
    "manual_matches_ama = pd.merge(\n",
    "    left=manual_matches, right=ama_merge_df3, on='AMA_research_id', how='inner')\n",
    "manual_matches_ama_un = manual_matches_ama.drop_duplicates('person_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df = pd.merge(left=nih_df_m, right=ama_merge_df3, on=['person_uuid_match'], how='left')\n",
    "\n",
    "full_df['internship_diff'] = full_df['internship_start']-full_df['AMA_grad_yr']\n",
    "full_df['abs_internship_diff'] = full_df['internship_diff'].abs()\n",
    "full_df['grad_diff'] = full_df['medschool_year_grad']-full_df['AMA_grad_yr']\n",
    "full_df['abs_grad_diff'] = full_df['grad_diff'].abs()\n",
    "full_df['birth_diff'] = full_df['birth_year']-full_df['AMA_birth_year']\n",
    "full_df['abs_birth_diff'] = full_df['birth_diff'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get unique combos of NIH people, research id matches\n",
    "unique_match_combos = full_df.sort_values(\n",
    "    ['person_uuid_match', 'abs_grad_diff', 'abs_birth_diff']).drop_duplicates(\n",
    "    ['person_uuid_match', 'AMA_research_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_matches = unique_match_combos.loc[\n",
    "    pd.isnull(unique_match_combos['AMA_research_id']), [c for c in unique_match_combos.columns if not c.startswith('AMA_')]]\n",
    "print no_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_match_combos2 = unique_match_combos.loc[~pd.isnull(unique_match_combos['AMA_research_id'])]\n",
    "print unique_match_combos2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate first name similarity\n",
    "def name_sim(nih_fname, ama_fname):\n",
    "    # if either name is null, return null\n",
    "    if pd.isnull(nih_fname) or pd.isnull(ama_fname):\n",
    "        return np.nan\n",
    "    if len(nih_fname) == 1 or len(ama_fname) == 1:\n",
    "        return 100*(nih_fname[0]==ama_fname[0])\n",
    "    return fuzz.ratio(nih_fname, ama_fname)\n",
    "    \n",
    "def medschool_sim(nih_name, ama_name):\n",
    "    # if either name is null, return null\n",
    "    if pd.isnull(nih_name) or pd.isnull(ama_name):\n",
    "        return np.nan\n",
    "    return fuzz.ratio(nih_name, ama_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of matches where grad diff or birth year diff >= 3\n",
    "unique_match_combos3 = unique_match_combos2.loc[\n",
    "    (unique_match_combos2.abs_grad_diff <= 2) | (unique_match_combos2.abs_birth_diff <= 2)]\n",
    "unique_match_combos3['fname_sim'] = unique_match_combos3[\n",
    "    ['clean_first_name', 'AMA_fname']].apply(lambda x: name_sim(*x), axis=1)\n",
    "unique_match_combos3['mname_sim'] = unique_match_combos3[\n",
    "    ['clean_middle_name', 'AMA_mname']].apply(lambda x: name_sim(*x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate reverse sim score for sorting\n",
    "unique_match_combos3['reverse_fname_sim'] = 100 - unique_match_combos3['fname_sim']\n",
    "unique_match_combos3['reverse_mname_sim'] = 100 - unique_match_combos3['mname_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort by grad year, birth year differences then name sim\n",
    "unique_match_combos4 = unique_match_combos3.sort_values(\n",
    "    ['person_uuid_match', 'abs_grad_diff', 'abs_birth_diff', \n",
    "         'abs_internship_diff', 'reverse_fname_sim', 'reverse_mname_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for every match, take first option (least bad)\n",
    "matches = unique_match_combos4.drop_duplicates('person_uuid_match', keep='first')\n",
    "print matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep matches where name freq is unusual (< 1 in the data set) or name sim >= 80 and birth year or grad year match\n",
    "def is_match(row):\n",
    "    if row['fname_sim'] <= 70:\n",
    "        return 0\n",
    "    if row['lname_freq'] == 1:\n",
    "        return 1\n",
    "    # if name sim > 80 and birth year or grad diff similar, match\n",
    "    if row['abs_birth_diff'] == 0 or row['abs_grad_diff'] == 0:\n",
    "        return 1\n",
    "    if row['fname_sim'] >= 95:\n",
    "        return 1\n",
    "    # if internship start date is equal to ama_grad date, do a match\n",
    "    if row['internship_diff'] < 2:\n",
    "        return 1\n",
    "    # check middle name sim\n",
    "    if row['mname_sim'] >= 60:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches['is_match'] = matches.apply(is_match, axis=1)\n",
    "matches.loc[matches.is_match==0, 'AMA_research_id'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches.is_match.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched_ids = matches.loc[matches.is_match==1, 'person_uuid_match']\n",
    "matched_ama_ids = matches.loc[matches.is_match==1, 'AMA_research_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_matches = nih_df_m.loc[~(nih_df_m.person_uuid_match.isin(matched_ids))]\n",
    "\n",
    "non_matches.to_csv(os.path.join(AMA_DIR, 'unmatched_nih.csv'), index=False)\n",
    "\n",
    "print non_matches.loc[non_matches.time_period_flag==1].shape\n",
    "print non_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data corrections\n",
    "reviewed_unmatched = pd.read_excel(os.path.join(CORRECTIONS_DIR, 'data_corrections_final.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_unmatched = non_matches.loc[(non_matches.time_period_flag==1) & ~(non_matches.person_uuid.isin(reviewed_unmatched.person_uuid))]\n",
    "\n",
    "new_unmatched = non_matches.loc[(non_matches.time_period_flag==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_unmatched.to_excel(os.path.join(CORRECTIONS_DIR, 'unmatched_manual_review.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmatched_ama = ama_merge_df3.loc[\n",
    "    ~((ama_merge_df3.AMA_research_id.isin(matched_ama_ids)) | (ama_merge_df3.person_uuid_match.isin(matched_ids))), :]\n",
    "unmatched_ama.shape\n",
    "\n",
    "# get data set of unique people\n",
    "unique_unmatched = unmatched_ama[\n",
    "    [c for c in unmatched_ama if c.startswith('AMA_')]]\n",
    "\n",
    "unique_unmatched2 = unique_unmatched.drop_duplicates('AMA_research_id')\n",
    "\n",
    "unique_unmatched2.to_csv(os.path.join(AMA_DIR, 'unmatched_ama.csv'), index=False)\n",
    "print unique_unmatched2.shape\n",
    "\n",
    "matches.loc[\n",
    "#     ((matches.is_match==1) & (matches.time_period_flag==1)),:].to_csv(os.path.join(AMA_DIR, 'matched_nih.csv'))\n",
    "    (matches.is_match==1),:].to_csv(os.path.join(AMA_DIR, 'matched_nih.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matches.loc[(\n",
    "#         (matches.abs_internship_diff == 0) & (\n",
    "#             matches.abs_birth_diff != 0) & (\n",
    "#                 matches.abs_grad_diff != 0)), NAME_COLS + AMA_cols + ['is_match']]\n",
    "test_m = matches.loc[(\n",
    "        (matches.is_match==0)), NAME_COLS + AMA_cols + ['is_match']].sort_values(['person_uuid', 'reverse_fname_sim'])\n",
    "\n",
    "test_m_options = unique_match_combos2.loc[(\n",
    "        unique_match_combos2.person_uuid.isin(\n",
    "            no_matches.person_uuid)), NAME_COLS + AMA_cols + ['internship_start', 'eod_year', 'year_accepted']].sort_values(\n",
    "                ['person_uuid', 'reverse_fname_sim'])\n",
    "# merge not matched people to ama data set to unmatched ama\n",
    "other_matches_options = pd.merge(left=non_matches.loc[\n",
    "        (non_matches.time_period_flag==1) & ~(non_matches.person_uuid.isin(test_m_options.person_uuid)), \n",
    "            NAME_COLS + ['internship_start', 'eod_year', 'year_accepted']], right=unique_unmatched2, \n",
    "                left_on='clean_last_name', right_on='AMA_lname', how='left')\n",
    "all_options = pd.concat([test_m_options, other_matches_options], axis=0)\n",
    "print test_m.shape\n",
    "print test_m_options.shape\n",
    "test_m.to_csv(os.path.join(CORRECTIONS_DIR, 'ama_test_matches.csv'), index=False)\n",
    "all_options[NAME_COLS + AMA_cols + ['internship_start', 'eod_year', 'year_accepted']].to_csv(os.path.join(CORRECTIONS_DIR, 'ama_unmatched_possible_matches.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# non AMA columns\n",
    "non_ama_cols = [c for c in matches.columns if not c.startswith('AMA_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine manual matches with unique matches and combine with ama data set to get a panel \n",
    "# get nih people not able to be matched to AMA data set\n",
    "print matches.loc[matches.person_uuid.isin(manual_matches_ama.person_uuid)].shape\n",
    "full_matches = pd.concat([matches, manual_matches_ama_un], axis=0) \n",
    "no_matches = nih_df.loc[~nih_df.person_uuid.isin(full_matches.person_uuid), ]\n",
    "no_matches['AMA_research_id'] = np.nan\n",
    "full_matches = full_matches[non_ama_cols+['AMA_research_id']]\n",
    "all_nih = pd.concat([full_matches, no_matches], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these should be equal in len\n",
    "print all_nih.shape\n",
    "print nih_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now, merge all_nih into AMA data to get a panel data set\n",
    "ama_cols = [c for c in ama_merge_df3.columns if c.startswith('AMA_')]\n",
    "panel_nih = pd.merge(\n",
    "    left=all_nih, right=ama_merge_df3[ama_cols], on='AMA_research_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nih_ama_unique = panel_nih.sort_values(\n",
    "    ['person_uuid', 'AMA_observation_year']).drop_duplicates('person_uuid', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nih_ama_unique['medschool_name_sim'] = nih_ama_unique[\n",
    "    ['AMA_med_school', 'medical_school']].apply(lambda x: medschool_sim(x[0], x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nih_ama_unique.loc[\n",
    "    (~pd.isnull(nih_ama_unique.AMA_research_id) & ~(pd.isnull(nih_ama_unique.medschool_name_sim))), ['medical_school', 'AMA_med_school', 'medschool_name_sim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_cols = ['residency_1', 'birth_year.1', 'old_uuid', \n",
    "     'reverse_fname_sim', 'reverse_mname_sim', 'is_match', 'suffix_cd', 'correct_match_flag', \n",
    "     'person_uuid_match', 'grad_diff', 'abs_grad_diff', 'birth_diff', 'abs_birth_diff']\n",
    "nih_ama_unique2 = nih_ama_unique.drop(old_cols, axis=1)\n",
    "panel_nih2 = panel_nih.drop(old_cols, axis=1).sort_values(['person_uuid', 'AMA_observation_year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_order = sorted([c for c in panel_nih2.columns if c not in AMA_MERGE_IMPORTANT_COLS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nih_ama_unique2[AMA_MERGE_IMPORTANT_COLS+col_order].to_csv(os.path.join(APP_DATA_DIR, 'ama_nih_merge.csv'), index=False)\n",
    "panel_nih2[AMA_MERGE_IMPORTANT_COLS+col_order].to_csv(os.path.join(APP_DATA_DIR, 'ama_nih_merge_panel.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# percentage missing\n",
    "print np.average(pd.isnull(nih_ama_unique2.AMA_research_id))\n",
    "\n",
    "# percentage missing ama medical school\n",
    "print np.average(pd.isnull(nih_ama_unique2.AMA_med_school))\n",
    "\n",
    "# percentage missing ama middle name\n",
    "print np.average(pd.isnull(nih_ama_unique2.AMA_mname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.average(pd.isnull(nih_ama_unique2.AMA_b_date))\n",
    "print np.average(pd.isnull(nih_ama_unique2[nih_ama_unique2.control_flag==1].AMA_b_date))\n",
    "print np.average(pd.isnull(nih_ama_unique2[nih_ama_unique2.control_flag==0].AMA_b_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(nih_ama_unique2.AMA_birth_year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nih_ama_unique2.loc[pd.isnull(nih_ama_unique2.AMA_b_date), ['AMA_birth_year', 'AMA_b_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
