{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import funcy\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from data_cleaning_functions import (trans_remov_punc, standardize_whitespace, remove_punc, remove_suffix_from_last_name,\n",
    "                                     clean_names, has_award, has_suffix, get_suffix, replace_last_name, \n",
    "                                     is_year_range, str_sim, clean_med_school, clean_std_college_name, long_form_date, \n",
    "                                    correct_mispellings)\n",
    "\n",
    "from dev import (\n",
    "    APP_DATA_DIR, SUM_STAT_DIR, ATT_DATA_DIR, CARD_DATA_DIR, CORRECTIONS_DIR, AWARDS_KEYWORDS, NAME_COLS, RAW_NAME_COLS, \n",
    "    RAW_CARD_ID, RAW_INDEX_IDS, PERSON_APPLICATION_ID, PERSON_ID, NIH_ID, FEMALE_FIRST_NAMES,\n",
    "    PICKLE_DIR, AAMC_DATA_DIR, GRANT_ID)\n",
    "\n",
    "from merging_functions import *\n",
    "\n",
    "OUTPUT_CSV = False \n",
    "\n",
    "PERSONAL_INFO = [\n",
    "    'clean_first_name', 'clean_last_name', 'clean_middle_name',\n",
    "    'date_of_birth', 'medical_school', 'clean_college_trans']\n",
    "\n",
    "\n",
    "# load autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps = pd.read_csv(os.path.join(APP_DATA_DIR, 'NIH_AAMC_index_cards_grant_standardized.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps = apps.rename(columns={'inst': 'medical_school_std', 'department': 'residency_department', \n",
    "                           'birth_country_cd': 'birth_country', 'institute': 'NIH_institution', \n",
    "                           'sub_department':'residency_sub_dep'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps['multiple_applications_flag'] = apps[['application_year_min', 'application_year_max']].apply(\n",
    "    lambda x: 1 if x[0] != x[1] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_percent_df(df_raw, group_col_1, value_col):\n",
    "    if not isinstance(group_col_1, str):\n",
    "        grouping_1 = list(group_col_1)\n",
    "        grouping_2 = grouping_1 + [value_col]\n",
    "    else:\n",
    "        grouping_1 = [group_col_1]\n",
    "        grouping_2 = [group_col_1, value_col]\n",
    "    c = df_raw.groupby(grouping_1)[PERSON_ID].apply(lambda x: len(x))\n",
    "    d2_raw = pd.DataFrame(df_raw.groupby(grouping_2)[PERSON_ID].apply(lambda x: len(x.unique())))\n",
    "    vals = []\n",
    "    for v in c.index.values:\n",
    "        try:\n",
    "            d2_0 = d2_raw.xs(v, level=group_col_1, drop_level=False).apply(lambda x: x/c[v])\n",
    "            vals.append(d2_0)\n",
    "        except KeyError as e:\n",
    "            # if no grouped values in the index, continue loop\n",
    "            print e\n",
    "    concat_df = pd.concat(vals, axis=0)\n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_sum_stats(df, excel_writer, col_name, combos=None):\n",
    "    # to basic grouping \n",
    "    d1_size = df.shape[0]\n",
    "    d1 = pd.DataFrame(df[col_name].value_counts(dropna=False)/d1_size)\n",
    "    d1.to_excel(excel_writer, col_name)\n",
    "    if not combos:\n",
    "        combos = [('control_flag', '{}_control_flag'), ('application_year_min', '{}_app_year'), \n",
    "                     (('control_flag', 'application_year_min'), '{}_app_year_control')]\n",
    "    for grouping_combo, sheet_name in combos:\n",
    "        formatted_sheetname = sheet_name.format(col_name)[:30]\n",
    "        d2 = get_percent_df(df, grouping_combo, col_name)\n",
    "        d2.to_excel(excel_writer, formatted_sheetname)\n",
    "#     d3 = get_percent_df(df, 'application_year_min', col_name)\n",
    "#     d3.to_excel(excel_writer, '{}_app_year'.format(col_name)[:30])\n",
    "#     d4 = get_percent_df(df, ('control_flag', 'application_year_min'), col_name)\n",
    "#     d4.to_excel(excel_writer, '{}_app_year_control'.format(col_name)[:30])\n",
    "    excel_writer.save()\n",
    "    # write each to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter(os.path.join(PICKLE_DIR, 'sample_summary_stats.xlsx'), engine='openpyxl')\n",
    "\n",
    "# calc_sum_stats(apps, writer, 'medical_school_std', None)\n",
    "\n",
    "# # calc_sum_stats(apps, writer, 'residency_department', None)\n",
    "# # calc_sum_stats(apps, writer, 'residency_hospital_std', None)\n",
    "# # calc_sum_stats(apps, writer, 'internship_hospital_std', None)\n",
    "# calc_sum_stats(apps, writer, 'eod_year', [('control_flag', '{}_control_flag')])\n",
    "# calc_sum_stats(apps, writer, 'is_foreign', None)\n",
    "# calc_sum_stats(apps, writer, 'is_female', None)\n",
    "# calc_sum_stats(apps, writer, 'application_year_min', [('control_flag', '{}_control_flag')])\n",
    "\n",
    "# calc_sum_stats(apps, writer, 'birth_country')\n",
    "# calc_sum_stats(apps, writer, 'birth_year')\n",
    "# calc_sum_stats(apps, writer, 'multiple_applications_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_missing_values(df, col_name, NULL_VALS=None):\n",
    "    if not NULL_VALS:\n",
    "        NULL_VALS = ['NONE', 'OTHER', '', 'None', 'NA']\n",
    "    df.loc[df[col_name].isin(NULL_VALS), col_name] = np.nan\n",
    "    missing_mask = pd.isnull(df[col_name])\n",
    "    missing_colname = '{}_missing'.format(col_name)\n",
    "    df[missing_colname] = 0\n",
    "    df.loc[missing_mask, missing_colname] = 1\n",
    "    miss_series = df[missing_colname].value_counts()/df.shape[0]\n",
    "    return miss_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = map(lambda x: count_missing_values(apps, x), \n",
    "          ['clean_first_name', 'clean_middle_name', 'clean_last_name', 'birth_date',\n",
    "            'birth_country', 'birth_year', 'medical_school', 'residency_department',\n",
    "             'residency_hospital', 'internship_hospital', 'undergrad_year_grad', 'race', \n",
    "            'clean_college', 'medschool_year_grad', 'internship_start', 'internship_end',\n",
    "            'residency_start', 'residency_end', 'address', 'city', 'state', 'aamc_id', \n",
    "           'eod_year',  'application_year_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_series = pd.concat(res, axis=1)\n",
    "missing_series.to_csv(os.path.join(SUM_STAT_DIR, 'missing_data_summary_stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eod_year</th>\n",
       "      <th>application_year_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      eod_year  application_year_max\n",
       "1395       NaN                1960.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps.loc[pd.isnull(apps.eod_year)&(~pd.isnull(apps.dno)), ['eod_year', 'application_year_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps.loc[pd.isnull(apps.eod_year)&(~pd.isnull(apps.dno)), 'eod_year'] =  apps.loc[\n",
    "    pd.isnull(apps.eod_year)&(~pd.isnull(apps.dno)), 'application_year_max'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "control = apps.groupby(['application_year_max', 'control_flag'])['person_uuid'].apply(lambda x: len(x))\n",
    "female = apps.groupby(['application_year_max', 'is_female'])['person_uuid'].apply(lambda x: len(x))\n",
    "foreign = apps.groupby(['application_year_max', 'is_foreign'])['person_uuid'].apply(lambda x: len(x))\n",
    "\n",
    "control_nonmale_nonforeign = apps.loc[(apps.is_female==0) & (apps.is_foreign==0), :].groupby(\n",
    "    ['application_year_max', 'control_flag'])['person_uuid'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_df = pd.concat([control, female, foreign, control_nonmale_nonforeign], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_df.columns = ['is_control', 'is_female', 'is_foreign', 'restricted_control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_df.to_csv(os.path.join(SUM_STAT_DIR, 'broad_sample_sum_stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
