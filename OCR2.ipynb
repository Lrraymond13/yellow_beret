{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import funcy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "test_lst = [\n",
    "    'BENDER GENEVIEVE I', 'BENDER LOUIS J JR BENDLIN JUDITH E',\n",
    "    'BENEDICT JEAN D', 'BENEDICT MYRTLE M', 'BENHAM WILLIAM F']\n",
    "\n",
    "#jupyter nbconvert --to script\n",
    "# convert jupyter notebook to script so you can import functions\n",
    "\n",
    "SUFFIXES = ['JR', 'SR', 'I', 'II', 'IV', 'III', 'DR']\n",
    "path = '/Users/lrraymond13/MIT/Azoulay_RA_2016/Data'\n",
    "\n",
    "\n",
    "def is_suffix_initial(wrd):\n",
    "    if wrd in SUFFIXES + ['8', 'OR', 'DR', 'MC', 'LA']:\n",
    "        return True\n",
    "    return len(wrd) == 1\n",
    "\n",
    "\n",
    "def clean_name_string(raw_str):\n",
    "    # standardize spaces, map to uppercase\n",
    "    raw_lst = filter(None, raw_str.split(' '))\n",
    "    # remove periods, commas\n",
    "    cleaned_str = map(\n",
    "        lambda wrd: ''.join(\n",
    "            funcy.remove(lambda x: x in ['.', ','], wrd)), raw_lst)\n",
    "    # convert back into a string\n",
    "    return ' '.join(map(lambda x: x.upper().strip(), cleaned_str))\n",
    "\n",
    "\n",
    "def parse_multi_names(raw_str):\n",
    "    wrds = raw_str.split(' ')\n",
    "    counter = 0\n",
    "    names_list = []\n",
    "    while counter < len(wrds):\n",
    "        next_counter = 2\n",
    "        print counter, next_counter\n",
    "        name = wrds[counter: counter+next_counter]\n",
    "        # check next word\n",
    "        while counter+next_counter < len(wrds):\n",
    "            if is_suffix_initial(wrds[counter+next_counter]):\n",
    "                name.append(wrds[counter+next_counter])\n",
    "                next_counter += 1\n",
    "            else:\n",
    "                break\n",
    "        counter = counter + next_counter\n",
    "        names_list.append(' '.join(name))\n",
    "    return names_list\n",
    "\n",
    "\n",
    "def process_list_names(index, lst_names):\n",
    "    wrds = lst_names[index].split(' ')\n",
    "    if (index == len(lst_names) - 1) and (len(wrds) <= 3):\n",
    "        # if last set of words in the list and less than 3 words\n",
    "        print 'end'\n",
    "        print index, len(lst_names)\n",
    "        return True, [], lst_names[index]\n",
    "    if len(wrds) == 3 and is_suffix_initial(wrds[-1]):\n",
    "        print 'len is 3'\n",
    "        return True, lst_names[index+1:], lst_names[index]\n",
    "    elif len(wrds) == 4 and is_suffix_initial(wrds[-1]):\n",
    "        print 'len is 4'\n",
    "        # something like ANDERSON ELIZABETH P DR\n",
    "        return True, lst_names[index+1:], lst_names[index]\n",
    "    elif len(wrds) == 2:\n",
    "        print 'len is 2'\n",
    "        # check to make sure no suffix starting with next word\n",
    "        next_wrds = lst_names[index+1].split(' ')\n",
    "        if is_suffix_initial(next_wrds[1]) and is_suffix_initial(next_wrds[0]):\n",
    "            new_next = ' '.join(next_wrds[2:])\n",
    "            return False, [new_next] + lst_names[index+2:], ' '.join(wrds+next_wrds[:2])\n",
    "        elif is_suffix_initial(next_wrds[0]):\n",
    "            new_next = ' '.join(next_wrds[1:])\n",
    "            return False, [new_next] + lst_names[index+2:], ' '.join(wrds+next_wrds[0])\n",
    "        else:\n",
    "            print 'Normal words'\n",
    "            return True, lst_names[index+2:], ' '.join(wrds)\n",
    "    else:\n",
    "        # length is greater before, so def more than 1 name\n",
    "        # parse these out\n",
    "        'print parsing multi names'\n",
    "        names = parse_multi_names(lst_names[index])\n",
    "        return False, lst_names[index+1:], names\n",
    "\n",
    "\n",
    "def separate_names(multi_names_df):\n",
    "    # create new df with multi names sep into rows\n",
    "    new_dfs = []\n",
    "    for row in multi_names_df['clean'].values:\n",
    "        new_names = []\n",
    "        row_names = row.split('\\n')\n",
    "        process_list = row_names\n",
    "        while len(process_list) > 0:\n",
    "            res = process_list_names(0, process_list)\n",
    "            print res\n",
    "            is_name = res[0]\n",
    "            one_name = res[2]\n",
    "            process_list = res[1]\n",
    "            if len(one_name) > 0:\n",
    "                new_names.append(one_name)\n",
    "        new_names_flat = funcy.flatten(new_names)\n",
    "        new_dfs.append(pd.DataFrame({\n",
    "            'name': [row]*len(new_names_flat),\n",
    "            'clean': new_names_flat,\n",
    "            'cleaned_name': [1]*len(new_names_flat)}))\n",
    "    return pd.concat(new_dfs, axis=0)\n",
    "\n",
    "\n",
    "def has_multi_names(raw_str):\n",
    "    # check if a column contains more than one name\n",
    "    # if a column contains a newline, def multiple names\n",
    "    split_names = raw_str.split('\\n')\n",
    "    if len(split_names) > 1:\n",
    "        return True\n",
    "    # otherwise, if more than 4 sep words, flag\n",
    "    wrds = raw_str.split(' ')\n",
    "    if len(wrds) <= 3:\n",
    "        return False\n",
    "    if len(wrds) <= 5:\n",
    "        return not is_suffix_initial(wrds[-1])\n",
    "    return True\n",
    "\n",
    "\n",
    "def process_sheet(sheet_df_obj):\n",
    "    # clean strings, find rows with multiple names in one row\n",
    "    # separate those into sep df, create single names\n",
    "    # return appended df\n",
    "    sheet_df_obj['clean'] = sheet_df_obj['name'].apply(clean_name_string)\n",
    "    # then find rows with multiple names in one row\n",
    "    multi_row_mask = sheet_df_obj['clean'].apply(has_multi_names)\n",
    "    multi_rows = sheet_df_obj[multi_row_mask]\n",
    "    single_names = sheet_df_obj[~multi_row_mask]\n",
    "    if multi_rows.shape[0] > 0:\n",
    "        new_rows = separate_names(multi_rows)\n",
    "        return single_names.append(new_rows)\n",
    "    return single_names\n",
    "\n",
    "\n",
    "def process_workbook(year, path, sheets=None):\n",
    "    # sheet should be a list\n",
    "    # for each sheet, create a dataframe of cleaned names\n",
    "    # append together, add year column and return\n",
    "    filename = os.path.join(path, '{}_excel.xlsx'.format(str(year)))\n",
    "    if not sheets:\n",
    "        excel_file = pd.ExcelFile(filename)\n",
    "        sheets = filter(lambda x: x.startswith('Sheet'), excel_file.sheet_names)\n",
    "    year_df_lst = []\n",
    "    for sheet_name in sheets:\n",
    "        print sheet_name\n",
    "        df = pd.read_excel(filename, sheetname=sheet_name, header=None, names=['name'])\n",
    "        print df.head()\n",
    "        new_df = process_sheet(df)\n",
    "        new_df['sheet'] = sheet_name\n",
    "        year_df_lst.append(new_df)\n",
    "    # append all dfs together, add a year columns\n",
    "    year_df = pd.concat(year_df_lst, axis=0)\n",
    "    year_df['year'] = int(year)\n",
    "    return year_df\n",
    "\n",
    "def write_out_result(df, path, year):\n",
    "    df2 = df.fillna(0)\n",
    "    df2.to_csv(os.path.join(path, '{}_filtered.csv'.format(str(year))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}