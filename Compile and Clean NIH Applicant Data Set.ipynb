{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in known applicant files, clean and try to dedupe\n",
    "from collections import Counter\n",
    "import difflib\n",
    "from fuzzywuzzy import fuzz\n",
    "import uuid\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import funcy\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "from data_cleaning_functions import correct_mispellings, long_form_date, clean_names, clean_med_school\n",
    "from dev import (\n",
    "    SUFFIXES, FEMALE_FIRST_NAMES, FEMALE_MIDDLE_NAMES, NAME_COLS, RAW_ATT_DATA_DIR, ATT_DATA_DIR, PICKLE_DIR, \n",
    "        CORRECTIONS_DIR, SUM_STAT_DIR)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1_file = '1964-1973 associates.XLS'\n",
    "r2_file = 'Associates alpha by institute.XLS'\n",
    "r3_file = 'Associates data.XLS'\n",
    "r4_file = 'NIMH Associates Complete.XLS'\n",
    "r5_file = 'NINDB Associates alpha by year.xls'\n",
    "filenames = [r1_file, r2_file, r3_file, r4_file, r5_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "file_df = map(lambda x: pd.read_excel(os.path.join(RAW_ATT_DATA_DIR, x)), filenames)\n",
    "\n",
    "file_4_columns = [\n",
    "    'dno', 'source', 'unknown', 'lastname', 'first_middle', 'institute', 'lab_brch', \n",
    "    'program', 'supervisor', 'eod_year', 'med_school', 'year_grad', 'intern_hos', 'intern_dte',\n",
    "       'res_hosp', 'residency', 'res_dtes'\n",
    "]\n",
    "\n",
    "file_df[2].rename(columns={'lname':'lastname', 'fname': 'first_middle'}, inplace=True)\n",
    "file_df[1].rename(columns={'lname':'lastname', 'fname': 'first_middle'}, inplace=True)\n",
    "\n",
    "file_df[4].columns = file_4_columns\n",
    "# for each files in the list, add a column to track source\n",
    "for name, f in zip(filenames, file_df):\n",
    "    f.loc[:, 'data_source'] = name\n",
    "concat_df = pd.concat(file_df).reset_index(drop=True)\n",
    "\n",
    "print sum(map(lambda x: x.shape[0], file_df)) == concat_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def has_suffix(lst_strs):\n",
    "    # check for any existing suffix\n",
    "    existing_suffixes = filter(None, filter(lambda x: x in lst_strs, SUFFIXES))\n",
    "    # if suffix is I or V, only return suffix if len of lst_string > 2 (otherwise middle name)\n",
    "    if ('I' in existing_suffixes or 'V' in existing_suffixes) and len(lst_strs) > 2:\n",
    "        return existing_suffixes\n",
    "    return funcy.remove(lambda x: x in ['I', 'V', 'DR'], existing_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_first_middle(raw_str):\n",
    "    # seperate first_middle column string (Thomas, Bruce) into THOMAS BRUCE\n",
    "    # suffix also appears to be in column THOMAS BRUCE JR\n",
    "    names = filter(None, raw_str.split(' '))\n",
    "    cleaned_vals = map(clean_names, names)\n",
    "    suff = has_suffix(cleaned_vals)\n",
    "    # suffix is actually a list\n",
    "    if suff:\n",
    "        root = funcy.remove(lambda x: x==suff[-1], cleaned_vals)\n",
    "        return pd.Series(\n",
    "            {'clean_first_name': root[0],\n",
    "                 'clean_middle_name': ' '.join(root[1:]),\n",
    "                    'clean_suffix': suff[-1]})\n",
    "    return pd.Series(\n",
    "        {'clean_first_name': cleaned_vals[0],\n",
    "             'clean_middle_name': np.nan if len(cleaned_vals)==1 else ' '.join(cleaned_vals[1:]),\n",
    "                'clean_suffix': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_suffix_df = pd.DataFrame(concat_df.loc[~pd.isnull(concat_df.first_middle), 'first_middle'].apply(strip_first_middle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_suffix(raw_str):\n",
    "    # wrapper around get suffix\n",
    "    if pd.isnull(raw_str) or len(raw_str.split(' ')) < 2:\n",
    "        return np.nan\n",
    "    str_list = raw_str.split(' ')\n",
    "    suff = has_suffix(str_list)\n",
    "    if suff:\n",
    "        return suff[-1]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we have all the associates, sep first middle into first and middle name, then sort and check \n",
    "# to see if we have any duplicates\n",
    "df2 = pd.concat([concat_df, cleaned_suffix_df], axis=1)\n",
    "df2.head()\n",
    "df2.loc[:, 'clean_last_name'] = df2.lastname.apply(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10729, 24)\n",
      "(10723, 24)\n"
     ]
    }
   ],
   "source": [
    "# consolidate firstname columns\n",
    "missing_first_middle = pd.isnull(df2.first_middle)\n",
    "df2.loc[missing_first_middle, ['clean_first_name', 'clean_middle_name']] = df2.loc[missing_first_middle, ['firstname', 'middlename']].applymap(clean_names)\n",
    "df2.loc[:, 'len_middle'] = df2.clean_middle_name.apply(lambda x: np.nan if pd.isnull(x) else len(x.split(' ')))\n",
    "\n",
    "# clean suffix out from any other columns\n",
    "may_have_suffix_mask = df2.len_middle > 1\n",
    "df2.loc[may_have_suffix_mask, 'clean_suffix'] = df2[may_have_suffix_mask]['clean_middle_name'].apply(get_suffix)\n",
    "\n",
    "df3 = df2.drop(['first_middle', 'firstname', 'middlename', 'lastname', 'len_middle'], axis=1)\n",
    "# df3 = df2\n",
    "# # dropnow where both first and last name are missing\n",
    "df4 = df3.dropna(subset=['clean_first_name', 'clean_last_name'], how='all')\n",
    "print df3.shape\n",
    "print df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove all females\n",
    "female_mask = np.logical_or(\n",
    "    df4.clean_first_name.isin(FEMALE_FIRST_NAMES), df4.clean_middle_name.isin(FEMALE_MIDDLE_NAMES))\n",
    "\n",
    "df5 = df4.loc[~female_mask, :].sort_values(NAME_COLS)\n",
    "df5.loc[:, 'clean_middle_initial'] = df5.clean_middle_name.apply(lambda x: np.nan if pd.isnull(x) or x=='' else x[0])\n",
    "df5.loc[:, 'clean_first_initial'] = df5.clean_first_name.apply(lambda x: np.nan if pd.isnull(x) or x=='' else x[0])\n",
    "df5.loc[:, 'clean_medical_school'] = df5.med_school.apply(funcy.rcompose(clean_names, clean_med_school))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_missing(row):\n",
    "    # count the number of entries that are null\n",
    "    return row[pd.isnull(row)].size\n",
    "\n",
    "df5.loc[:, 'count_missing'] = df5[\n",
    "    NAME_COLS+['clean_medical_school', 'eod_year', 'res_dtes', 'res_hosp', 'year_grad']].apply(count_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10050, 28)\n",
      "(3872, 28)\n"
     ]
    }
   ],
   "source": [
    "# drop duplicates by dno\n",
    "df6 = df5.drop_duplicates('dno').sort_values(\n",
    "    ['clean_last_name', 'clean_first_initial', 'clean_middle_name', 'count_missing'], axis=0)\n",
    "print df5.shape\n",
    "print df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_year_diff(x):\n",
    "    # get reference value\n",
    "    ref_year = x.iloc[0]\n",
    "    return pd.Series(x - ref_year)\n",
    "\n",
    "def is_duplicate(grouped_df):\n",
    "    # return true if grouped df should be counted as one duplicate, returns filter mask\n",
    "    # check if med schools match/are missing\n",
    "    # check if eod years match/are missing\n",
    "    # first group_id\n",
    "    if grouped_df.shape[0] == 1:\n",
    "        return pd.Series([np.nan])\n",
    "    med_schools = grouped_df['clean_medical_school'].dropna().unique()\n",
    "    # if only <= 1 unique med school, mark as duplicate\n",
    "    ref_dno = grouped_df['dno'].values[0]\n",
    "    if len(med_schools) < 2:\n",
    "        return pd.Series([ref_dno]*grouped_df.shape[0])\n",
    "    ms1 = med_schools[0]\n",
    "    # otherwise, check the string similarity of the med school\n",
    "    med_school_sims = [\n",
    "        np.nan if pd.isnull(ms) else fuzz.partial_token_sort_ratio(\n",
    "                ms1, ms) for ms in grouped_df.clean_medical_school.values]\n",
    "    # for med schools with high string sim, count as dups, otherwise not \n",
    "    is_dups = [ref_dno if pd.isnull(sim) or sim > .8 else False for sim in med_school_sims]\n",
    "    return pd.Series(is_dups)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizenship</th>\n",
       "      <th>data_source</th>\n",
       "      <th>dno</th>\n",
       "      <th>dob</th>\n",
       "      <th>eod_year</th>\n",
       "      <th>generation</th>\n",
       "      <th>institute</th>\n",
       "      <th>intern_dte</th>\n",
       "      <th>intern_hos</th>\n",
       "      <th>lab_brch</th>\n",
       "      <th>...</th>\n",
       "      <th>unknown</th>\n",
       "      <th>year_grad</th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_suffix</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_middle_initial</th>\n",
       "      <th>clean_first_initial</th>\n",
       "      <th>clean_medical_school</th>\n",
       "      <th>count_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Associates alpha by institute.XLS</td>\n",
       "      <td>4130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIMH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZIVIN</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>NORTHWESTERN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Associates alpha by institute.XLS</td>\n",
       "      <td>4131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIMH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZIVIN</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>NORTHWESTERN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     citizenship                        data_source   dno  dob  eod_year  \\\n",
       "5556         NaN  Associates alpha by institute.XLS  4130  NaN    1973.0   \n",
       "5557         NaN  Associates alpha by institute.XLS  4131  NaN       NaN   \n",
       "\n",
       "     generation institute intern_dte intern_hos lab_brch      ...        \\\n",
       "5556        NaN      NIMH        NaN        NaN      NaN      ...         \n",
       "5557        NaN      NIMH        NaN        NaN      NaN      ...         \n",
       "\n",
       "     unknown year_grad clean_first_name clean_middle_name clean_suffix  \\\n",
       "5556     NaN    1970.0           JUSTIN             ALLEN          NaN   \n",
       "5557     NaN    1970.0           JUSTIN             ALLEN          NaN   \n",
       "\n",
       "     clean_last_name  clean_middle_initial clean_first_initial  \\\n",
       "5556           ZIVIN                     A                   J   \n",
       "5557           ZIVIN                     A                   J   \n",
       "\n",
       "     clean_medical_school  count_missing  \n",
       "5556         NORTHWESTERN              2  \n",
       "5557         NORTHWESTERN              3  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.loc[df6.dno==4130, :]\n",
    "df6.loc[df6.clean_last_name=='ZIVIN', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df6_grouped = df6.groupby(['clean_last_name', 'clean_first_initial'])\n",
    "df6['eod_year_diff'] = df6_grouped.eod_year.apply(get_year_diff)\n",
    "# df6['is_dup_index'] = df6_grouped.apply(is_duplicate)\n",
    "new_col = df6_grouped.apply(is_duplicate)\n",
    "# reset so no longer grouped as a multi index, then merge in via clean first, last_name\n",
    "\n",
    "# dups = df6_grouped.filter(lambda x: is_duplicate(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3773,)\n",
      "(3773, 3)\n"
     ]
    }
   ],
   "source": [
    "new_col2 = new_col.reset_index()\n",
    "new_col2.drop('level_2', axis=1, inplace=True)\n",
    "print new_col.shape\n",
    "print new_col2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_col2.columns = ['clean_last_name', 'clean_first_initial', 'duplicate_dno']\n",
    "new_col3 = new_col2.drop_duplicates(['clean_last_name', 'clean_first_initial', 'duplicate_dno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_first_initial</th>\n",
       "      <th>duplicate_dno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARON</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clean_last_name clean_first_initial duplicate_dno\n",
       "0           AARON                   R           NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_col4 = new_col3[new_col3['duplicate_dno']!=False]\n",
    "new_col4[new_col4['clean_last_name']=='AARON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df7 = pd.merge(left=df6, right=new_col4, on=['clean_last_name', 'clean_first_initial'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_medical_school</th>\n",
       "      <th>eod_year</th>\n",
       "      <th>res_dtes</th>\n",
       "      <th>res_hosp</th>\n",
       "      <th>year_grad</th>\n",
       "      <th>dno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1970-1971</td>\n",
       "      <td>Beth Israel - Harvard</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>VANDERBILT</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1960-1961</td>\n",
       "      <td>Johns Hopkins Hospital</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>STUART</td>\n",
       "      <td>PHILLIP</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clean_first_name clean_middle_name clean_last_name clean_medical_school  \\\n",
       "22           RONALD             DAVID           ADLER             STANFORD   \n",
       "23          RICHARD               NaN           ADLER           VANDERBILT   \n",
       "24           STUART           PHILLIP           ADLER        JOHNS HOPKINS   \n",
       "\n",
       "    eod_year   res_dtes                res_hosp  year_grad  dno  \n",
       "22    1971.0  1970-1971   Beth Israel - Harvard     1969.0   28  \n",
       "23    1961.0  1960-1961  Johns Hopkins Hospital     1959.0   27  \n",
       "24    1972.0        NaN                     NaN     1971.0   29  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.loc[\n",
    "    df7.clean_last_name=='ADLER', NAME_COLS+['clean_medical_school', 'eod_year', 'res_dtes', 'res_hosp', 'year_grad', 'dno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df7.loc[:, 'eod_year_diff'] = df7.eod_year_diff.abs()\n",
    "df7.loc[(df7.eod_year_diff>2) , 'duplicate_dno'] = np.nan\n",
    "df7.loc[df7.duplicate_dno==df7.dno , 'duplicate_dno'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>dup_flag</th>\n",
       "      <th>duplicate_dno</th>\n",
       "      <th>dno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>STUART</td>\n",
       "      <td>PHILLIP</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>0</td>\n",
       "      <td>[28, 27]</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clean_first_name clean_middle_name clean_last_name  dup_flag duplicate_dno  \\\n",
       "22           RONALD             DAVID           ADLER         0           NaN   \n",
       "23          RICHARD               NaN           ADLER         0           NaN   \n",
       "24           STUART           PHILLIP           ADLER         0           NaN   \n",
       "0           RICHARD             DAVID           ADLER         0      [28, 27]   \n",
       "\n",
       "    dno  \n",
       "22   28  \n",
       "23   27  \n",
       "24   29  \n",
       "0    28  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.loc[df9.clean_last_name=='ADLER', NAME_COLS+['dup_flag', 'duplicate_dno', 'dno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>dup_flag</th>\n",
       "      <th>duplicate_dno</th>\n",
       "      <th>dno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>JOHN</td>\n",
       "      <td></td>\n",
       "      <td>TEW</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEW</td>\n",
       "      <td>0</td>\n",
       "      <td>3700</td>\n",
       "      <td>3699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clean_first_name clean_middle_name clean_last_name  dup_flag  \\\n",
       "3367             JOHN                               TEW         1   \n",
       "3368             JOHN               NaN             TEW         0   \n",
       "\n",
       "     duplicate_dno   dno  \n",
       "3367           NaN  3700  \n",
       "3368          3700  3699  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.loc[df9.clean_last_name=='TEW', NAME_COLS+['dup_flag', 'duplicate_dno', 'dno']]\n",
    "df8.loc[df8.dno==3699, NAME_COLS+['dup_flag', 'duplicate_dno', 'dno']]\n",
    "df8.loc[df8.dno.isin([3700, 3699]), NAME_COLS+['dup_flag', 'duplicate_dno', 'dno']]\n",
    "df8.loc[df8.dno.isin([3700, 3699]), NAME_COLS+['dup_flag', 'duplicate_dno', 'dno']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>dno</th>\n",
       "      <th>dup_flag</th>\n",
       "      <th>duplicate_dno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>V</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>AXELROD</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>M</td>\n",
       "      <td>BARON</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ROLF</td>\n",
       "      <td>F</td>\n",
       "      <td>BARTH</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>NORMAN</td>\n",
       "      <td>WALTER</td>\n",
       "      <td>BARTON</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PATRICK</td>\n",
       "      <td>BENNETT</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>GERALD</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>BERG</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>BERKOWITZ</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>L</td>\n",
       "      <td>BERMAN</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>W</td>\n",
       "      <td>KENNETH</td>\n",
       "      <td>BLAYLOCK</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>H</td>\n",
       "      <td>BLUM</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>ALLEN</td>\n",
       "      <td>RICHARD</td>\n",
       "      <td>BRAUN</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>CARL SUMMER</td>\n",
       "      <td>BREITNER</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>STEVEN</td>\n",
       "      <td>S</td>\n",
       "      <td>BREM</td>\n",
       "      <td>421</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>BURKE</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>BROOKS</td>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>CLARENCE</td>\n",
       "      <td>H</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>454</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>DONALD</td>\n",
       "      <td>D</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ERIC</td>\n",
       "      <td>JOEL</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>W</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>STICKLER</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>WILLIS</td>\n",
       "      <td>E</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>HOLMES</td>\n",
       "      <td>BURNS</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>R</td>\n",
       "      <td>CARTER</td>\n",
       "      <td>569</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ANTHONY</td>\n",
       "      <td>CHIA LING</td>\n",
       "      <td>CHANG</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>M</td>\n",
       "      <td>CLARK</td>\n",
       "      <td>643</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>CLARK</td>\n",
       "      <td>649</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>DONALD</td>\n",
       "      <td>JAY</td>\n",
       "      <td>COHEN</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARSHALL</td>\n",
       "      <td>DORF</td>\n",
       "      <td>SKLAR</td>\n",
       "      <td>3472</td>\n",
       "      <td>0</td>\n",
       "      <td>[3472, 3471]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDREW</td>\n",
       "      <td>JEPTHA KINCANNON</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>3484</td>\n",
       "      <td>1</td>\n",
       "      <td>[3483, 3482, 3484]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHARLES</td>\n",
       "      <td>VERNON</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>3486</td>\n",
       "      <td>0</td>\n",
       "      <td>[3485, 3486]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>3488</td>\n",
       "      <td>0</td>\n",
       "      <td>[3487, 3488]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOWARD</td>\n",
       "      <td>GARY</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>3491</td>\n",
       "      <td>0</td>\n",
       "      <td>[3490, 3491]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>GRAHAM</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>3499</td>\n",
       "      <td>1</td>\n",
       "      <td>[3497, 3499, 3498, 3496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOLOMON</td>\n",
       "      <td>HALBERT</td>\n",
       "      <td>SNYDER</td>\n",
       "      <td>3511</td>\n",
       "      <td>0</td>\n",
       "      <td>[3510, 3511]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURRAY</td>\n",
       "      <td>B</td>\n",
       "      <td>STEIN</td>\n",
       "      <td>3584</td>\n",
       "      <td>0</td>\n",
       "      <td>[3584, 3583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHERMAN</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>STEIN</td>\n",
       "      <td>3587</td>\n",
       "      <td>0</td>\n",
       "      <td>[3587, 3586]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>M</td>\n",
       "      <td>STEWART</td>\n",
       "      <td>3601</td>\n",
       "      <td>0</td>\n",
       "      <td>[3601, 3600]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>LEWIS</td>\n",
       "      <td>SULLIVAN</td>\n",
       "      <td>3644</td>\n",
       "      <td>0</td>\n",
       "      <td>[3644, 3643]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TALAL</td>\n",
       "      <td>3668</td>\n",
       "      <td>1</td>\n",
       "      <td>[3668, 3667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANUEL</td>\n",
       "      <td>ELLIS</td>\n",
       "      <td>TANCER</td>\n",
       "      <td>3674</td>\n",
       "      <td>1</td>\n",
       "      <td>[3674, 3673]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>O</td>\n",
       "      <td>TAYLOR</td>\n",
       "      <td>3690</td>\n",
       "      <td>1</td>\n",
       "      <td>[3690, 3689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERRY</td>\n",
       "      <td>3698</td>\n",
       "      <td>1</td>\n",
       "      <td>[3698, 3697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOHN</td>\n",
       "      <td></td>\n",
       "      <td>TEW</td>\n",
       "      <td>3700</td>\n",
       "      <td>1</td>\n",
       "      <td>[3700, 3699]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>ARTHUR</td>\n",
       "      <td>THOMAS</td>\n",
       "      <td>3711</td>\n",
       "      <td>0</td>\n",
       "      <td>[3710, 3711]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>KEITH</td>\n",
       "      <td>THORPE</td>\n",
       "      <td>3722</td>\n",
       "      <td>0</td>\n",
       "      <td>[3721, 3722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>W</td>\n",
       "      <td>TUCKER</td>\n",
       "      <td>3763</td>\n",
       "      <td>1</td>\n",
       "      <td>[3763, 3762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JONATHAN</td>\n",
       "      <td>C</td>\n",
       "      <td>VOGEL</td>\n",
       "      <td>3826</td>\n",
       "      <td>0</td>\n",
       "      <td>[3826, 3825]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELLIOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WESER</td>\n",
       "      <td>3949</td>\n",
       "      <td>1</td>\n",
       "      <td>[3949, 3948]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>LYNN</td>\n",
       "      <td>WILDER</td>\n",
       "      <td>3979</td>\n",
       "      <td>0</td>\n",
       "      <td>[3979, 3978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GARY</td>\n",
       "      <td>MURRAY</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3986</td>\n",
       "      <td>0</td>\n",
       "      <td>[3985, 3986]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REDFORD</td>\n",
       "      <td>BROWN JR L</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3991</td>\n",
       "      <td>0</td>\n",
       "      <td>[3990, 3991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WINSTON</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3994</td>\n",
       "      <td>0</td>\n",
       "      <td>[3993, 3994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARSHALL</td>\n",
       "      <td>LEONE</td>\n",
       "      <td>WOLF</td>\n",
       "      <td>4031</td>\n",
       "      <td>0</td>\n",
       "      <td>[4030, 4031]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>J</td>\n",
       "      <td>WURTMAN</td>\n",
       "      <td>4065</td>\n",
       "      <td>1</td>\n",
       "      <td>[4065, 4064]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>TOSHIRO</td>\n",
       "      <td>YANAGIHARA</td>\n",
       "      <td>4072</td>\n",
       "      <td>0</td>\n",
       "      <td>[4072, 4071, 4070]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NATHANIEL</td>\n",
       "      <td>A</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4091</td>\n",
       "      <td>0</td>\n",
       "      <td>[4090, 4091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>CRABILL</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4093</td>\n",
       "      <td>0</td>\n",
       "      <td>[4092, 4093]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clean_first_name clean_middle_name clean_last_name   dno  dup_flag  \\\n",
       "22            RONALD             DAVID           ADLER    28         0   \n",
       "50            JOSEPH             JAMES       ALEXANDER    56         0   \n",
       "53            ROBERT             WAYNE       ALEXANDER    59         0   \n",
       "77           RICHARD                 V        ANDERSON    86         0   \n",
       "128            DAVID             ALLEN         AXELROD   139         0   \n",
       "162           JOSEPH                 M           BARON   178         1   \n",
       "172             ROLF                 F           BARTH   187         0   \n",
       "179           NORMAN            WALTER          BARTON   193         0   \n",
       "226          WILLIAM           PATRICK         BENNETT   245         0   \n",
       "234           GERALD            ROBERT            BERG   256         0   \n",
       "245            DAVID              ALAN       BERKOWITZ   268         0   \n",
       "252          MICHAEL                 L          BERMAN   275         0   \n",
       "309                W           KENNETH        BLAYLOCK   336         1   \n",
       "324           RONALD                 H            BLUM   350         0   \n",
       "376            ALLEN           RICHARD           BRAUN   408         1   \n",
       "386             JOHN       CARL SUMMER        BREITNER   419         1   \n",
       "388           STEVEN                 S            BREM   421         1   \n",
       "411            BURKE            JOSEPH          BROOKS   448         0   \n",
       "418         CLARENCE                 H           BROWN   454         0   \n",
       "419           DONALD                 D           BROWN   456         0   \n",
       "421             ERIC              JOEL           BROWN   458         0   \n",
       "426             JOHN                 W           BROWN   462         0   \n",
       "434           ROBERT          STICKLER           BROWN   470         0   \n",
       "438           WILLIS                 E           BROWN   475         0   \n",
       "472          WILLIAM            HOLMES           BURNS   512         1   \n",
       "523            JAMES                 R          CARTER   569         1   \n",
       "548          ANTHONY         CHIA LING           CHANG   595         0   \n",
       "594           JOSEPH                 M           CLARK   643         0   \n",
       "599           ROBERT              JOHN           CLARK   649         0   \n",
       "612           DONALD               JAY           COHEN   662         0   \n",
       "..               ...               ...             ...   ...       ...   \n",
       "0           MARSHALL              DORF           SKLAR  3472         0   \n",
       "0             ANDREW  JEPTHA KINCANNON           SMITH  3484         1   \n",
       "0            CHARLES            VERNON           SMITH  3486         0   \n",
       "0              DAVID             ALLEN           SMITH  3488         0   \n",
       "0             HOWARD              GARY           SMITH  3491         0   \n",
       "0            RICHARD            GRAHAM           SMITH  3499         1   \n",
       "0            SOLOMON           HALBERT          SNYDER  3511         0   \n",
       "0             MURRAY                 B           STEIN  3584         0   \n",
       "0            SHERMAN           CHARLES           STEIN  3587         0   \n",
       "0            MICHAEL                 M         STEWART  3601         0   \n",
       "0              JAMES             LEWIS        SULLIVAN  3644         0   \n",
       "0             NORMAN               NaN           TALAL  3668         1   \n",
       "0             MANUEL             ELLIS          TANCER  3674         1   \n",
       "0              JAMES                 O          TAYLOR  3690         1   \n",
       "0            WILLIAM               NaN           TERRY  3698         1   \n",
       "0               JOHN                               TEW  3700         1   \n",
       "0              JAMES            ARTHUR          THOMAS  3711         0   \n",
       "0            WILLIAM             KEITH          THORPE  3722         0   \n",
       "0             ROBERT                 W          TUCKER  3763         1   \n",
       "0           JONATHAN                 C           VOGEL  3826         0   \n",
       "0             ELLIOT               NaN           WESER  3949         1   \n",
       "0             RONALD              LYNN          WILDER  3979         0   \n",
       "0               GARY            MURRAY        WILLIAMS  3986         0   \n",
       "0            REDFORD        BROWN JR L        WILLIAMS  3991         0   \n",
       "0            WINSTON            HOWARD        WILLIAMS  3994         0   \n",
       "0           MARSHALL             LEONE            WOLF  4031         0   \n",
       "0            RICHARD                 J         WURTMAN  4065         1   \n",
       "0            RICHARD           TOSHIRO      YANAGIHARA  4072         0   \n",
       "0          NATHANIEL                 A           YOUNG  4091         0   \n",
       "0             ROBERT           CRABILL           YOUNG  4093         0   \n",
       "\n",
       "                duplicate_dno  \n",
       "22                        NaN  \n",
       "50                        NaN  \n",
       "53                        NaN  \n",
       "77                        NaN  \n",
       "128                       NaN  \n",
       "162                       NaN  \n",
       "172                       NaN  \n",
       "179                       NaN  \n",
       "226                       NaN  \n",
       "234                       NaN  \n",
       "245                       NaN  \n",
       "252                       NaN  \n",
       "309                       NaN  \n",
       "324                       NaN  \n",
       "376                       NaN  \n",
       "386                       NaN  \n",
       "388                       NaN  \n",
       "411                       NaN  \n",
       "418                       NaN  \n",
       "419                       NaN  \n",
       "421                       NaN  \n",
       "426                       NaN  \n",
       "434                       NaN  \n",
       "438                       NaN  \n",
       "472                       NaN  \n",
       "523                       NaN  \n",
       "548                       NaN  \n",
       "594                       NaN  \n",
       "599                       NaN  \n",
       "612                       NaN  \n",
       "..                        ...  \n",
       "0                [3472, 3471]  \n",
       "0          [3483, 3482, 3484]  \n",
       "0                [3485, 3486]  \n",
       "0                [3487, 3488]  \n",
       "0                [3490, 3491]  \n",
       "0    [3497, 3499, 3498, 3496]  \n",
       "0                [3510, 3511]  \n",
       "0                [3584, 3583]  \n",
       "0                [3587, 3586]  \n",
       "0                [3601, 3600]  \n",
       "0                [3644, 3643]  \n",
       "0                [3668, 3667]  \n",
       "0                [3674, 3673]  \n",
       "0                [3690, 3689]  \n",
       "0                [3698, 3697]  \n",
       "0                [3700, 3699]  \n",
       "0                [3710, 3711]  \n",
       "0                [3721, 3722]  \n",
       "0                [3763, 3762]  \n",
       "0                [3826, 3825]  \n",
       "0                [3949, 3948]  \n",
       "0                [3979, 3978]  \n",
       "0                [3985, 3986]  \n",
       "0                [3990, 3991]  \n",
       "0                [3993, 3994]  \n",
       "0                [4030, 4031]  \n",
       "0                [4065, 4064]  \n",
       "0          [4072, 4071, 4070]  \n",
       "0                [4090, 4091]  \n",
       "0                [4092, 4093]  \n",
       "\n",
       "[276 rows x 6 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.loc[df9.duplicated('dno', keep=False), NAME_COLS+['dno', 'dup_flag', 'duplicate_dno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df7.loc[:, 'dup_flag'] = 0\n",
    "dup_mask = df7.dno.isin(df7.duplicate_dno.dropna())\n",
    "df7.loc[dup_mask, 'dup_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_flags = ['missing_{}'.format(f) for f in df7.columns]\n",
    "\n",
    "def count_missing(x):\n",
    "    # returns 1 for missing value\n",
    "    if x is None or x in ['None', '', ' ']:\n",
    "        return 1\n",
    "    return 1 if pd.isnull(x) else 0\n",
    "\n",
    "# calculate missing info stats\n",
    "df7[missing_flags] = df7.applymap(count_missing)\n",
    "\n",
    "# calculate missing stats for people in the data set\n",
    "df7[missing_flags].describe().to_csv(os.path.join(SUM_STAT_DIR, 'NIH_attendees_data_fill_rates.csv'))\n",
    "df8 = df7.drop(missing_flags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consolidate_row(series):\n",
    "    nonnulls = series.dropna().unique()\n",
    "    if nonnulls.shape[0] == 0:\n",
    "        return pd.Series([np.nan]*series.shape[0])\n",
    "    if isinstance(nonnulls[0], str):\n",
    "        val = sorted(nonnulls, key=len, reverse=True)[0]\n",
    "        return pd.Series([val]*series.shape[0])\n",
    "    val = sorted(nonnulls, reverse=True)[0]\n",
    "    return pd.Series([val]*series.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_dups = df8.loc[\n",
    "    df8.duplicated(['clean_last_name', 'clean_first_initial'], keep=False), :].groupby(\n",
    "        ['clean_last_name', 'clean_first_initial'], as_index=False)\n",
    "new_df = []\n",
    "for g, df in grouped_dups:\n",
    "    consol_df = df.apply(consolidate_row, axis=0)\n",
    "    consol_df['duplicate_dno'] = [df.dno.values]*df.shape[0]\n",
    "    new_df.append(consol_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df2 = pd.concat(new_df, axis=0)\n",
    "new_df3 = new_df2.drop_duplicates(['clean_first_name', 'clean_last_name', 'eod_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now, merge in manual corrections to add any more duplicate dnos\n",
    "# finally consolidate people merged into the same row\n",
    "df9 = pd.concat([df8.loc[pd.isnull(df8.duplicate_dno), :], new_df3], axis=0)\n",
    "\n",
    "\n",
    "# df7.loc[df7.duplicated(['clean_last_name', 'clean_medical_school'], keep=False), NAME_COLS+['clean_medical_school', 'eod_year', 'dno', 'duplicate_dno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_remove = ['TERRECE', 'FRED', 'LAURENCE',\n",
    "             'CUONO', 'DEFRENZE', 'JEFFERY', 'FINKLEMAN', 'SHERRAD', 'ANSCHNETZ', 'MARC', 'JENSON', 'KASTI', \n",
    "            'ADELBERT', 'RITCHARD', 'MANSFORD', 'DEFRENZO', 'DROBIN', 'HAMES', 'KREUZ', 'JERROLD', 'MANEUSI',\n",
    "            'UNGARO']\n",
    "to_replace = ['TERRENCE', 'FREDERICK', 'LAWRENCE',\n",
    "              'CUOMO', 'DEFRONZO', 'JEFFREY', 'FINKELMAN', 'SHERRARD', 'ANSCHUETZ', 'MARCUS', 'JENSEN', 'KASTL',\n",
    "              'ALBERT', 'RITCHARD', 'MANIFORD', 'DEFRONZO', 'DROBIS', 'JAMES', 'KRUEZ', 'JERROD', 'MANCUSI',\n",
    "              'UNGARO']\n",
    "\n",
    "correct_name_mispellings_fnc = funcy.rpartial(correct_mispellings, to_remove, to_replace)\n",
    "\n",
    "df9.loc[:, 'clean_last_name'] = df9.clean_last_name.apply(correct_name_mispellings_fnc)\n",
    "df9.loc[:, 'clean_first_name'] = df9.clean_first_name.apply(correct_name_mispellings_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to go in and correct some of the name mispellings in both data sets\n",
    "# MUTATING FUNCTION\n",
    "def change_names(df, selection_type, selection_value, to_change_type, to_change_values):\n",
    "    for t, v in zip(to_change_type, to_change_values):\n",
    "        print t, v\n",
    "        df.loc[df[selection_type]==selection_value, t] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_first_name BRUCE\n",
      "clean_middle_name WILCOX\n",
      "clean_first_name MARC\n",
      "clean_middle_name I\n",
      "clean_first_name SIDNEY\n",
      "clean_middle_name CHARLES\n",
      "clean_medical_school WAKE_FOREST\n",
      "clean_first_name DONALD\n",
      "clean_middle_name MARTIN\n",
      "clean_first_name DONALD\n",
      "clean_middle_name MARTIN\n"
     ]
    }
   ],
   "source": [
    "change_names(\n",
    "    df9, 'clean_last_name', 'CHESEBRO', ['clean_first_name', 'clean_middle_name'], ['BRUCE', 'WILCOX'])\n",
    "change_names(df9, 'clean_last_name', 'GALANTER', ['clean_first_name', 'clean_middle_name'], ['MARC', 'I'])\n",
    "change_names(\n",
    "    df9, 'clean_last_name', 'BEAN', ['clean_first_name', 'clean_middle_name', 'clean_medical_school'], ['SIDNEY', 'CHARLES', 'WAKE_FOREST'])\n",
    "change_names(\n",
    "    df9, 'clean_last_name', 'EILER', ['clean_first_name', 'clean_middle_name'], ['DONALD', 'MARTIN'])\n",
    "change_names(\n",
    "    df9, 'clean_last_name', 'FALCHUK', ['clean_first_name', 'clean_middle_name'], ['DONALD', 'MARTIN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in missing eod year\n",
    "# manual corrections\n",
    "df9.loc[(df9.clean_last_name=='BEELS') & pd.isnull(df9.eod_year), 'eod_year'] = 1967\n",
    "df9.loc[(df9.clean_last_name=='KRAUSE') & pd.isnull(df9.eod_year), 'eod_year'] = 1965\n",
    "df9.loc[(df9.clean_last_name=='MELLMAN') & pd.isnull(df9.eod_year), 'eod_year'] = 1986\n",
    "# df9.loc[pd.isnull(df9.eod_year), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import manual eod year fixes\n",
    "manual_eod_fixes = pd.read_excel(os.path.join(CORRECTIONS_DIR, 'manual_eod_fixes.xlsx'))\n",
    "manual_eod_fixes.head()\n",
    "manual_eod_df = manual_eod_fixes[['clean_last_name'] + [c for c in manual_eod_fixes.columns if c.startswith('to_fix')]]\n",
    "\n",
    "missing_eod = pd.merge(\n",
    "    left=df9.loc[pd.isnull(df9.eod_year), :], right=manual_eod_df, on='clean_last_name', how='inner')\n",
    "\n",
    "for x in ['clean_medical_school', 'clean_first_name', 'clean_middle_name', 'eod_year']:\n",
    "    mask = ~pd.isnull(missing_eod['to_fix_{}'.format(x)])\n",
    "    missing_eod.loc[mask, x] = missing_eod.loc[mask, 'to_fix_{}'.format(x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_eod2 = missing_eod.drop(\n",
    "    (c for c in missing_eod.columns if c not in df9.columns), axis=1).drop_duplicates(['clean_last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df10 = pd.concat([df9.loc[~pd.isnull(df9.eod_year), :], missing_eod2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dup_ids = np.concatenate(df10.duplicate_dno.dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dups = ~pd.isnull(df10.duplicate_dno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniques = df10.loc[dups, NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df11 = pd.concat([uniques, df10.loc[~df10.dno.isin(dup_ids)]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>dno</th>\n",
       "      <th>duplicate_dno</th>\n",
       "      <th>clean_medical_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STANFORD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VANDERBILT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>STUART</td>\n",
       "      <td>PHILLIP</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>28</td>\n",
       "      <td>[28, 27]</td>\n",
       "      <td>VANDERBILT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clean_first_name clean_middle_name clean_last_name  dno duplicate_dno  \\\n",
       "22           RONALD             DAVID           ADLER   28           NaN   \n",
       "23          RICHARD               NaN           ADLER   27           NaN   \n",
       "24           STUART           PHILLIP           ADLER   29           NaN   \n",
       "0           RICHARD             DAVID           ADLER   28      [28, 27]   \n",
       "\n",
       "   clean_medical_school  \n",
       "22             STANFORD  \n",
       "23           VANDERBILT  \n",
       "24        JOHNS HOPKINS  \n",
       "0            VANDERBILT  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df10.loc[~pd.isnull(df10.duplicate_dno), NAME_COLS+['dno', 'duplicate_dno']]\n",
    "df10.loc[df10.clean_last_name=='ADLER', NAME_COLS+['dno', 'duplicate_dno', 'clean_medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>dno</th>\n",
       "      <th>duplicate_dno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GARRETT</td>\n",
       "      <td>E</td>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>C</td>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>CLIFTON</td>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>ARTHUR</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>L</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>V</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>ALAN</td>\n",
       "      <td>DOUGLAS</td>\n",
       "      <td>ANDREWS</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>AXELROD</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AXELROD</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>M</td>\n",
       "      <td>BARON</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>JEFFREY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BARON</td>\n",
       "      <td>177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ROLF</td>\n",
       "      <td>F</td>\n",
       "      <td>BARTH</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>BARTH</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NEIL</td>\n",
       "      <td>M</td>\n",
       "      <td>BARTON</td>\n",
       "      <td>192</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>NORMAN</td>\n",
       "      <td>WALTER</td>\n",
       "      <td>BARTON</td>\n",
       "      <td>193</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>MANIFRED</td>\n",
       "      <td>I</td>\n",
       "      <td>BEHRENS</td>\n",
       "      <td>223</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>J</td>\n",
       "      <td>CLAUDE</td>\n",
       "      <td>BENNETT</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>IRA</td>\n",
       "      <td>BENNETT</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PATRICK</td>\n",
       "      <td>BENNETT</td>\n",
       "      <td>245</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>GERALD</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>BERG</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>GARY</td>\n",
       "      <td>WARREN</td>\n",
       "      <td>BERG</td>\n",
       "      <td>255</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>BERKOWITZ</td>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>DANIEL</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>BERKOWITZ</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>MARVIN</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>BERMAN</td>\n",
       "      <td>274</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>L</td>\n",
       "      <td>BERMAN</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>W</td>\n",
       "      <td>KENNETH</td>\n",
       "      <td>BLAYLOCK</td>\n",
       "      <td>336</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>EDWARD</td>\n",
       "      <td>WALKER</td>\n",
       "      <td>3845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>ELLIOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WESER</td>\n",
       "      <td>3949</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>LYNN</td>\n",
       "      <td>WILDER</td>\n",
       "      <td>3979</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>LYNN</td>\n",
       "      <td>WILDER</td>\n",
       "      <td>3978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>GARY</td>\n",
       "      <td>MURRAY</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>GARY</td>\n",
       "      <td>WM</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3986</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>REDFORD</td>\n",
       "      <td>BROWN JR L</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>ROGER</td>\n",
       "      <td>RICHARDS</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>WILLIS</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>WINSTON</td>\n",
       "      <td>HUGH</td>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>GOLDER</td>\n",
       "      <td>N</td>\n",
       "      <td>WILSON</td>\n",
       "      <td>4003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>THOMAS</td>\n",
       "      <td>QUENTIN</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>4016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>THORNE</td>\n",
       "      <td>S</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>4017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>MARSHALL</td>\n",
       "      <td>A</td>\n",
       "      <td>WOLF</td>\n",
       "      <td>4030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>MITCHEL</td>\n",
       "      <td>LEONE</td>\n",
       "      <td>WOLF</td>\n",
       "      <td>4031</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>PETER</td>\n",
       "      <td>FARNUM</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>4058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>J</td>\n",
       "      <td>WURTMAN</td>\n",
       "      <td>4065</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>HAJIME</td>\n",
       "      <td>YANAGIHARA</td>\n",
       "      <td>4072</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>TOSHIRO</td>\n",
       "      <td>YANAGIHARA</td>\n",
       "      <td>4071</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YANAGIHARA</td>\n",
       "      <td>4070</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>NATHANIEL</td>\n",
       "      <td>A</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4090</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>NEAL</td>\n",
       "      <td>S</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>CRABILL</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4092</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>KONG</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4093</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>ZIVIN</td>\n",
       "      <td>4130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JEFFREY</td>\n",
       "      <td>PAUL</td>\n",
       "      <td>FROEHLICH</td>\n",
       "      <td>1198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>M</td>\n",
       "      <td>LYON</td>\n",
       "      <td>2326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>STEVEN</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>NEWMAN</td>\n",
       "      <td>2695</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>A</td>\n",
       "      <td>PECK</td>\n",
       "      <td>2832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JOHN</td>\n",
       "      <td></td>\n",
       "      <td>TEW</td>\n",
       "      <td>3700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clean_first_name clean_middle_name clean_last_name   dno duplicate_dno\n",
       "22             RONALD             DAVID           ADLER    28           NaN\n",
       "23            RICHARD               NaN           ADLER    27           NaN\n",
       "47            GARRETT                 E       ALEXANDER    53           NaN\n",
       "49               JOHN                 C       ALEXANDER    55           NaN\n",
       "50             JOSEPH             JAMES       ALEXANDER    56           NaN\n",
       "52             ROBERT           CLIFTON       ALEXANDER    58           NaN\n",
       "53             ROBERT             WAYNE       ALEXANDER    59           NaN\n",
       "75            RICHARD            ARTHUR        ANDERSON    84           NaN\n",
       "76            RICHARD                 L        ANDERSON    85           NaN\n",
       "77            RICHARD                 V        ANDERSON    86           NaN\n",
       "80               ALAN           DOUGLAS         ANDREWS    89           NaN\n",
       "128             DAVID             ALLEN         AXELROD   139           NaN\n",
       "129             DAVID               NaN         AXELROD   138           NaN\n",
       "162            JOSEPH                 M           BARON   178           NaN\n",
       "163           JEFFREY               NaN           BARON   177           NaN\n",
       "172              ROLF                 F           BARTH   187           NaN\n",
       "173           RICHARD            JOSEPH           BARTH   186           NaN\n",
       "178              NEIL                 M          BARTON   192           NaN\n",
       "179            NORMAN            WALTER          BARTON   193           NaN\n",
       "206          MANIFRED                 I         BEHRENS   223           NaN\n",
       "222                 J            CLAUDE         BENNETT   241           NaN\n",
       "225           WILLIAM               IRA         BENNETT   244           NaN\n",
       "226           WILLIAM           PATRICK         BENNETT   245           NaN\n",
       "234            GERALD            ROBERT            BERG   256           NaN\n",
       "235              GARY            WARREN            BERG   255           NaN\n",
       "245             DAVID              ALAN       BERKOWITZ   268           NaN\n",
       "246            DANIEL            MARTIN       BERKOWITZ   267           NaN\n",
       "251            MARVIN             DAVID          BERMAN   274           NaN\n",
       "252           MICHAEL                 L          BERMAN   275           NaN\n",
       "309                 W           KENNETH        BLAYLOCK   336           NaN\n",
       "...               ...               ...             ...   ...           ...\n",
       "3494           ROBERT            EDWARD          WALKER  3845           NaN\n",
       "3588           ELLIOT               NaN           WESER  3949           NaN\n",
       "3617           RONALD              LYNN          WILDER  3979           NaN\n",
       "3618           RONALD              LYNN          WILDER  3978           NaN\n",
       "3624             GARY            MURRAY        WILLIAMS  3985           NaN\n",
       "3625             GARY                WM        WILLIAMS  3986           NaN\n",
       "3629          REDFORD        BROWN JR L        WILLIAMS  3990           NaN\n",
       "3630            ROGER          RICHARDS        WILLIAMS  3991           NaN\n",
       "3632           WILLIS            HOWARD        WILLIAMS  3993           NaN\n",
       "3633          WINSTON              HUGH        WILLIAMS  3994           NaN\n",
       "3641           GOLDER                 N          WILSON  4003           NaN\n",
       "3653           THOMAS           QUENTIN          WINTER  4016           NaN\n",
       "3654           THORNE                 S          WINTER  4017           NaN\n",
       "3666         MARSHALL                 A            WOLF  4030           NaN\n",
       "3667          MITCHEL             LEONE            WOLF  4031           NaN\n",
       "3694            PETER            FARNUM          WRIGHT  4058           NaN\n",
       "3700          RICHARD                 J         WURTMAN  4065           NaN\n",
       "3706           RONALD            HAJIME      YANAGIHARA  4072           NaN\n",
       "3707          RICHARD           TOSHIRO      YANAGIHARA  4071           NaN\n",
       "3708          RICHARD               NaN      YANAGIHARA  4070           NaN\n",
       "3724        NATHANIEL                 A           YOUNG  4090           NaN\n",
       "3725             NEAL                 S           YOUNG  4091           NaN\n",
       "3726           ROBERT           CRABILL           YOUNG  4092           NaN\n",
       "3727           ROBERT              KONG           YOUNG  4093           NaN\n",
       "3760           JUSTIN             ALLEN           ZIVIN  4130           NaN\n",
       "5             JEFFREY              PAUL       FROEHLICH  1198           NaN\n",
       "14             GEORGE                 M            LYON  2326           NaN\n",
       "17             STEVEN              ALAN          NEWMAN  2695           NaN\n",
       "18            WILLIAM                 A            PECK  2832           NaN\n",
       "23               JOHN                               TEW  3700           NaN\n",
       "\n",
       "[297 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.loc[dups, NAME_COLS+['dno', 'duplicate_dno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>dno</th>\n",
       "      <th>duplicate_dno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>STUART</td>\n",
       "      <td>PHILLIP</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>ADLER</td>\n",
       "      <td>28</td>\n",
       "      <td>[28, 27]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clean_first_name clean_middle_name clean_last_name  dno duplicate_dno\n",
       "22           RONALD             DAVID           ADLER   28           NaN\n",
       "23          RICHARD               NaN           ADLER   27           NaN\n",
       "24           STUART           PHILLIP           ADLER   29           NaN\n",
       "0           RICHARD             DAVID           ADLER   28      [28, 27]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.loc[df10.clean_last_name=='ADLER', NAME_COLS+['dno', 'duplicate_dno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it seems that dno does refer to unique person, so drop dups based on that \n",
    "# save this unique to pick\n",
    "df10.to_pickle(os.path.join(PICKLE_DIR, 'unique_attendees.p'))\n",
    "\n",
    "# to csv\n",
    "df10.to_csv(os.path.join(ATT_DATA_DIR, 'unique_attendees.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_eod_year = df10.loc[pd.isnull(df10.eod_year), :].sort_values('clean_last_name')\n",
    "\n",
    "missing_eod_year[NAME_COLS+['clean_medical_school', 'dno']].to_csv(os.path.join(ATT_DATA_DIR, 'missing_eod_year.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
