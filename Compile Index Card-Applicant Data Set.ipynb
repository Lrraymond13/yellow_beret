{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import string\n",
    "import funcy\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "APP_DATA_DIR = '~/Dropbox (MIT)/yellowberets/lindsey/intermediate_data/applicants_data'\n",
    "ATT_DATA_DIR = '~/Dropbox (MIT)/yellowberets/lindsey/intermediate_data/attendees_data'\n",
    "RAW_ATT_DATA_DIR = '~/Dropbox (MIT)/yellowberets/lindsey/intermediate_data/attendees_data/raw_NIH_data'\n",
    "CARD_DATA_DIR = '~/Dropbox (MIT)/yellowberets/lindsey/intermediate_data/applicants_data/raw_card_data'\n",
    "SUM_STAT_DIR = '~/Dropbox (MIT)/yellowberets/lindsey/intermediate_data/summary stats/raw'\n",
    "print CARD_DATA_DIR\n",
    "\n",
    "r1_file = 'App card info spreadsheet_delaney.xlsx'\n",
    "r2_file = 'App card info spreadsheet SavedDJH2.xlsx'\n",
    "r3_file = 'App card_last484 (1).xlsx'\n",
    "\n",
    "\n",
    "CLEAN_NAMES = ['clean_first_name', 'clean_middle_name', 'clean_last_name']\n",
    "NAMES = ['first_name', 'middle_name', 'last_name']\n",
    "PERSONAL_INFO = [\n",
    "    'clean_first_name', 'clean_last_name', 'clean_middle_name',\n",
    "    'date_of_birth', 'medical_school', 'clean_college_trans']\n",
    "\n",
    "AWARDS_KEYWORDS = ['HONORS', 'AWARD', 'HONOR', 'SOCIETY', 'SCHOLAR', 'AOA', 'PME', 'FNHS', 'ODK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1 = pd.read_excel(os.path.join(CARD_DATA_DIR, r1_file), skiprows=1)\n",
    "r2 = pd.read_excel(os.path.join(CARD_DATA_DIR, r2_file), skiprows=1)\n",
    "r3 = pd.read_excel(os.path.join(CARD_DATA_DIR, r3_file), skiprows=1)\n",
    "\n",
    "r1_2 = r1.drop([c for c in r1.columns if c.startswith('Unnamed:')], axis=1)\n",
    "r2_2 = r2.drop([c for c in r2.columns if c.startswith('Unnamed:')], axis=1)\n",
    "r3_2 = r3.drop([c for c in r3.columns if c.startswith('Unnamed:')], axis=1)\n",
    "\n",
    "del r1, r2, r3\n",
    "\n",
    "# check differing columns\n",
    "print 'Extra r1 columns'\n",
    "print set(r1_2.columns) - set(r2_2.columns)\n",
    "print 'Extra r2 columns'\n",
    "print set(r2_2.columns) - set(r1_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1_2.dropna(how='all', subset=['Sixth', 'Fifth']).loc[:, ['First', 'Second', 'Third', 'Fourth', 'Sixth', 'Fifth']]\n",
    "# only 16 rows aren't totally blank for the columns fifth and sixth, and these columns are blank for all other honor societies\n",
    "r1_2['First'] = r1_2.loc[(~r1_2['Fifth'].isnull()), 'Fifth']\n",
    "\n",
    "# fill in any info from sixth (only 1 row with info)\n",
    "r1_2['Second'] = r1_2.loc[(~r1_2['Sixth'].isnull()), 'Sixth']\n",
    "\n",
    "# drop fifth and sixth columns\n",
    "r1_2.drop(['Fifth', 'Sixth'], axis=1, inplace=True)\n",
    "\n",
    "# some duplicate column names exist, find them\n",
    "sorted(r1_2.columns)\n",
    "# rename second column first_name\n",
    "# rename 1st year graduated undergrad_graduated and second med_graduated\n",
    "col_rename_dict = {\n",
    "    'First': 'first_name', 'Last': 'last_name', 'Middle': 'middle_name',\n",
    "    'First.1': 'honor_societies_first', 'Second': 'honor_societies_second', \n",
    "    'Third': 'honor_societies_third', 'Fourth': 'honor_societies_fourth',\n",
    "    'Year Graduated': 'undergrad_year_grad', 'Year Graduated.1': 'medschool_year_grad'\n",
    "}\n",
    "r1_2.rename(columns=col_rename_dict, inplace=True)\n",
    "r2_2.rename(columns=col_rename_dict, inplace=True)\n",
    "r3_2.rename(columns=col_rename_dict, inplace=True)\n",
    "# note that in data set r2 internship is spelled intership, correcting\n",
    "r1_2.rename(\n",
    "    columns={'Internship Year(s)': 'internship year(s)', 'Internship Hospital 1': 'internship hospital 1'}, inplace=True)\n",
    "r2_2.rename(\n",
    "    columns={'Intership Year(s)': 'internship year(s)', 'Intership Hospital 1': 'internship hospital 1'}, inplace=True)\n",
    "r3_2.rename(\n",
    "    columns={'Internship Year(s)': 'internship year(s)', 'Internship Hospital 1': 'internship hospital 1'}, inplace=True)\n",
    "# add reviewer column\n",
    "r1_2['reviewer'] = 1\n",
    "r2_2['reviewer'] = 2\n",
    "r3_2['reviewer'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# append the 2 data sets on top of each other, adding an indicator which reviewer they come from\n",
    "all_appcards = pd.concat([r1_2, r2_2, r3_2], axis=0)\n",
    "\n",
    "all_appcards2 = all_appcards.dropna(subset=['first_name', 'last_name'], axis=0, how='all')\n",
    "\n",
    "all_appcards2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# verify the lengths of pieces all up to len of new data set\n",
    "print(r1_2.shape[0] + r2_2.shape[0] + r3_2.shape[0] == all_appcards.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change all variable names to lowercase and insert _ instead of spaces\n",
    "def to_lower(str_var):\n",
    "    # lowercase, remove extraneous spaces, join with '_'\n",
    "    lower = str_var.lower()\n",
    "    return '_'.join(filter(None, lower.split(' ')))\n",
    "\n",
    "# apply column name cleaning fnc\n",
    "all_appcards2.columns = map(to_lower, all_appcards2.columns)\n",
    "\n",
    "# find and delete duplicate columns\n",
    "count = Counter(all_appcards2.columns)\n",
    "print count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_appcards3 = all_appcards2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_appcards4 = all_appcards3.reset_index(drop=False).rename(columns={'index': 'raw_uuid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add an id column to save raw data set\n",
    "str_cols = [c for c in all_appcards2.columns if all_appcards4.dtypes[c]!='float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_str(row_val):\n",
    "    if pd.isnull(row_val):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return str(row_val)\n",
    "    except UnicodeEncodeError:\n",
    "        return row_val.encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_year(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return pd.to_datetime(x).year\n",
    "    except ValueError:\n",
    "        print x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_appcards4['application_year'] = all_appcards4.application_date.apply(get_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_appcards4.loc[all_appcards4.last_name=='Aron', ['last_name', 'first_name', 'medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_appcards4.application_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_appcards4.reviewer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert unicode issues to string\n",
    "all_appcards4.loc[:, str_cols] = all_appcards4[str_cols].applymap(convert_to_str)\n",
    "\n",
    "all_appcards4.to_csv(os.path.join(CARD_DATA_DIR, 'raw_applicant_card_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
