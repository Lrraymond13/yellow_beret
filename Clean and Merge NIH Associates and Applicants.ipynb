{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in known applicant files, dedupe and try to merge with applicants file\n",
    "from collections import Counter\n",
    "import difflib\n",
    "import uuid\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import funcy\n",
    "import re\n",
    "import os\n",
    "\n",
    "from data_cleaning_functions import (trans_remov_punc, standardize_whitespace, remove_punc, remove_suffix_from_last_name,\n",
    "                                     clean_names, has_award, has_suffix, get_suffix, replace_last_name, \n",
    "                                     is_year_range, str_sim, clean_med_school, clean_std_college_name, long_form_date, \n",
    "                                    correct_mispellings, is_foreign_med_school, clean_med_school)\n",
    "\n",
    "from dev import (\n",
    "    APP_DATA_DIR, SUM_STAT_DIR, ATT_DATA_DIR, CARD_DATA_DIR, CORRECTIONS_DIR, AWARDS_KEYWORDS, NAME_COLS, RAW_NAME_COLS, \n",
    "    RAW_CARD_ID, RAW_INDEX_IDS, PERSON_APPLICATION_ID, PERSON_ID, NIH_ID, FEMALE_FIRST_NAMES, PICKLE_DIR)\n",
    "from merging_functions import *\n",
    "\n",
    "OUTPUT_CSV = False \n",
    "\n",
    "PERSONAL_INFO = [\n",
    "    'clean_first_name', 'clean_last_name', 'clean_middle_name',\n",
    "    'date_of_birth', 'medical_school', 'clean_college_trans']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# id column that links back to raw applicant data file\n",
    "RAW_CARD_ID = 'raw_uuid'\n",
    "\n",
    "# column where the raw id information is stored\n",
    "RAW_INDEX_IDS = 'raw_card_ids'\n",
    "\n",
    "# try to get one id per unique applicant in the dataset\n",
    "PERSON_ID = 'person_uuid'\n",
    "# id per deduped application-person - if someone applied multiple times, they will have multiple ids\n",
    "PERSON_APPLICATION_ID = 'person_app_uuid' \n",
    "NIH_ID = 'dno'\n",
    "\n",
    "APPLICANT_SUFFIX = '_ap'\n",
    "ATTENDEE_SUFFIX = '_at'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps_filename = 'index_cards_deduped_fuzzy.csv'\n",
    "# apps_filename = 'person_application_date_wide.csv'\n",
    "\n",
    "NIH_filename = 'unique_attendees.csv'\n",
    "# NIH_filename = 'NIH_attendee_deduped_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NAME_COLS = ['clean_first_name', 'clean_middle_name', 'clean_last_name'] \n",
    "\n",
    "MED_TRAINING_COLS = ['res_dates', 'intern_dates', 'residency_hospital', 'internship_hospital', 'medical_school', 'residency']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import NIH raw data set\n",
    "NIH_raw = pd.read_csv(os.path.join(ATT_DATA_DIR, NIH_filename)).drop_duplicates('dno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop from the data set all people with eod years > 1980\n",
    "# NIH = NIH_raw.loc[NIH_raw.eod_year<1980, :] \n",
    "NIH = NIH_raw\n",
    "del NIH['medical_school']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NIH['clean_medical_school'] = NIH.med_school.str.upper().str.strip().apply(clean_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import cleaned, deduped applicant data set in wide form (multiple app dates as columns)\n",
    "apps = pd.read_csv(os.path.join(APP_DATA_DIR, apps_filename))\n",
    "apps['medical_school'] = apps.original_medical_school.str.upper().str.strip().apply(clean_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps.loc[apps.clean_first_name=='HOWARD UNIVERSITY COLLEGE OF MEDICINE', 'clean_first_name'] = 'HOWARD'\n",
    "apps.loc[apps.clean_middle_name=='HOWARD UNIVERSITY COLLEGE OF MEDICINE', 'clean_middle_name'] = 'HOWARD'\n",
    "apps.loc[apps.clean_first_name=='STANFORD UNIVERSITY', 'clean_first_name'] = 'STANFORD'\n",
    "\n",
    "NIH.loc[NIH.clean_first_name=='HOWARD UNIVERSITY COLLEGE OF MEDICINE', 'clean_first_name']\n",
    "NIH.loc[NIH.clean_first_name=='STANFORD UNIVERSITY', 'clean_first_name'] = 'STANFORD'\n",
    "\n",
    "apps.loc[apps.clean_last_name=='MCCLURE MCCHURE', ['clean_last_name', 'last_name']] = ['MCCLURE', 'MCCLURE']\n",
    "apps.loc[apps.clean_last_name=='MCCHURE', ['clean_last_name', 'last_name']] = ['MCCLURE', 'MCCLURE']\n",
    "apps.loc[apps.clean_last_name=='MCCLURE', 'application_year'] = 1972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NIH.loc[NIH.clean_last_name=='YARNELL', ['clean_first_name', 'clean_middle_name']] = ['PHILIP', 'R']\n",
    "NIH.loc[NIH.clean_last_name=='YARNELL', ['NIH_first_name', 'NIH_middle_name']] = ['PHILIP', 'R']\n",
    "\n",
    "# need to correct some mispelled first names\n",
    "apps.loc[apps.clean_first_name=='WILEY', ['clean_first_name', 'first_name']] = ['WYLIE', 'WYLIE']\n",
    "apps.loc[apps.clean_first_name=='ANCELO', ['clean_first_name', 'first_name']]= ['ANGELO', 'ANGELO']\n",
    "apps.loc[apps.clean_first_name=='DOHN', ['clean_first_name', 'first_name']] = ['JOHN', 'JOHN']\n",
    "apps.loc[apps.clean_first_name=='MERION', ['clean_first_name', 'first_name']] = ['MERTON', 'MERTON']\n",
    "apps.loc[apps.clean_first_name=='NAHVM', ['clean_first_name', 'first_name']] = ['NAHUM', 'NAHUM']\n",
    "apps.loc[apps.clean_last_name=='PERPICH', ['clean_first_name', 'first_name']] = ['JOSEPH', 'JOSEPH']\n",
    "\n",
    "# replace MORTON's first name which is mistakenly John\n",
    "apps.loc[\n",
    "    apps.clean_last_name=='MORTON', 'clean_first_name'] = apps[\n",
    "        apps.clean_last_name=='MORTON']['first_name'].apply(lambda x: x.upper().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps.loc[apps.clean_last_name=='MORTON', NAME_COLS+['first_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps.loc[apps.clean_last_name=='COLLER', 'application_year'] = 1972\n",
    "\n",
    "apps.loc[apps.clean_last_name=='PERPICH', 'application_year'] = 1967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps.loc[:, 'res_dates'] = apps['residency_year(s)'].apply(long_form_date)\n",
    "\n",
    "apps.loc[:, 'intern_dates'] = apps['internship_year(s)'].apply(long_form_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NIH = NIH.rename(columns={'res_dtes':'res_dates', 'intern_dte':'intern_dates', 'intern_hos': 'internship_hospital', \n",
    "                         'res_hosp':'residency_hospital', 'clean_medical_school': 'medical_school'})\n",
    "# sorted(NIH.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps2 = apps.rename(\n",
    "    columns={'residency_type': 'residency', 'internship_hospital_1': 'internship_hospital'})\n",
    "\n",
    "string_med_cols = ['medical_school', 'residency_hospital', 'internship_hospital', 'residency']\n",
    "\n",
    "# apply string cleaning function to each of the string medical info columns\n",
    "apps2.loc[:, string_med_cols] = apps2[string_med_cols].applymap(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_remove = ['TERRECE', 'FRED', 'LAURENCE',\n",
    "             'CUONO', 'DEFRENZE', 'JEFFERY', 'FINKLEMAN', 'SHERRAD', 'ANSCHNETZ', 'MARC', 'JENSON', 'KASTI', \n",
    "            'ADELBERT', 'RITCHARD', 'MANSFORD', 'DEFRENZO', 'DROBIN', 'HAMES', 'KREUZ', 'JERROLD', 'MANEUSI',\n",
    "            'UNGARO']\n",
    "to_replace = ['TERRENCE', 'FREDERICK', 'LAWRENCE',\n",
    "              'CUOMO', 'DEFRONZO', 'JEFFREY', 'FINKELMAN', 'SHERRARD', 'ANSCHUETZ', 'MARCUS', 'JENSEN', 'KASTL',\n",
    "              'ALBERT', 'RITCHARD', 'MANIFORD', 'DEFRONZO', 'DROBIS', 'JAMES', 'KRUEZ', 'JERROD', 'MANCUSI',\n",
    "              'UNGARO']\n",
    "\n",
    "correct_name_mispellings_fnc = funcy.rpartial(correct_mispellings, to_remove, to_replace)\n",
    "\n",
    "apps2.loc[:, 'clean_last_name'] = apps2.clean_last_name.apply(correct_name_mispellings_fnc)\n",
    "apps2.loc[:, 'clean_first_name'] = apps2.clean_first_name.apply(correct_name_mispellings_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to go in and correct some of the name mispellings in both data sets\n",
    "# MUTATING FUNCTION\n",
    "def change_names(df, selection_type, selection_value, to_change_type, to_change_values):\n",
    "    for t, v in zip(to_change_type, to_change_values):\n",
    "        print t, v\n",
    "        sel = df.loc[df[selection_type]==selection_value, t]\n",
    "        print sel.shape[0]\n",
    "        if sel.shape[0] > 1:\n",
    "            print \"WARNING\"\n",
    "        df.loc[df[selection_type]==selection_value, t] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "apps2.loc[(apps2.clean_last_name=='LIBOW') & (apps2.clean_middle_name=='S'), 'clean_first_name'] = 'LESLIE'\n",
    "\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'CHESEBRO', ['clean_first_name', 'clean_middle_name'], ['BRUCE', 'WILCOX'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'GALANTER', ['clean_first_name', 'clean_middle_name'], ['MARC', 'I'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'BEAN', ['clean_first_name', 'clean_middle_name', 'medical_school'], ['SIDNEY', 'CHARLES', 'WAKE_FOREST'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'BOYD', ['clean_first_name', 'clean_middle_name'], ['MICHAEL', 'RAY'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'CHAPMAN', \n",
    "    ['clean_first_name', 'clean_middle_name', 'medical_school'], ['STANLEY', 'WILLETS', 'ROCHESTER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "change_names(apps2, 'clean_last_name', 'DANFORTH', ['clean_first_name', 'first_name'], ['DAVID', 'DAVID'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'HUNT', [\n",
    "        'clean_first_name', 'clean_middle_name', 'first_name', 'middle_name'], ['ROBERT', 'D', 'ROBERT', 'D'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'KARK', [\n",
    "        'clean_first_name', 'clean_middle_name', 'first_name', 'middle_name'], ['ROBERT', 'ADRIAN', 'ROBERT', 'ADRIAN'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'KEBABIAN', [\n",
    "        'clean_first_name', 'clean_middle_name','first_name', 'middle_name'], ['JOHN', 'WILLIS', 'JOHN', 'WILLIS'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'KNOPF', [\n",
    "        'clean_first_name', 'clean_middle_name', 'first_name', 'middle_name'], ['HARRY', 'LOUIS', 'HARRY', 'LOUIS'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'KROLIKOWSKI', [\n",
    "        'clean_first_name', 'clean_middle_name', 'first_name', 'middle_name'], ['FRANCIS', 'JOHN', 'FRANCIS', 'JOHN'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'KASTL', [\n",
    "        'clean_first_name', 'clean_middle_name', 'first_name', 'middle_name'], ['DAVID', 'GENE', 'DAVID', 'GENE'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'KLAVEMAN', ['clean_last_name', 'last_name'], ['KLAEVEMAN', 'KLAEVEMAN'])\n",
    "change_names(\n",
    "    apps2, 'clean_last_name', 'MATHEW', ['clean_last_name', 'last_name'], ['MATTHEW', 'MATTHEW'])\n",
    "\n",
    "apps2.loc[apps2.clean_last_name=='CHESEBRO', ['clean_first_name', 'first_name']] = ['BRUCE', 'BRUCE']\n",
    "apps2.loc[apps2.clean_last_name=='CHESEBRO', ['clean_middle_name', 'middle_name']] = ['WILCOX', 'WILCOX']\n",
    "apps2.loc[\n",
    "    (apps2.clean_last_name=='HEALY') & (\n",
    "        apps2.medical_school=='USC KECK SCHOOL OF MEDICINE'), ['clean_first_name', 'first_name']] = ['MARK', 'MARK']\n",
    "apps2.loc[\n",
    "    (apps2.clean_last_name=='HEALY') & (\n",
    "        apps2.medical_school=='USC KECK SCHOOL OF MEDICINE'), ['clean_middle_name', 'middle_name']] = ['H', 'H']\n",
    "\n",
    "apps2.loc[apps2.clean_last_name=='LENN', ['clean_first_name', 'first_name']] = ['NICHOLAS', 'NICHOLAS']\n",
    "apps2.loc[\n",
    "        apps2.clean_last_name=='BRESLOW', [\n",
    "            'clean_first_name', 'first_name', 'clean_middle_name', 'middle_name']] = ['JAN', 'JAN', 'LESLIE', 'LESLE']\n",
    "\n",
    "apps2.loc[\n",
    "        (apps2.clean_last_name=='NADLER') & (\n",
    "            pd.isnull(apps2.clean_first_name)), [\n",
    "                'clean_first_name', 'first_name', 'clean_middle_name', 'middle_name']] = ['LEE', 'LEE', 'MARSHALL', 'MARSHALL']\n",
    "apps2.loc[\n",
    "        (pd.isnull(apps2.clean_first_name)) & (\n",
    "            apps2.clean_last_name=='ROSEN'), ['clean_first_name', 'first_name']] = ['HENRY', 'HENRY']\n",
    "\n",
    "apps2.loc[\n",
    "        (apps2.clean_last_name=='NEELON'), [\n",
    "            'first_name', 'clean_first_name', 'clean_middle_name', 'middle_name']] = ['FRANCIS', 'FRANCIS', 'ALBERT', 'ALBERT']\n",
    "\n",
    "apps2.loc[(apps2.clean_last_name=='NICHOLAS') , ['first_name', 'clean_first_name']] = ['JOHN', 'JOHN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps2.loc[(apps2.clean_last_name=='KEBIAN') , 'clean_last_name'] = 'KEBABIAN'\n",
    "apps2.loc[(apps2.clean_last_name=='KEBABIAN') , 'last_name'] = 'KEBABIAN'\n",
    "apps2.loc[((apps2.clean_last_name=='FENSTER')&(apps2.clean_first_name=='FREDERICK')) , 'clean_first_name'] = 'L'\n",
    "apps2.loc[((apps2.clean_last_name=='FENSTER')&(apps2.clean_first_name=='L')) , 'first_name'] = 'L'\n",
    "apps2.loc[\n",
    "    ((apps2.clean_last_name=='ALFORD')&(\n",
    "            apps2.clean_first_name=='ROBERT')) , ['middle_name', 'clean_middle_name']] = ['H', 'H']\n",
    "apps2.loc[((apps2.clean_last_name=='KASHIMA')&(apps2.clean_first_name=='HASKINS')) , 'clean_middle_name'] = 'K'\n",
    "apps2.loc[((apps2.clean_last_name=='KASHIMA')&(apps2.clean_first_name=='HASKINS')) , 'middle_name'] = 'K'\n",
    "apps2.loc[((apps2.clean_middle_name=='SAMMUEL')) , 'clean_middle_name'] = 'SAMUEL'\n",
    "apps2.loc[\n",
    "    ((apps2.clean_last_name=='MANEUSI UNQARO')) , ['last_name', 'clean_last_name']] = ['MANEUSI UNGARO', 'MANEUSI UNGARO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NIH.loc[\n",
    "    (NIH.clean_last_name=='ALEXANDER') & (\n",
    "        NIH.clean_first_name=='JOHN'), ['NIH_middle_name', 'clean_middle_name']] = ['CHARLES', 'CHARLES']\n",
    "\n",
    "NIH.loc[\n",
    "    (NIH.clean_last_name=='LEBOWITZ') & (\n",
    "        NIH.clean_first_name=='EDWARD ARTHUR'), [\n",
    "            'clean_first_name', 'NIH_first_name', 'clean_middle_name', 'NIH_middle_name']] = ['EDWARD', 'EDWARD', 'ARTHUR', 'ARTHUR']\n",
    "NIH.loc[(\n",
    "        NIH.clean_last_name=='LEBOWITZ') & (\n",
    "            NIH.clean_first_name=='EDWARD'), 'medical_school'] = 'ALBERT EINSTEIN COLLEGE OF MEDICINE OF YESHIVA'\n",
    "\n",
    "NIH = NIH.loc[NIH.clean_first_name!='GERALDINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# there are a bunch of duplicates in apps, where application year is the same, but first name is missing\n",
    "name_dups = apps2.loc[\n",
    "    apps2.duplicated(\n",
    "        ['clean_last_name', 'medical_school', 'application_year'], keep=False), NAME_COLS+[PERSON_ID, 'medical_school', 'application_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_delete_ids = name_dups.loc[(pd.isnull(name_dups.clean_middle_name)) & (pd.isnull(name_dups.clean_first_name))\n",
    "                             & pd.isnull(name_dups.medical_school), PERSON_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps4 = apps2.loc[~apps2[PERSON_ID].isin(to_delete_ids), :].sort_values(\n",
    "    NAME_COLS+['medical_school'], ascending=False).drop_duplicates(NAME_COLS+['medical_school'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print apps4.shape\n",
    "print apps2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in manual matches\n",
    "man = pd.read_excel(os.path.join(CORRECTIONS_DIR, 'manual_dno_matches.xlsx'), index=False).rename(columns={'medical_school': 'dno_medical_school'})\n",
    "man['medical_school'] = man.dno_medical_school.apply(clean_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = pd.merge(left=apps4, right=man, on=['clean_last_name', 'clean_middle_name'], how='inner', suffixes=['_x', '_y'])\n",
    "print t.shape\n",
    "\n",
    "t['sim'] = t[['medical_school_x', 'medical_school_y']].apply(get_name_str_sim, axis=1)\n",
    "\n",
    "t['clean_first_name'] = t['clean_first_name_y']\n",
    "\n",
    "t_1 = t.sort_values(['dno', 'sim'], ascending=False).drop_duplicates(['dno'], keep='first')\n",
    "\n",
    "# t[NAME_COLS+['dno', 'medical_school_x', 'medical_school_y', 'sim']]\n",
    "t_1.loc[t_1.duplicated('dno', keep=False), NAME_COLS+['dno', 'medical_school_x', 'medical_school_y', 'sim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps4.loc[(apps4.clean_last_name=='COHEN') & (apps4.clean_first_name=='HARVEY'), NAME_COLS+['medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.loc[t.clean_last_name=='COHEN', NAME_COLS+['first_name', 'sim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "um = man[~man.dno.isin(t_1.dno)]\n",
    "\n",
    "um.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# t2 = pd.merge(left=apps4, right=um, on=['clean_last_name', 'clean_first_name'], how='inner', suffixes=['_x', '_y'])\n",
    "# print t2.shape\n",
    "# print um.shape\n",
    "\n",
    "# t2['sim'] = t2[['medical_school_x', 'medical_school_y']].apply(get_name_str_sim, axis=1)\n",
    "\n",
    "# t2['clean_middle_name'] = t2['clean_middle_name_y']\n",
    "\n",
    "# t2_1 = t2.sort_values(['dno', 'sim'], ascending=False).drop_duplicates(['dno'], keep='first')\n",
    "# t2_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t3 = t_1[NAME_COLS+['dno', PERSON_ID]]\n",
    "# t3 = pd.concat([t2_1[NAME_COLS+['dno', PERSON_ID]], t_1[NAME_COLS+['dno', PERSON_ID]]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "man_dno = pd.merge(left=apps4, right=t3, on=PERSON_ID, how='left', suffixes=['_x', '_y'])\n",
    "print man_dno.shape\n",
    "print t3.shape\n",
    "print man.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask = ~pd.isnull(man_dno.clean_last_name_y)\n",
    "man_dno = man_dno.rename(columns={'clean_last_name_x': 'clean_last_name', 'clean_first_name_x': 'clean_first_name', \n",
    "                       'clean_middle_name_x': 'clean_middle_name'})\n",
    "mask = ~pd.isnull(man_dno.clean_last_name_y)\n",
    "man_dno.loc[mask, 'clean_last_name'] = man_dno.loc[mask, 'clean_last_name_y']\n",
    "mask = ~pd.isnull(man_dno.clean_first_name_y)\n",
    "man_dno.loc[mask, 'clean_first_name'] = man_dno.loc[mask, 'clean_first_name_y']\n",
    "mask = ~pd.isnull(man_dno.clean_middle_name_y)\n",
    "man_dno.loc[mask, 'clean_middle_name'] = man_dno.loc[mask, 'clean_middle_name_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps5 = man_dno.loc[pd.isnull(man_dno['dno']), :].drop(['dno', 'clean_middle_name_y', 'clean_first_name_y', 'clean_last_name_y'], axis=1) \n",
    "has_dno = man_dno.loc[~pd.isnull(man_dno['dno']), NAME_COLS+['dno', 'person_uuid']] \n",
    "# apps5 = man_dno.drop(['dno', 'clean_middle_name_y', 'clean_first_name_y', 'clean_last_name_y'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mark femalse\n",
    "NIH['is_female'] = 0\n",
    "female_mask = (NIH.clean_first_name.isin(FEMALE_FIRST_NAMES))  \n",
    "NIH.loc[female_mask, 'is_female'] = 1\n",
    "\n",
    "\n",
    "apps5['is_female'] = 0\n",
    "female_mask = (apps5.clean_first_name.isin(FEMALE_FIRST_NAMES))  \n",
    "apps5.loc[female_mask, 'is_female'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NIH.loc[NIH.clean_first_name=='ASHLEY', NAME_COLS]\n",
    "apps5.loc[apps5.clean_first_name=='JULES', NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_first_letter(str_var):\n",
    "    if pd.isnull(str_var) or str_var=='':\n",
    "        return np.nan\n",
    "    return str_var[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NIH['clean_first_initial'] = NIH.clean_first_name.apply(get_first_letter)\n",
    "NIH['clean_middle_initial'] = NIH.clean_middle_name.apply(get_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print NIH.shape\n",
    "print  apps5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# After cleaning apps2 to match cleaning in Clean NIH Applicant notebook, we try to start merging\n",
    "sims_cols = ['medical_school_sim', 'clean_middle_name_sim', 'clean_first_name_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NIH['fuzzy_merge_col'] = NIH[\n",
    "    ['clean_first_name', 'clean_middle_name', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "apps5['fuzzy_merge_col'] = apps5[\n",
    "    ['clean_first_name', 'clean_middle_name', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "match1 = df_get_closest_matches(apps5, NIH, 'fuzzy_merge_col', suffixes=['_x', '_y']) \n",
    "print match1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add last name counter to each\n",
    "app_counter = Counter(apps4.clean_last_name.values)\n",
    "NIH_counter = Counter(NIH.clean_last_name.values)\n",
    "match1['last_name_counts_x'] = match1.clean_last_name_x.apply(lambda x: app_counter[x])\n",
    "match1['last_name_counts_y'] = match1.clean_last_name_y.apply(lambda x: NIH_counter[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_match(row):\n",
    "    # address and application year match\n",
    "    app_eod_year_diff = abs(row['application_year'] - row['eod_year'])\n",
    "    if row['is_female_x'] != row['is_female_y']:\n",
    "        return 0\n",
    "    if row['clean_last_name_sim'] < 90 or app_eod_year_diff > 8:\n",
    "        return 0\n",
    "    if not pd.isnull(row['medical_school_sim']) and row['medical_school_sim'] < 90:\n",
    "        # drop people with no medical school similarity\n",
    "        return 0\n",
    "    if not pd.isnull(row['clean_first_name_sim']) and row['clean_first_name_sim'] < 80:\n",
    "        return 0\n",
    "    # the first and middle name seem to be mixed up in index card data set\n",
    "    mixed_sim1 =  get_name_str_sim(row[['clean_middle_name_x', 'clean_first_name_y']])\n",
    "    mixed_sim2 =  get_name_str_sim(row[['clean_middle_name_y', 'clean_first_name_x']])\n",
    "    mix_sim = max(mixed_sim1, mixed_sim2)\n",
    "    if pd.isnull(mix_sim):\n",
    "        mix_sim = 0\n",
    "    if (mix_sim > 90) and row['medical_school_sim'] > 90:\n",
    "        return 1\n",
    "    if row['last_name_counts_x'] < 2 and row['last_name_counts_y'] < 2:\n",
    "        return 1\n",
    "    if (mix_sim > 90) and pd.isnull(row['medical_school_sim']) and (app_eod_year_diff < 5):\n",
    "        return 1\n",
    "    # if matching application year and med schools match\n",
    "    if (app_eod_year_diff < 5) and row['medical_school_sim'] > 80:\n",
    "        return 1\n",
    "    # first and middle names match or first\n",
    "    if (app_eod_year_diff < 5) and row['clean_first_name_sim'] > 80:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "feature_dict = {\n",
    "    'clean_first_name': get_name_str_sim,\n",
    "    'clean_middle_name': get_name_str_sim,\n",
    "    'clean_last_name': get_name_str_sim,\n",
    "    'medical_school': get_name_str_sim,\n",
    "}\n",
    "\n",
    "match2 = add_similarity_features(match1, feature_dict, check_match, suffixes=['_x', '_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select out people who match and make sure each person id and dno only 1x in data set\n",
    "match3 = match2[match2.is_match==1].sort_values(['clean_last_name_x']+sims_cols, ascending=False).dropna(\n",
    "    axis=0, subset=[RAW_CARD_ID])\n",
    "print match3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def filter_one_match_per_group(df, dedupe_col, sim_cols):\n",
    "    # to merge cols should be a dict the names of the extra cols to merge in\n",
    "    # values should be col names to rename\n",
    "    # sim cols should be name of the columns to use as features\n",
    "    # sim mask should be mask that accounts as actual mask\n",
    "    # dedupe col is name of col to dedupe on\n",
    "\n",
    "    def count_matches(id_list_arr):\n",
    "        # for each id, make sure matched on 1x in data set\n",
    "        # should be applied with rolling apply so takes in a dataframe and must return single value\n",
    "        # unpack already matched ids from string\n",
    "        current_id1 = id_list_arr[-1]\n",
    "        other_matches = id_list_arr[:-1]\n",
    "        is_dup = np.any(other_matches[:] == current_id1)\n",
    "        if is_dup:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # for each uuid, check for duplicates and choose best match based on sim cols\n",
    "    # order of the sim cols should be with most important first\n",
    "    dup_flag = '{}_duplicate'.format(dedupe_col)\n",
    "    df[dup_flag] = 0\n",
    "    df.loc[:, dup_flag] = df[\n",
    "        dedupe_col].expanding(center=False, min_periods=0).apply(func=count_matches)\n",
    "\n",
    "    df_matches = df[df['is_match'] == 1].sort_values([dedupe_col] + sim_cols, ascending=False)\n",
    "    return df_matches.drop_duplicates([dedupe_col], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match4 = filter_one_match_per_group(match3, 'raw_uuid', sims_cols)\n",
    "print match4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match5 = filter_one_match_per_group(match4, NIH_ID, sims_cols)\n",
    "print match5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match5.loc[match5.clean_last_name_x=='BRADEN', ['medical_school_y', 'medical_school_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get nonmatched NIH people and not matched applicants \n",
    "nm_apps = get_nonmatched(apps5, id_colname=RAW_CARD_ID, matched_ids=match5[RAW_CARD_ID].dropna().values)\n",
    "nm_NIH = get_nonmatched(NIH, id_colname=NIH_ID, matched_ids=match5[NIH_ID].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do another round of matching just on last name\n",
    "nm_match1 = df_get_closest_matches(nm_apps, nm_NIH, 'clean_last_name', suffixes=['_x', '_y']) \n",
    "print nm_match1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_match(row):\n",
    "    app_eod_year_diff = abs(row['application_year'] - row['eod_year'])\n",
    "    if app_eod_year_diff > 8:\n",
    "        return 0\n",
    "    if row['is_female_x'] != row['is_female_y']:\n",
    "        return 0\n",
    "    if not pd.isnull(row['medical_school_sim']) and row['medical_school_sim'] < 80:\n",
    "        return 0\n",
    "    # the first and middle name seem to be mixed up in index card data set\n",
    "    mixed_sim1 =  get_name_str_sim(row[['clean_middle_name_x', 'clean_first_name_y']])\n",
    "    mixed_sim2 =  get_name_str_sim(row[['clean_middle_name_y', 'clean_first_name_x']])\n",
    "    \n",
    "    max_name_sim = max(row['clean_first_name_sim'], row['medical_school_sim'], row['clean_middle_name_sim'])\n",
    "    if max_name_sim < 80:\n",
    "        return 0\n",
    "    mix_sim = max(mixed_sim1, mixed_sim2)\n",
    "    if pd.isnull(mix_sim):\n",
    "        mix_sim = 0\n",
    "    if (mix_sim > 90) and row['medical_school_sim'] > 90:\n",
    "        return 1\n",
    "    if (mix_sim > 90) and pd.isnull(row['medical_school_sim']) and (app_eod_year_diff < 6):\n",
    "        return 1\n",
    "    if not pd.isnull(row['clean_first_name_sim']) and row['clean_first_name_sim'] < 70:\n",
    "        return 0\n",
    "    # if matching application year and med schools match\n",
    "    if (app_eod_year_diff < 6) and row['medical_school_sim'] > 90:\n",
    "        return 1\n",
    "    # first and middle names match or first\n",
    "    if (app_eod_year_diff < 6) and row['clean_first_name_sim'] > 90:\n",
    "        return 1\n",
    "    # first and middle names match or first\n",
    "    if (app_eod_year_diff < 6) and row['clean_middle_name_sim'] > 90:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nm_feature_dict = {\n",
    "    'clean_first_name': get_name_str_sim,\n",
    "    'clean_middle_name': get_name_str_sim,\n",
    "    'medical_school': get_name_str_sim,\n",
    "}\n",
    "\n",
    "nm_match2 = add_similarity_features(nm_match1, nm_feature_dict, check_match, suffixes=['_x', '_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nm_match3 = nm_match2.loc[(nm_match2.is_match==1) & (nm_match2.index!='MORTON'), :].reset_index(\n",
    "    drop=False).rename(columns={'index': 'clean_last_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print nm_match3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge the manual people with dno with the dno data set and append to the matches list\n",
    "man_dno2 = man_dno.loc[~pd.isnull(man_dno['dno']), :].drop(['clean_first_name_y', 'clean_middle_name_y',\n",
    "                                                            'clean_last_name_y'], axis=1)\n",
    "man_dno2.loc[:, 'dno'] = man_dno2.dno.astype(int)\n",
    "NIH.loc[:, 'dno'] = NIH.dno.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "man_dno2.loc[man_dno2.clean_last_name=='COHEN', NAME_COLS+['first_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print man_dno2.shape\n",
    "man_dno_merge = pd.merge(left=man_dno2, right=NIH, on='dno', how='inner')\n",
    "print man_dno_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stewart and sherwin have eod years outside range\n",
    "man_dno2.loc[~man_dno.dno.isin(man_dno_merge.dno), NAME_COLS+['dno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "man_dno_merge2 = man_dno_merge.rename(columns={'clean_first_name_x': 'clean_first_name2', \n",
    "                                               'clean_middle_name_x': 'clean_middle_name2',\n",
    "                             'clean_last_name_x': 'clean_last_name2'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "man_dno_merge2.loc[man_dno_merge2.clean_last_name_y=='COHEN', NAME_COLS+['first_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fails = man_dno2.loc[~man_dno2.dno.isin(man_dno_merge.dno), :]\n",
    "print fails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# append matches together\n",
    "match6 = pd.concat([nm_match3, match5, man_dno_merge2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get nonmatched NIH people and not matched applicants \n",
    "nm_apps2 = get_nonmatched(apps5, id_colname=RAW_CARD_ID, matched_ids=match6[RAW_CARD_ID].dropna().values)\n",
    "nm_NIH2 = get_nonmatched(NIH, id_colname=NIH_ID, matched_ids=match6[NIH_ID].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nm_NIH3 = nm_NIH2.loc[\n",
    "    (nm_NIH2.eod_year< 1976) & (\n",
    "        nm_NIH2.eod_year>1963), NAME_COLS+['medical_school', 'eod_year']].sort_values('clean_last_name')\n",
    "print nm_NIH3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apps_match = nm_apps2.loc[nm_apps2.clean_last_name.isin(nm_NIH3.clean_last_name.values)]\n",
    "test_merge = pd.merge(left=nm_NIH3, right=apps_match, on='clean_last_name', how='inner').sort_values('clean_last_name')\n",
    "test_merge = test_merge[sorted(test_merge.columns)]\n",
    "if OUTPUT_CSV:\n",
    "    test_merge.to_csv(os.path.join(CORRECTIONS_DIR, 'test_merge_missing_NIH.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match6.loc[pd.isnull(match6.clean_last_name), 'clean_last_name'] =  match6.loc[\n",
    "    pd.isnull(match6.clean_last_name), 'clean_last_name_x']\n",
    "to_drop = [c for c in match6.columns if c.endswith('_sim') or '_counts' in c]\n",
    "match7= match6.drop(to_drop+[\n",
    "        'dup_flag', 'eod_year_diff', 'fuzzy_merge_col_x', 'fuzzy_merge_col_y', 'unknown',\n",
    "        'Unnamed: 0', 'raw_uuid_duplicate', 'dno_duplicate', 'count_missing',\n",
    "                'clean_last_name_x', 'clean_last_name_y', 'is_match'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# consolidate columns in match6\n",
    "match7a = consolidate_merge_cols(match7, ['_x', '_y'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(match7a.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match7a.loc[match7a.med_school.str.upper()!=match7a.medical_school, NAME_COLS+['med_school', 'medical_school', 'original_medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps.loc[apps.clean_last_name=='MORTON', NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask = ~pd.isnull(match7a.clean_first_name2)\n",
    "match7a.loc[mask, 'clean_first_name'] = match7a.loc[mask, 'clean_first_name2']\n",
    "\n",
    "mask = ~pd.isnull(match7a.clean_last_name2)\n",
    "match7a.loc[mask, 'clean_last_name'] = match7a.loc[mask, 'clean_last_name2']\n",
    "\n",
    "mask = ~pd.isnull(match7a.clean_middle_name2)\n",
    "match7a.loc[mask, 'clean_middle_name'] = match7a.loc[mask, 'clean_middle_name2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match8 = pd.concat([\n",
    "        man_dno[~pd.isnull(man_dno['dno'])], match7a, apps4.loc[\n",
    "            ~apps4[PERSON_ID].isin(match7a[PERSON_ID].values),:]], axis=0).drop(['clean_first_name2', \n",
    "                                                                                'clean_middle_name2', \n",
    "                                                                                'clean_last_name2'], axis=1)\n",
    "print match8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# replace date of birth with dob whenever date of birth missing and dob is not\n",
    "match8.loc[\n",
    "    (pd.isnull(match8['date_of_birth'])) & (~pd.isnull(match8['dob'])), 'date_of_birth'] = match8.loc[\n",
    "        (pd.isnull(match8['date_of_birth'])) & (~pd.isnull(match8['dob'])), 'dob']\n",
    "\n",
    "\n",
    "c1 = 'date_of_birth'\n",
    "c2 = 'dob'\n",
    "match8.loc[(pd.isnull(match8[c1])) & (~pd.isnull(match8[c2])), [c1, c2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match8.loc[(match8.clean_last_name=='KNOWLER') & (match8.clean_first_name=='JAN'), 'dno'] = 1922\n",
    "match8.loc[\n",
    "    (match8.clean_last_name== 'E ROSS HARVARD') & (match8.clean_first_name=='MICHAEL'), 'clean_last_name'] = 'ROSS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match9 = match8.drop(['dob'], axis=1).reset_index(drop=True).sort_values(\n",
    "    NAME_COLS+['dno']).drop_duplicates(NAME_COLS+['dno']).drop_duplicates(NAME_COLS+[PERSON_ID])\n",
    "# print sorted(match9.columns)\n",
    "print match8.shape\n",
    "print match9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for dno duplicates \n",
    "dups_dno = match9.loc[(~pd.isnull(match9.dno)) & (\n",
    "        match9.duplicated('dno', keep=False)), NAME_COLS+['dno', PERSON_ID, 'medical_school']]\n",
    "\n",
    "dups_merge = pd.merge(\n",
    "    left=dups_dno, right=NIH.loc[NIH.dno.isin(dups_dno.dno), NAME_COLS+['dno', 'medical_school']], on=['dno'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sim_score(row):\n",
    "    sim_cols = NAME_COLS + ['medical_school']\n",
    "    sims = []\n",
    "    for col in sim_cols:\n",
    "        sim_1 = get_name_str_sim(row[['{}_x'.format(col), '{}_y'.format(col)]])\n",
    "        sims.append(sim_1)\n",
    "    return np.mean(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups_merge['sim'] = dups_merge.apply(get_sim_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups_merge = dups_merge.sort_values(['dno', 'sim'], ascending=False).rename(columns={'dno':'old_dno'})\n",
    "dups_merge['dno'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_match = dups_merge.groupby('old_dno').first().person_uuid.values\n",
    "print len(best_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = (dups_merge.sim > 94) & (dups_merge.person_uuid.isin(best_match))\n",
    "print sum(mask)\n",
    "dups_merge.loc[mask, 'dno'] = dups_merge[mask]['old_dno']\n",
    "# match9.loc[(~pd.isnull(match9.clean_first_name_y)), ['clean_first_name', 'clean_first_name_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dups_merge.loc[dups_merge.dno==dups_merge.old_dno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset duplicates to null\n",
    "match9.loc[match9.person_uuid.isin(dups_merge.loc[dups_merge['dno']==0, PERSON_ID]), 'dno'] = np.nan\n",
    "\n",
    "match9.loc[match9.person_uuid==35, NAME_COLS+[PERSON_ID, 'dno']]\n",
    "\n",
    "match9.loc[(match9.duplicated('dno', keep=False) & (~pd.isnull(match9.dno))), NAME_COLS+['dno', PERSON_ID]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to check we haven't created amy frankenstein matches\n",
    "# ie. people who shouldn't really match together\n",
    "# get a\n",
    "match9.loc[(~pd.isnull(match9.first_name) & (\n",
    "    match9.clean_first_name!=match9.first_name.str.upper())), NAME_COLS+['first_name', 'middle_name', 'last_name', 'med_school', 'original_medical_school',\n",
    "                                                                        'NIH_first_name', 'NIH_middle_name', 'NIH_last_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9.is_female.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add an international applicant flag\n",
    "# also drop anyone missing first, middle names and med school\n",
    "match9['is_foreign'] = 0\n",
    "match9.loc[:, 'is_foreign'] = match9.medical_school.apply(is_foreign_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9.is_foreign.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match9['control_flag'] = 0\n",
    "match9.loc[pd.isnull(match9.dno) & pd.isnull(match9.year_accepted), 'control_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9.loc[pd.isnull(match9.application_year), 'application_year'] = match9.loc[\n",
    "    pd.isnull(match9.application_year), 'application_year_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_number_applications(app_years):\n",
    "    unique_apps_years = app_years.dropna().unique()\n",
    "    return unique_apps_years.shape[0]\n",
    "\n",
    "match9['number_applications'] = match9[\n",
    "    ['application_year', 'application_year_1', 'application_year_2', 'application_year_3']].apply(\n",
    "        total_number_applications, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def applications_max_min(app_years, fnc):\n",
    "    unique_apps_years = app_years.dropna().unique()\n",
    "    if unique_apps_years.shape[0] == 0:\n",
    "        print app_years\n",
    "        return np.nan\n",
    "    return fnc(unique_apps_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9['application_year_max'] = match9[\n",
    "    ['application_year', 'application_year_1', 'application_year_2', 'application_year_3']].apply(\n",
    "        funcy.rpartial(applications_max_min, max), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9['application_year_min'] = match9[\n",
    "    ['application_year', 'application_year_1', 'application_year_2', 'application_year_3']].apply(\n",
    "        funcy.rpartial(applications_max_min, min), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9['time_period_flag'] = 0\n",
    "match9.loc[(match9.application_year_max>1964) & (match9.application_year_max<1976), 'time_period_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# match9A.loc[(match9A.clean_last_name=='MCCHURE') & (pd.isnull(match9A.clean_first_name))]]\n",
    "match9.loc[match9.clean_last_name=='MCCLURE MCCHURE', 'clean_last_name'] = 'MCCLURE'\n",
    "match9.loc[match9.clean_last_name=='PERPICH', 'application_year'] = 1967\n",
    "match9.loc[match9.clean_last_name=='PERPICH', 'application_year_min'] = 1967\n",
    "match9.loc[match9.clean_last_name=='PERPICH', 'application_year_max'] = 1967\n",
    "mathch9 = match9[match9.clean_last_name!='BRADEN R']\n",
    "match9_1 = match9[~((match9.clean_last_name=='BULKEY') & (match9.clean_first_name=='GREGORY'))]\n",
    "match9_2 = match9_1[~((match9_1.clean_last_name=='KNOWLER') & (match9_1.clean_first_name=='JAN'))]\n",
    "match9_3 = match9_2[~((match9_2.clean_last_name=='COLLIN') & (match9_2.clean_first_name=='ROBERT'))]\n",
    "match9_4 = match9_3[~((match9_3.clean_last_name=='BULLARD') & (match9_3.clean_first_name=='BRIAN'))]\n",
    "# CHESEBRE, COLDBERG, Robert Collin, DIEZMAN, GLASSROBTH, HUGH HAYWOOD, Bart Kentover, jan knowler, robert jeffery kramer\n",
    "# SAIRAI, william sullivan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix some \n",
    "match9_4.loc[(\n",
    "        match9_4.clean_first_name=='WILLIAM') & (match9_4.clean_middle_name=='WILLIAM') & \n",
    "             (match9_4.clean_last_name=='SULLIVAN'), 'clean_middle_name'] = np.nan\n",
    "\n",
    "match9_4.loc[match9_4.clean_middle_name=='JEFFERY', 'clean_middle_name'] = 'JEFFREY'\n",
    "match9_4.loc[match9_4.clean_last_name=='GLASSROBTH', 'clean_last_name'] = 'GLASSROTH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name corrections\n",
    "match9_4.loc[((match9_4.clean_first_name=='ALBERT') & (match9_4.first_name=='Adelbert')), 'clean_first_name'] = 'ADELBERT'\n",
    "match9_4.loc[((match9_4.clean_first_name=='BENJAMIN') & (match9_4.clean_last_name=='CAHAN')), 'clean_first_name'] = 'LESLIE'\n",
    "match9_4.loc[((match9_4.clean_first_name=='GEORGES')), 'clean_first_name'] = 'GEORGE'\n",
    "match9_4.loc[((match9_4.clean_first_name=='JACKS')), 'clean_first_name'] = 'JACK'\n",
    "match9_4.loc[((match9_4.clean_first_name=='HAVERY')), 'clean_first_name'] = 'HARVEY'\n",
    "match9_4.loc[((match9_4.clean_first_name=='LAWRENCE') & (match9_4.first_name=='Laurence')), 'clean_first_name'] = 'LAURENCE'\n",
    "match9_4.loc[((match9_4.clean_first_name=='PHILLIP') & (match9_4.first_name=='Philip')), 'clean_first_name'] = 'PHILIP'\n",
    "match9_4.loc[((match9_4.clean_first_name=='FREDERIC') & (match9_4.clean_last_name=='MUSHINSKI')), 'clean_middle_name'] = 'COSTEP'\n",
    "# name corrections\n",
    "match9_4.loc[((match9_4.clean_first_name=='ALBERT') & (match9_4.first_name=='Adelbert')), 'clean_first_name'] = 'ADELBERT'\n",
    "match9_4.loc[((match9_4.clean_first_name=='BENJAMIN') & (match9_4.clean_last_name=='CAHAN')), 'clean_first_name'] = 'LESLIE'\n",
    "match9_4.loc[((match9_4.clean_first_name=='GEORGES')), 'clean_first_name'] = 'GEORGE'\n",
    "match9_4.loc[((match9_4.clean_first_name=='JACKS')), 'clean_first_name'] = 'JACK'\n",
    "match9_4.loc[((match9_4.clean_first_name=='HAVERY')), 'clean_first_name'] = 'HARVEY'\n",
    "match9_4.loc[((match9_4.clean_first_name=='LAWRENCE') & (match9_4.first_name=='Laurence')), 'clean_first_name'] = 'LAURENCE'\n",
    "match9_4.loc[((match9_4.clean_first_name=='PHILLIP') & (match9_4.first_name=='Philip')), 'clean_first_name'] = 'PHILIP'\n",
    "match9_4.loc[((match9_4.clean_first_name=='FREDERIC') & (match9_4.clean_last_name=='MUSHINSKI')), 'clean_middle_name'] = 'COSTEP'\n",
    "match9_4.loc[((match9_4.clean_first_name=='STANLEY') & (match9_4.clean_last_name=='SHERWIN')), 'clean_first_name'] = 'ROBERT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = ['PERPICH',  'BRADEN', 'BRADEN R', 'BULKEY', 'BULKLEY', \n",
    "       'CHESEBRE', 'COLDBERG', 'COLLIN', 'DIEZMAN', 'DIETZMAN', 'GLASSROBTH', \n",
    "        'GLASSROTH', 'HAYWARD', 'HAYWOOD', 'MCCLURE MCCHURE', 'MCCLURE', 'MCCHURE',\n",
    "       'KETOVER', 'KENTOVER', 'KNOWLER', 'KRAMER', 'SARAI', 'SARAL', 'SARAL', 'SULLIVAN', 'COLLINS', \n",
    "       'KOEHLER']\n",
    "match9_4.loc[match9_4.clean_last_name.isin(test), NAME_COLS+['medical_school']].sort_values('clean_last_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete people missing first and middle names\n",
    "print match9_4.shape\n",
    "match9A = match9_4.loc[~((pd.isnull(match9_4.clean_first_name) & pd.isnull(match9_4.clean_middle_name))), :]\n",
    "match9A2 = match9A.loc[~(\n",
    "        (match9A.medical_school=='UNIVERSITY OF MINNESOTA MEDICAL SCHOOL DULUTH') & (\n",
    "            match9A.clean_last_name=='PERPICH')), :]\n",
    "match9A3 = match9A2.loc[~((pd.isnull(match9A2.clean_first_name) & (match9A2.clean_last_name=='MCCHURE'))), :]\n",
    "match9A4 = match9A3.loc[~(\n",
    "        (match9A3.clean_first_name==match9A3.clean_middle_name) & (match9A3.clean_last_name=='BROWER')), :]\n",
    "match9B = match9A4.loc[~pd.isnull(match9A4.application_year_min), :]\n",
    "print match9A.shape\n",
    "print match9B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9A2.loc[pd.isnull(match9A2.application_year_min), NAME_COLS+['application_year_min', 'medical_school', 'application_year']]\n",
    "match9B.loc[match9B.clean_last_name=='PERPICH', NAME_COLS+['application_year_min', 'medical_school', 'application_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = match9B.clean_first_name.apply(has_suffix)\n",
    "match9B.loc[mask, 'clean_suffix'] = match9B.loc[mask, 'clean_first_name'].apply(get_suffix)\n",
    "\n",
    "match9B.loc[mask, 'clean_first_name'] = 'SPENCER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for person id duplicates\n",
    "dups_mask = match9B.duplicated(PERSON_ID, keep=False)\n",
    "match9B.loc[dups_mask, NAME_COLS+['medical_school', PERSON_ID, 'address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from random import randint\n",
    "max(match9B.person_uuid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_id = max(match9B.person_uuid.values)\n",
    "print max_id\n",
    "dups_mask = match9B.duplicated(PERSON_ID, keep=False)\n",
    "dups = match9B.ix[dups_mask, NAME_COLS+[PERSON_ID, 'medical_school', 'address']]\n",
    "dups['new_id'] = dups.person_uuid.apply(lambda x: max_id+randint(10, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NIH.loc[NIH.dno==3482, NAME_COLS+['NIH_first_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9B.loc[match9B.duplicated(PERSON_ID, keep=False), NAME_COLS+[PERSON_ID, 'dno', 'first_name', 'NIH_first_name', 'NIH_last_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_NIH_names_mask = (pd.isnull(match9B.NIH_first_name) & (~pd.isnull(match9B.dno)))\n",
    "match9B.loc[missing_NIH_names_mask, 'NIH_first_name'] = match9B[missing_NIH_names_mask]['dno'].apply(\n",
    "    lambda x: NIH.get_value(NIH.loc[NIH.dno==x].index[0], 'NIH_first_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match9C = pd.merge(left=match9B, right=dups, on=NAME_COLS+['medical_school', 'address', PERSON_ID], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to correct Dale Dietzman's medical school\n",
    "match9C.loc[((match9C.clean_last_name=='DIETZMAN') & (match9C.clean_first_name=='DALE')), 'medical_school'] = 'BAYLOR COLLEGE OF MEDICINE'\n",
    "match9C.loc[((match9C.clean_last_name=='DIETZMAN') & (match9C.clean_first_name=='DALE')), 'medical_school']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = ~pd.isnull(match9C.new_id)\n",
    "\n",
    "match9C.loc[match9C.person_uuid==3800,NAME_COLS+[PERSON_ID, 'new_id']]\n",
    "\n",
    "match9C.loc[mask, PERSON_ID] = match9C[mask]['new_id'] \n",
    "\n",
    "del match9C['new_id']\n",
    "\n",
    "dups_mask = match9C.duplicated(PERSON_ID, keep=False)\n",
    "match9C.loc[dups_mask, NAME_COLS+['medical_school', PERSON_ID, 'address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match9C.rename(columns={'res_dates': 'residency_dates_NIH', 'intern_dates': 'internship_dates_NIH', \n",
    "                        'residency_year(s)': 'residency_dates', 'internship_year(s)': 'internship_dates',\n",
    "                      'clean_college_trans': 'clean_college', 'med_school': 'NIH_medical_school'}, inplace=True)\n",
    "\n",
    "IMPORTANT_COLS = [NIH_ID, PERSON_ID, 'application_year_min', 'application_year_max', 'eod_year',\n",
    "                  'clean_first_name', 'clean_middle_name', \n",
    "                 'clean_last_name', 'control_flag', 'time_period_flag', 'year_accepted',\n",
    "                  'rejected', 'rejection_date', 'clean_college', 'medical_school',\n",
    "                'residency_dates', 'residency_dates_NIH', 'internship_dates', 'internship_dates_NIH',\n",
    "                  'is_female', 'is_foreign', 'number_applications', \n",
    "                 'NIH_first_name', 'NIH_middle_name', 'NIH_last_name', 'NIH_medical_school']\n",
    "\n",
    "other_cols = sorted([i for i in match9C.columns if i not in IMPORTANT_COLS])\n",
    "\n",
    "# order columns so important ones are \n",
    "match10 = match9C[IMPORTANT_COLS+other_cols].sort_values(['clean_last_name', 'clean_first_name', 'application_year_max']).drop(\n",
    "    ['clean_first_name_y', 'clean_middle_name_y', 'clean_last_name_y'], axis=1)\n",
    "\n",
    "match11 = match10.dropna(subset=[PERSON_ID], axis=0).sort_values(['clean_last_name', 'clean_first_name'])\n",
    "\n",
    "mask = (pd.isnull(match11.eod_year) & ~pd.isnull(match11.dno))\n",
    "\n",
    "match11['is_female'] = 0\n",
    "\n",
    "match11.loc[match11.clean_first_name.isin(FEMALE_FIRST_NAMES), 'is_female'] = 1\n",
    "\n",
    "match11.loc[mask, 'eod_year'] = match11[mask].dno.apply(lambda x: NIH.loc[NIH.dno==x, 'eod_year'].values[0])\n",
    "# wide_apps5.to_pickle(os.path.join(APP_DATA_DIR, 'all_apps_plus_NIH_info.p'))\n",
    "match11.to_csv(os.path.join(APP_DATA_DIR, 'fuzzy_all_apps_plus_NIH_info.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match9A.loc[match9A.clean_last_name.isin(['HARRIN']), NAME_COLS+[PERSON_ID, 'medical_school', 'application_year', 'dno', 'residency','residency_hospital',\n",
    "                                                            'internship_hospital', 'residency_dates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups_dno = match11.loc[(~pd.isnull(match11.dno)) & (match11.duplicated('dno', keep=False)), NAME_COLS+['dno', PERSON_ID, 'medical_school']]\n",
    "print dups_dno.shape\n",
    "dups_merge = pd.merge(\n",
    "    left=dups_dno, right=NIH.loc[NIH.dno.isin(dups_dno.dno), NAME_COLS+['dno', 'medical_school']], on=['dno'], how='left')\n",
    "\n",
    "dups_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for uuid dups\n",
    "match11.loc[match11.duplicated(PERSON_ID, keep=False), NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
