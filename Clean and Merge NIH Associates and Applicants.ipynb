{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in known applicant files, dedupe and try to merge with applicants file\n",
    "from collections import Counter\n",
    "import difflib\n",
    "import uuid\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import funcy\n",
    "import re\n",
    "import os\n",
    "\n",
    "APP_DATA_DIR = os.path.abspath('Data/applicant_data')\n",
    "ATT_DATA_DIR = os.path.abspath('Data/attendees_data')\n",
    "CARD_DATA_DIR = os.path.abspath('Data/applicant_data/raw_card_data')\n",
    "\n",
    "from data_cleaning_functions import (trans_remov_punc, standardize_whitespace, remove_punc, remove_suffix_from_last_name,\n",
    "                                     clean_names, has_award, has_suffix, get_suffix, replace_last_name,  \n",
    "                                     is_year_range, str_sim, clean_med_school, clean_std_college_name)\n",
    "from data_cleaning_functions import correct_mispellings\n",
    "\n",
    "\n",
    "# id column that links back to raw applicant data file\n",
    "RAW_CARD_ID = 'raw_uuid'\n",
    "\n",
    "# column where the raw id information is stored\n",
    "RAW_INDEX_IDS = 'raw_card_ids'\n",
    "\n",
    "# try to get one id per unique applicant in the dataset\n",
    "PERSON_ID = 'person_uuid'\n",
    "# id per deduped application-person - if someone applied multiple times, they will have multiple ids\n",
    "PERSON_APPLICATION_ID = 'person_app_uuid' \n",
    "NIH_ID = 'dno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read _csv\n",
    "df3_unique = pd.read_csv(os.path.join(ATT_DATA_DIR, 'unique_attendees.csv'))\n",
    "\n",
    "# import applicants file and try to merge with attendees\n",
    "# interested to see how many applicants were NOT accepted\n",
    "apps = pd.read_pickle(os.path.join(APP_DATA_DIR, 'person_application_date_wide.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:20:57.307343",
     "start_time": "2016-09-06T19:20:57.283824"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename columns in df3 to match\n",
    "# change residency and internship dates to be YYYY-YYYY instead of YYYY-YY\n",
    "def long_form_date(dt_str):\n",
    "    if pd.isnull(dt_str):\n",
    "        return dt_str\n",
    "    m = re.match(r'(\\d{4})-(\\d{2})', dt_str)\n",
    "    if m:\n",
    "        g = m.groups()\n",
    "        return '{0}-19{1}'.format(g[0], g[1])\n",
    "    m = re.match(r'(\\d{4})', dt_str)\n",
    "    if m:\n",
    "        return dt_str\n",
    "    print dt_str\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:20:58.769854",
     "start_time": "2016-09-06T19:20:58.727460"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps['res_dates'] = apps['residency_year(s)'].apply(long_form_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:20:59.235846",
     "start_time": "2016-09-06T19:20:59.179062"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Str. Medicine\n",
      "Medicine\n"
     ]
    }
   ],
   "source": [
    "apps['intern_dates'] = apps['internship_year(s)'].apply(long_form_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:20:59.747850",
     "start_time": "2016-09-06T19:20:59.676465"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3_unique.rename(columns={'res_dtes': 'res_dates', 'intern_dte': 'intern_dates', 'res_hosp': 'residency_hospital', \n",
    "                          'intern_hos': 'internship_hospital', 'clean_middlename': 'clean_middle_name', \n",
    "                          'clean_firstname': 'clean_first_name', 'clean_lastname': 'clean_last_name', \n",
    "                          'med_school': 'medical_school'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:01.254405",
     "start_time": "2016-09-06T19:21:01.219435"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps.rename(columns={'residency_type': 'residency', 'internship_hospital_1': 'internship_hospital'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:01.571869",
     "start_time": "2016-09-06T19:21:01.554296"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NAME_COLS = ['clean_middle_name', 'clean_last_name', 'clean_first_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:01.854766",
     "start_time": "2016-09-06T19:21:01.835997"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MED_TRAINING_COLS = ['res_dates', 'intern_dates', 'residency_hospital', 'internship_hospital', 'medical_school', 'residency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:02.524552",
     "start_time": "2016-09-06T19:21:02.128587"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply string cleaning to each of the medical training info cols\n",
    "for c in ['medical_school', 'residency_hospital', 'internship_hospital', 'residency', 'institute']:\n",
    "    df3_unique.loc[:, c] = df3_unique[c].apply(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:02.734350",
     "start_time": "2016-09-06T19:21:02.526876"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply string cleaning to each of the medical training info cols\n",
    "for c in ['medical_school', 'residency_hospital', 'internship_hospital', 'residency']:\n",
    "    apps.loc[:, c] = apps[c].apply(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:06.450494",
     "start_time": "2016-09-06T19:21:06.160238"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3_unique.loc[:, 'clean_medical_school'] = df3_unique.medical_school.apply(clean_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address',\n",
       " 'age',\n",
       " 'application_date',\n",
       " 'application_date_2',\n",
       " 'application_date_3',\n",
       " 'application_year',\n",
       " 'associate_program_entered',\n",
       " 'bob',\n",
       " 'ca',\n",
       " 'cc',\n",
       " 'citizenship',\n",
       " 'city',\n",
       " 'clean_college_trans',\n",
       " 'clean_first_name',\n",
       " 'clean_last_name',\n",
       " 'clean_middle_name',\n",
       " 'clean_suffix',\n",
       " 'clinical',\n",
       " 'cord',\n",
       " \"daniel's_comments\",\n",
       " 'date_of_birth',\n",
       " 'dbs',\n",
       " 'fifth',\n",
       " 'first_name',\n",
       " 'flag_missing_app_date',\n",
       " 'flag_rejected',\n",
       " 'honor_societies_first',\n",
       " 'honor_societies_fourth',\n",
       " 'honor_societies_second',\n",
       " 'honor_societies_third',\n",
       " 'ic',\n",
       " 'intern_dates',\n",
       " 'internship_hospital',\n",
       " 'internship_year(s)',\n",
       " 'last_name',\n",
       " 'medical_school',\n",
       " 'medschool_year_grad',\n",
       " 'middle_name',\n",
       " 'nci',\n",
       " 'nei',\n",
       " 'nhi',\n",
       " 'nhli',\n",
       " 'niaid',\n",
       " 'niamd',\n",
       " 'niamdd',\n",
       " 'nichd',\n",
       " 'nichhd',\n",
       " 'nidr',\n",
       " 'niehs',\n",
       " 'nigms',\n",
       " 'nimh',\n",
       " 'nindb',\n",
       " 'ninds',\n",
       " 'not_matched',\n",
       " 'oir',\n",
       " 'other',\n",
       " 'person_app_uuid',\n",
       " 'person_uuid',\n",
       " 'pharm_ra',\n",
       " 'pi',\n",
       " 'ra',\n",
       " 'raw_uuid',\n",
       " 'rejected',\n",
       " 'rejection_date',\n",
       " 'res_dates',\n",
       " 'research',\n",
       " 'residency',\n",
       " 'residency_hospital',\n",
       " 'residency_year(s)',\n",
       " 'reviewer',\n",
       " 'sa',\n",
       " 'sixth',\n",
       " 'state',\n",
       " 'teaching',\n",
       " 'undergrad_year_grad',\n",
       " 'undergraduate_school',\n",
       " 'unique_flag',\n",
       " 'withdrawal',\n",
       " 'year_accepted',\n",
       " 'zip_code']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(apps.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'clean_medical_school'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a8a30a4166ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_medical_school'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_medical_school\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_med_school\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'clean_medical_school'"
     ]
    }
   ],
   "source": [
    "i\n",
    "apps['clean_medical_school'] = apps.clean_medical_school.apply(clean_med_school) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_remove = ['TERRECE', 'FRED', 'LAURENCE',\n",
    "             'CUONO', 'DEFRENZE', 'JEFFERY', 'FINKLEMAN', 'SHERRAD', 'ANSCHNETZ', 'MARC', 'JENSON', 'KASTI', \n",
    "            'ADELBERT', 'RITCHARD', 'MANSFORD', 'DEFRENZO', 'DROBIN', 'HAMES', 'KREUZ', 'JERROLD', 'MANEUSI',\n",
    "            'UNGARO']\n",
    "to_replace = ['TERRENCE', 'FREDERICK', 'LAWRENCE',\n",
    "              'CUOMO', 'DEFRONZO', 'JEFFREY', 'FINKELMAN', 'SHERRARD', 'ANSCHUETZ', 'MARCUS', 'JENSEN', 'KASTL',\n",
    "              'ALBERT', 'RITCHARD', 'MANIFORD', 'DEFRONZO', 'DROBIS', 'JAMES', 'KRUEZ', 'JERROD', 'MANCUSI',\n",
    "              'UNGARO']\n",
    "\n",
    "correct_name_mispellings_fnc = funcy.rpartial(correct_mispellings, to_remove, to_replace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3_unique.loc[:, 'clean_last_name'] = df3_unique.clean_last_name.apply(correct_name_mispellings_fnc)\n",
    "df3_unique.loc[:, 'clean_first_name'] = df3_unique.clean_first_name.apply(correct_name_mispellings_fnc)\n",
    "apps.loc[:, 'clean_last_name'] = apps.clean_last_name.apply(correct_name_mispellings_fnc)\n",
    "apps.loc[:, 'clean_first_name'] = apps.clean_first_name.apply(correct_name_mispellings_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_names(dfs, selection_type, selection_value, to_change_type, to_change_values):\n",
    "    for t, v in zip(to_change_type, to_change_values):\n",
    "        print t, v\n",
    "        for df in dfs:\n",
    "            df.loc[df[selection_type]==selection_value, t] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALL_DFS = [apps, df3_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "change_names(\n",
    "    ALL_DFS, 'clean_last_name', 'CHESEBRO', ['clean_first_name', 'clean_middle_name'], ['BRUCE', 'WILCOX'])\n",
    "change_names(ALL_DFS, 'clean_last_name', 'GALANTER', ['clean_first_name', 'clean_middle_name'], ['MARC', 'I'])\n",
    "change_names(\n",
    "    ALL_DFS, 'clean_last_name', 'BEAN', ['clean_first_name', 'clean_middle_name', 'clean_medical_school'], ['SIDNEY', 'CHARLES', 'WAKE_FOREST'])\n",
    "change_names(\n",
    "    ALL_DFS, 'clean_last_name', 'EILER', ['clean_first_name', 'clean_middle_name'], ['DONALD', 'MARTIN'])\n",
    "change_names(\n",
    "    ALL_DFS, 'clean_last_name', 'FALCHUK', ['clean_first_name', 'clean_middle_name'], ['DONALD', 'MARTIN'])\n",
    "change_names(\n",
    "    [apps], 'clean_last_name', 'BOYD', ['clean_first_name', 'clean_middle_name'], ['MICHAEL', 'RAY'])\n",
    "change_names(\n",
    "    [apps], 'clean_last_name', 'CHAPMAN', \n",
    "    ['clean_first_name', 'clean_middle_name', 'clean_medical_school'], ['STANLEY', 'WILLETS', 'ROCHESTER'])\n",
    "change_names([apps], 'clean_last_name', 'DANFORTH', ['clean_first_name'], ['DAVID'])\n",
    "change_names([apps], 'clean_last_name', 'HUNT', ['clean_first_name', 'clean_middle_name'], ['ROBERT', 'D'])\n",
    "change_names([apps], 'clean_last_name', 'KARK', ['clean_first_name', 'clean_middle_name'], ['ROBERT', 'ADRIAN'])\n",
    "change_names([apps], 'clean_last_name', 'KEBABIAN', ['clean_first_name', 'clean_middle_name'], ['JOHN', 'WILLIS'])\n",
    "change_names([apps], 'clean_last_name', 'KNOPF', ['clean_first_name', 'clean_middle_name'], ['HARRY', 'LOUIS'])\n",
    "change_names([apps], 'clean_last_name', 'KROLIKOWSKI', ['clean_first_name', 'clean_middle_name'], ['FRANCIS', 'JOHN'])\n",
    "change_names([apps], 'clean_last_name', 'KASTL', ['clean_first_name', 'clean_middle_name'], ['DAVID', 'GENE'])\n",
    "change_names([apps], 'clean_first_name', 'JAN', ['clean_last_name'], ['KNOWLER'])\n",
    "change_names([apps], 'clean_last_name', 'KLAVEMAN', ['clean_last_name'], ['KLAEVEMAN'])\n",
    "change_names([apps], 'clean_last_name', 'MATHEW', ['clean_last_name'], ['MATTHEW'])\n",
    "\n",
    "apps.loc[apps.clean_last_name=='CHESEBRO', ['clean_first_name']] = 'BRUCE'\n",
    "apps.loc[apps.clean_last_name=='CHESEBRO', ['clean_middle_name']] = 'WILCOX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:07.034308",
     "start_time": "2016-09-06T19:21:06.971859"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_name_matches = pd.merge(left=df3_unique, right=apps, left_on=['clean_first_name', 'clean_middle_name', 'clean_last_name'], right_on=[\n",
    "        'clean_first_name', 'clean_middle_name', 'clean_last_name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:08.504317",
     "start_time": "2016-09-06T19:21:08.450571"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_matched_apps = apps.loc[~apps[PERSON_ID].isin(exact_name_matches[PERSON_ID]), :]\n",
    "not_matched_attendees = df3_unique.loc[~df3_unique[NIH_ID].isin(exact_name_matches[NIH_ID]), :]\n",
    "\n",
    "first_last_matches = pd.merge(left=not_matched_attendees, right=not_matched_apps, left_on=['clean_first_name', 'clean_last_name'], right_on=[\n",
    "        'clean_first_name', 'clean_last_name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:03.543055",
     "start_time": "2016-09-06T19:21:03.522386"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create counter objects for each data set that count the number of times the last name occurs in either data set\n",
    "attendees_counter = Counter(df3_unique.clean_last_name)\n",
    "\n",
    "apps_counter = Counter(apps.clean_last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:09.207976",
     "start_time": "2016-09-06T19:21:09.186009"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the first and last matches, where the last name only occurs 1x in each data set, set confidence flag to 1\n",
    "first_last_matches.loc[:, 'last_name_counts'] = first_last_matches.clean_last_name.apply(\n",
    "    lambda x: apps_counter[x] + attendees_counter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:10.672587",
     "start_time": "2016-09-06T19:21:10.654753"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_med_school_junk(seq_elem):\n",
    "    # difflib sequence matcher first element can take a fnc that inputs a\n",
    "    # sequence element and returns True if it should be considered Junk\n",
    "    return seq_elem in ['MEDICAL', 'SCHOOL', 'UNIVERSITY', 'COLLEGE', 'OF', 'THE', 'MEDICINE', 'CENTER', 'DENTISTRY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:11.248311",
     "start_time": "2016-09-06T19:21:11.229684"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_sim_fnc(row, index1, index2, junk_fnc=None):\n",
    "    has_null = any(map(lambda x: pd.isnull(x), row.values))\n",
    "    if has_null:\n",
    "        return np.nan\n",
    "    return difflib.SequenceMatcher(\n",
    "        junk_fnc, row[index1], row[index2]).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:12.510223",
     "start_time": "2016-09-06T19:21:12.492043"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_str_sim = funcy.rpartial(str_sim_fnc, 'clean_medical_school_x', 'clean_medical_school_y', define_med_school_junk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:12.951777",
     "start_time": "2016-09-06T19:21:12.900320"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_last_matches.loc[:, 'med_school_sim'] = first_last_matches[[\n",
    "        'clean_medical_school_x', 'clean_medical_school_y']].apply(get_str_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:14.585089",
     "start_time": "2016-09-06T19:21:14.556080"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_years(dt_str):\n",
    "    # return int date strings\n",
    "    try:\n",
    "        single_year = (dt_str.find('-') == -1)\n",
    "        if single_year:\n",
    "            return [dt_str]\n",
    "        return dt_str.split('-')\n",
    "    except ValueError as e:\n",
    "        print dt_str\n",
    "        return np.nan\n",
    "\n",
    "def get_dts_sim(row, name_str):\n",
    "    has_null = any(map(lambda x: pd.isnull(x), row.values))\n",
    "    if has_null:\n",
    "        return np.nan\n",
    "    dt1 = row['{}_x'.format(name_str)]\n",
    "    dt2 = row['{}_y'.format(name_str)]\n",
    "    dates_tup1 = get_years(dt1)\n",
    "    dates_tup2 = get_years(dt2)\n",
    "    # if dates match exactly, return 1\n",
    "    unique_dts = set(funcy.concat(dates_tup1, dates_tup2))\n",
    "    return (len(unique_dts) < (len(dates_tup1) + len(dates_tup2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:16.013562",
     "start_time": "2016-09-06T19:21:15.996819"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_intern_dts_sim = funcy.rpartial(get_dts_sim, 'intern_dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:16.414299",
     "start_time": "2016-09-06T19:21:16.379256"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_last_matches.loc[:, 'internship_sim'] = first_last_matches[[\n",
    "        'intern_dates_x', 'intern_dates_y']].apply(get_intern_dts_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:16.735763",
     "start_time": "2016-09-06T19:21:16.700189"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop all first and last name matches where the med school sim < .6 \n",
    "first_last_matches.loc[(first_last_matches['last_name_counts'] < 2), 'match_score'] = 1\n",
    "first_last_matches.loc[((first_last_matches['last_name_counts'] > 1) & (\n",
    "            first_last_matches['med_school_sim'] > .6) & (first_last_matches['internship_sim']==True)), 'match_score'] = 1\n",
    "first_last_matches.loc[((first_last_matches['last_name_counts'] > 1) & (\n",
    "            first_last_matches['med_school_sim'] > .6) & (pd.isnull(first_last_matches['internship_sim']))), 'match_score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T19:21:18.509174",
     "start_time": "2016-09-06T19:21:18.481151"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_last_matches.loc[pd.isnull(first_last_matches.match_score), 'match_score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exact_name_matches.loc[:, 'match_score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bunch of matches on last name only\n",
    "attendees_counter = Counter(df3_unique.clean_last_name)\n",
    "apps_counter = Counter(apps.clean_last_name)\n",
    "\n",
    "# Note that the case where count occurs 2x in one data set and not the other is ok, because nothing to merge on\n",
    "\n",
    "apps.loc[:, 'last_name_counts'] = apps.clean_last_name.apply(\n",
    "    lambda x: apps_counter[x] + attendees_counter[x])\n",
    "\n",
    "df3_unique.loc[:, 'last_name_counts'] = df3_unique.clean_last_name.apply(\n",
    "    lambda x: apps_counter[x] + attendees_counter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T20:57:55.847779",
     "start_time": "2016-09-06T20:57:55.808298"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop all people without a good match score\n",
    "# for non matches, do visual check, look at years 67-75, create a score of reliability they are control\n",
    "full_matches = pd.concat([first_last_matches.loc[first_last_matches.match_score==1, :], exact_name_matches], axis=0)\n",
    "# if application date year after eod year, drop\n",
    "# if double match and application date shows up 1x, drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# non matches\n",
    "not_matched_apps = apps.loc[~apps[PERSON_ID].isin(full_matches[PERSON_ID]), :]\n",
    "not_matched_attendees = df3_unique.loc[~df3_unique[NIH_ID].isin(full_matches[NIH_ID]), :]\n",
    "\n",
    "df3_unique.shape\n",
    "\n",
    "not_matched_attendees.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_matched_attendees.loc[not_matched_attendees.last_name_counts< 3, :].shape\n",
    "\n",
    "# there are a bunch of attendees who were not able to match on first and last name\n",
    "# for last name, if one instance in data set, try match\n",
    "last_matches = pd.merge(left=not_matched_apps.loc[not_matched_apps.last_name_counts<3, :],\n",
    "                    right=not_matched_attendees.loc[not_matched_attendees.last_name_counts < 3, :],\n",
    "                        left_on='clean_last_name', right_on='clean_last_name', how='inner')\n",
    "\n",
    "last_matches.loc[:, 'med_school_sim'] = last_matches[[\n",
    "        'clean_medical_school_x', 'clean_medical_school_y']].apply(get_str_sim, axis=1)\n",
    "last_matches.loc['match_score', :] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in manual match crosswalk\n",
    "m_matches = pd.read_excel(os.path.join(ATT_DATA_DIR, 'manual_attendees_match.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull from attendee data set because the information doesn't match\n",
    "# assuming NIH more reliable\n",
    "mm_df = df3_unique.loc[df3_unique[NIH_ID].isin(m_matches[NIH_ID]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mm2 = m_matches.dropna(subset=[PERSON_ID], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mmdf2 = pd.merge(left=mm_df, right=mm2, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mm_df3 = pd.merge(left=mmdf2, right=apps, left_on=PERSON_ID, right_on=PERSON_ID, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-43be5ce2e846>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-43be5ce2e846>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    col_pairs = map(lambda x: x.split('_x')[0], (filter(lambda x: x.endswith('_x'), 2.columns)))\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "col_pairs = map(lambda x: x.split('_x')[0], (filter(lambda x: x.endswith('_x'), 2.columns)))\n",
    "print col_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-294d3ad296f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcol_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'col_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "print col_pairs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mm_df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-eacec6d64b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmm_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'manual_match_flag'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mm_df3' is not defined"
     ]
    }
   ],
   "source": [
    "mm_df3.loc[:, 'manual_match_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mm_df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4798b2c566fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for each of paired columns, overwrite _y with _x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m mm_df3.loc[:, ['{}_y'.format(c_name) for c_name in col_pairs]] = mm_df3[[\n\u001b[0m\u001b[1;32m      3\u001b[0m         '{}_x'.format(c_name) for c_name in col_pairs]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mm_df3' is not defined"
     ]
    }
   ],
   "source": [
    "# for each of paired columns, overwrite _y with _x\n",
    "mm_df3.loc[:, ['{}_y'.format(c_name) for c_name in col_pairs]] = mm_df3[[\n",
    "        '{}_x'.format(c_name) for c_name in col_pairs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mm_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_matches2 = pd.concat([full_matches, last_matches, mm_df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for the attendees matched, we want to consolidate duplicate information for all the _x, _y columns\n",
    "col_pairs = map(lambda x: x.split('_x')[0], (filter(lambda x: x.endswith('_x'), full_matches2.columns)))\n",
    "print col_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches2.loc[full_matches2.manual_match_flag==1, ['clean_last_name', 'clean_first_name', 'clean_middle_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_nonmissing(a, b):\n",
    "    is_null = pd.isnull(a) and pd.isnull(b)\n",
    "    if is_null:\n",
    "        return np.nan\n",
    "    non_nulls = funcy.remove(pd.isnull, [a, b])\n",
    "    if isinstance(non_nulls[0], long) or isinstance(non_nulls[0], int) or isinstance(non_nulls[0], float):\n",
    "        return sorted(non_nulls, reverse=True)[0]\n",
    "    return sorted(non_nulls, key=len, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_mush = [('{}_x'.format(c), '{}_y'.format(c)) for c in col_pairs]\n",
    "for c1, c2 in cols_to_mush:\n",
    "    full_matches2.loc[:, c1.split('_x')[0]] = full_matches2.loc[:, [c1, c2]].apply(\n",
    "        lambda x: select_nonmissing(x[c1], x[c2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop consolidated columns\n",
    "full_matches2.drop(funcy.flatten(cols_to_mush), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# there are about 127 rows where applicant date and person are the same, drop these\n",
    "full_matches_dups = full_matches2.loc[\n",
    "    full_matches2.duplicated(['clean_first_name', 'clean_last_name'], keep=False), ['application_date', 'eod_year', 'rejection_date', 'clean_first_name', 'clean_last_name', 'sanity_check']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches_deduped = full_matches2.drop_duplicates(['clean_last_name', 'application_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches_deduped.loc[full_matches_deduped.manual_match_flag==1, ['clean_last_name', 'clean_first_name', 'clean_middle_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches2.loc[~pd.isnull(full_matches2.rejection_date), ['application_date', 'eod_year', 'rejection_date', 'clean_first_name', 'clean_last_name', 'sanity_check']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches_deduped.to_pickle(os.path.join(ATT_DATA_DIR, 'full_matches.p'))\n",
    "full_matches_deduped.to_csv(os.path.join(ATT_DATA_DIR, 'full_matches.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches_deduped2 = full_matches_deduped.set_index(PERSON_ID, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apps2 = apps.set_index(PERSON_ID, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_apps = full_matches_deduped2.combine_first(apps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_apps2 = wide_apps.drop(['Unnamed: 0', \"daniel's_comments\", 'firstname', 'lastname', 'middlename',  'med_school_sim', 'match_score', \n",
    "                'unknown'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_apps2.rename(columns={'clean_college_trans': 'clean_college'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# consolidate dob and date_of_birth, undergraduate_school and clean_college, intern_dates and internship_year(s)\n",
    "# res_dates and residency_year(s)\n",
    "# year_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace date of birth with dob whenever date of birth missing and dob is not\n",
    "wide_apps2.loc[\n",
    "    (pd.isnull(wide_apps2['date_of_birth'])) & (~pd.isnull(wide_apps2['dob'])), 'date_of_birth'] = wide_apps2.loc[\n",
    "        (pd.isnull(wide_apps2['date_of_birth'])) & (~pd.isnull(wide_apps2['dob'])), 'dob']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = 'date_of_birth'\n",
    "c2 = 'dob'\n",
    "wide_apps2.loc[(pd.isnull(wide_apps2[c1])) & (~pd.isnull(wide_apps2[c2])), [c1, c2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if columns fifth and sixth are empty\n",
    "wide_apps2.loc[~pd.isnull(wide_apps2.fifth), :]\n",
    "wide_apps2.loc[~pd.isnull(wide_apps2.sixth), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete them\n",
    "wide_apps3 = wide_apps2.drop(['dob', 'undergraduate_school', 'internship_year(s)', 'residency_year(s)', \n",
    "                              'year_grad', 'fifth', 'sixth', 'other', 'internship_sim'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_apps3.rename(columns={'res_dates': 'residency_dates', 'intern_dates': 'internship_dates'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMPORTANT_COLS = [NIH_ID, PERSON_ID, 'application_year', 'eod_year', 'application_date', 'clean_first_name', 'clean_middle_name', \n",
    "                 'clean_last_name', 'year_accepted', 'rejected', 'rejection_date', 'clean_college', 'clean_medical_school',\n",
    "                'residency_dates', 'internship_dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_cols = sorted([i for i in wide_apps3.columns if i not in IMPORTANT_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# order columns so important ones are \n",
    "wide_apps4 = wide_apps3[IMPORTANT_COLS+other_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wide_apps5 = wide_apps4.dropna(subset=[PERSON_ID], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_apps5.to_pickle(os.path.join(APP_DATA_DIR, 'all_apps_plus_NIH_info.p'))\n",
    "wide_apps5.to_csv(os.path.join(APP_DATA_DIR, 'all_apps_plus_NIH_info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_apps5.loc[(wide_apps5.application_year>1960) & (wide_apps5.application_year<1976), :].to_pickle(os.path.join(APP_DATA_DIR, 'all_apps_plus_NIH_info_vietnam.p'))\n",
    "\n",
    "wide_apps5.loc[(wide_apps5.application_year>1960) & (wide_apps5.application_year<1976), :].to_csv(os.path.join(APP_DATA_DIR, 'all_apps_plus_NIH_info_vietnam.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_matched_apps = apps.loc[~apps[PERSON_ID].isin(full_matches2[PERSON_ID]), :]\n",
    "not_matched_attendees = df3_unique.loc[~df3_unique[NIH_ID].isin(full_matches2[NIH_ID]), :]\n",
    "\n",
    "df3_unique.shape\n",
    "\n",
    "not_matched_attendees.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_matched_attendees_vietnam = not_matched_attendees.loc[(not_matched_attendees.eod_year<1976) & (not_matched_attendees.eod_year>1960), :].sort_values('clean_last_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_matched_attendees_vietnam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T21:38:00.442444",
     "start_time": "2016-09-06T21:38:00.417704"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_matched_attendees_vietnam.to_csv(os.path.join(ATT_DATA_DIR, 'not_matched_attendees.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-06T20:59:38.757257",
     "start_time": "2016-09-06T20:59:38.669227"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_matched_attendees.eod_year.value_counts().to_csv(os.path.join(ATT_DATA_DIR, 'not_matched_attendees.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_last_matches.loc[first_last_matches['clean_last_name']=='LARSON', ['medical_school_x', 'medical_school_y']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
