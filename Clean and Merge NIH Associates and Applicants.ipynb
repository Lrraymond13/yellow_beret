{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%install_ext` not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 27.1 ms\n"
     ]
    }
   ],
   "source": [
    "%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.6 ms\n"
     ]
    }
   ],
   "source": [
    "# read in known applicant files, dedupe and try to merge with applicants file\n",
    "from collections import Counter\n",
    "import difflib\n",
    "import uuid\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import funcy\n",
    "import re\n",
    "import os\n",
    "\n",
    "from data_cleaning_functions import (trans_remov_punc, standardize_whitespace, remove_punc, remove_suffix_from_last_name,\n",
    "                                     clean_names, has_award, has_suffix, get_suffix, replace_last_name, \n",
    "                                     is_year_range, str_sim, clean_med_school, clean_std_college_name, long_form_date, \n",
    "                                    correct_mispellings)\n",
    "\n",
    "from dev import (\n",
    "    APP_DATA_DIR, SUM_STAT_DIR, ATT_DATA_DIR, CARD_DATA_DIR, CORRECTIONS_DIR, AWARDS_KEYWORDS, NAME_COLS, RAW_NAME_COLS, \n",
    "    RAW_CARD_ID, RAW_INDEX_IDS, PERSON_APPLICATION_ID, PERSON_ID, NIH_ID, FEMALE_FIRST_NAMES, FEMALE_MIDDLE_NAMES, \n",
    "    PICKLE_DIR)\n",
    "from merging_functions import *\n",
    "\n",
    "OUTPUT_CSV = False \n",
    "\n",
    "PERSONAL_INFO = [\n",
    "    'clean_first_name', 'clean_last_name', 'clean_middle_name',\n",
    "    'date_of_birth', 'medical_school', 'clean_college_trans']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "time: 34.2 ms\n"
     ]
    }
   ],
   "source": [
    "# id column that links back to raw applicant data file\n",
    "RAW_CARD_ID = 'raw_uuid'\n",
    "\n",
    "# column where the raw id information is stored\n",
    "RAW_INDEX_IDS = 'raw_card_ids'\n",
    "\n",
    "# try to get one id per unique applicant in the dataset\n",
    "PERSON_ID = 'person_uuid'\n",
    "# id per deduped application-person - if someone applied multiple times, they will have multiple ids\n",
    "PERSON_APPLICATION_ID = 'person_app_uuid' \n",
    "NIH_ID = 'dno'\n",
    "\n",
    "APPLICANT_SUFFIX = '_ap'\n",
    "ATTENDEE_SUFFIX = '_at'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.5 ms\n"
     ]
    }
   ],
   "source": [
    "apps_filename = 'index_cards_deduped_fuzzy.csv'\n",
    "# apps_filename = 'person_application_date_wide.csv'\n",
    "\n",
    "NIH_filename = 'unique_attendees.csv'\n",
    "# NIH_filename = 'NIH_attendee_deduped_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms\n"
     ]
    }
   ],
   "source": [
    "NAME_COLS = ['clean_middle_name', 'clean_last_name', 'clean_first_name']\n",
    "\n",
    "MED_TRAINING_COLS = ['res_dates', 'intern_dates', 'residency_hospital', 'internship_hospital', 'medical_school', 'residency']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.4 ms\n"
     ]
    }
   ],
   "source": [
    "# import NIH raw data set\n",
    "NIH_raw = pd.read_csv(os.path.join(ATT_DATA_DIR, NIH_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.3 ms\n"
     ]
    }
   ],
   "source": [
    "# drop from the data set all people with eod years > 1980\n",
    "NIH = NIH_raw.loc[NIH_raw.eod_year<1980, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 87.7 ms\n"
     ]
    }
   ],
   "source": [
    "# import cleaned, deduped applicant data set in wide form (multiple app dates as columns)\n",
    "apps = pd.read_csv(os.path.join(APP_DATA_DIR, apps_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Open\"\n",
      "Str. Medicine\n",
      "Medicine\n",
      "time: 64.9 ms\n"
     ]
    }
   ],
   "source": [
    "apps.loc[:, 'res_dates'] = apps['residency_year(s)'].apply(long_form_date)\n",
    "\n",
    "apps.loc[:, 'intern_dates'] = apps['internship_year(s)'].apply(long_form_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.9 ms\n"
     ]
    }
   ],
   "source": [
    "apps2 = apps.rename(\n",
    "    columns={'residency_type': 'residency', 'internship_hospital_1': 'internship_hospital'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46 ms\n"
     ]
    }
   ],
   "source": [
    "NIH = NIH.rename(columns={'res_dtes':'res_dates', 'intern_dte':'intern_dates', 'intern_hos': 'internship_hospital', \n",
    "                         'res_hosp':'residency_hospital', 'clean_medical_school': 'medical_school'})\n",
    "# sorted(NIH.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "string_med_cols = ['medical_school', 'residency_hospital', 'internship_hospital', 'residency']\n",
    "\n",
    "# apply string cleaning function to each of the string medical info columns\n",
    "apps2.loc[:, string_med_cols] = apps2[string_med_cols].applymap(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 87.9 ms\n"
     ]
    }
   ],
   "source": [
    "to_remove = ['TERRECE', 'FRED', 'LAURENCE',\n",
    "             'CUONO', 'DEFRENZE', 'JEFFERY', 'FINKLEMAN', 'SHERRAD', 'ANSCHNETZ', 'MARC', 'JENSON', 'KASTI', \n",
    "            'ADELBERT', 'RITCHARD', 'MANSFORD', 'DEFRENZO', 'DROBIN', 'HAMES', 'KREUZ', 'JERROLD', 'MANEUSI',\n",
    "            'UNGARO']\n",
    "to_replace = ['TERRENCE', 'FREDERICK', 'LAWRENCE',\n",
    "              'CUOMO', 'DEFRONZO', 'JEFFREY', 'FINKELMAN', 'SHERRARD', 'ANSCHUETZ', 'MARCUS', 'JENSEN', 'KASTL',\n",
    "              'ALBERT', 'RITCHARD', 'MANIFORD', 'DEFRONZO', 'DROBIS', 'JAMES', 'KRUEZ', 'JERROD', 'MANCUSI',\n",
    "              'UNGARO']\n",
    "\n",
    "correct_name_mispellings_fnc = funcy.rpartial(correct_mispellings, to_remove, to_replace)\n",
    "\n",
    "apps2.loc[:, 'clean_last_name'] = apps2.clean_last_name.apply(correct_name_mispellings_fnc)\n",
    "apps2.loc[:, 'clean_first_name'] = apps2.clean_first_name.apply(correct_name_mispellings_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.2 ms\n"
     ]
    }
   ],
   "source": [
    "# there are a bunch of duplicates in apps, where application year is the same, but first name is missing\n",
    "name_dups = apps2.loc[\n",
    "    apps2.duplicated(\n",
    "        ['clean_last_name', 'medical_school', 'application_year'], keep=False), NAME_COLS+MED_TRAINING_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.8 ms\n"
     ]
    }
   ],
   "source": [
    "# name_dups.sort_values(['clean_last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.3 ms\n"
     ]
    }
   ],
   "source": [
    "apps3 = apps2.sort_values(['clean_last_name', 'clean_first_name']).drop_duplicates(\n",
    "    ['clean_last_name', 'medical_school', 'application_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.9 ms\n"
     ]
    }
   ],
   "source": [
    "# there are also some duplicates on middle and last name, but first is missing on one of the dups, \n",
    "# so we need to drop these\n",
    "dups_mask = apps3.duplicated(['clean_last_name', 'clean_middle_name', 'application_year'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.9 ms\n"
     ]
    }
   ],
   "source": [
    "apps4 = apps3.loc[((~dups_mask) | ((dups_mask) & (~pd.isnull(apps3.clean_first_name)))), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3982, 88)\n",
      "(3988, 88)\n",
      "time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "print apps4.shape\n",
    "print apps3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>OTTO</td>\n",
       "      <td>HAAKENSTAD</td>\n",
       "      <td>ALAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clean_middle_name clean_last_name clean_first_name\n",
       "59              OTTO      HAAKENSTAD             ALAN"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.1 ms\n"
     ]
    }
   ],
   "source": [
    "apps4.loc[apps4.clean_last_name=='HAAKENSTAD', NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_medical_school</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>OTTO</td>\n",
       "      <td>HAAKENSTAD</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1718 7th Street South</td>\n",
       "      <td>South Fargo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clean_middle_name clean_last_name clean_first_name  clean_medical_school  \\\n",
       "59              OTTO      HAAKENSTAD             ALAN                   NaN   \n",
       "\n",
       "                  address         city  \n",
       "59  1718 7th Street South  South Fargo  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.9 ms\n"
     ]
    }
   ],
   "source": [
    "apps3.loc[apps3.clean_last_name=='HAAKENSTAD', NAME_COLS+['clean_medical_school', 'address', 'city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.6 ms\n"
     ]
    }
   ],
   "source": [
    "# function to go in and correct some of the name mispellings in both data sets\n",
    "# MUTATING FUNCTION\n",
    "def change_names(df, selection_type, selection_value, to_change_type, to_change_values):\n",
    "    for t, v in zip(to_change_type, to_change_values):\n",
    "        print t, v\n",
    "        df.loc[df[selection_type]==selection_value, t] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 874 ms\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "change_names(\n",
    "    apps4, 'clean_last_name', 'CHESEBRO', ['clean_first_name', 'clean_middle_name'], ['BRUCE', 'WILCOX'])\n",
    "change_names(\n",
    "    apps4, 'clean_last_name', 'GALANTER', ['clean_first_name', 'clean_middle_name'], ['MARC', 'I'])\n",
    "change_names(\n",
    "    apps4, 'clean_last_name', 'BEAN', ['clean_first_name', 'clean_middle_name', 'medical_school'], ['SIDNEY', 'CHARLES', 'WAKE_FOREST'])\n",
    "change_names(\n",
    "    apps4, 'clean_last_name', 'EILER', ['clean_first_name', 'clean_middle_name'], ['DONALD', 'MARTIN'])\n",
    "change_names(\n",
    "    apps4, 'clean_last_name', 'FALCHUK', ['clean_first_name', 'clean_middle_name'], ['DONALD', 'MARTIN'])\n",
    "change_names(\n",
    "    apps4, 'clean_last_name', 'BOYD', ['clean_first_name', 'clean_middle_name'], ['MICHAEL', 'RAY'])\n",
    "change_names(\n",
    "    apps4, 'clean_last_name', 'CHAPMAN', \n",
    "    ['clean_first_name', 'clean_middle_name', 'medical_school'], ['STANLEY', 'WILLETS', 'ROCHESTER'])\n",
    "change_names(apps4, 'clean_last_name', 'DANFORTH', ['clean_first_name'], ['DAVID'])\n",
    "change_names(apps4, 'clean_last_name', 'HUNT', ['clean_first_name', 'clean_middle_name'], ['ROBERT', 'D'])\n",
    "change_names(apps4, 'clean_last_name', 'KARK', ['clean_first_name', 'clean_middle_name'], ['ROBERT', 'ADRIAN'])\n",
    "change_names(apps4, 'clean_last_name', 'KEBABIAN', ['clean_first_name', 'clean_middle_name'], ['JOHN', 'WILLIS'])\n",
    "change_names(apps4, 'clean_last_name', 'KNOPF', ['clean_first_name', 'clean_middle_name'], ['HARRY', 'LOUIS'])\n",
    "change_names(apps4, 'clean_last_name', 'KROLIKOWSKI', ['clean_first_name', 'clean_middle_name'], ['FRANCIS', 'JOHN'])\n",
    "change_names(apps4, 'clean_last_name', 'KASTL', ['clean_first_name', 'clean_middle_name'], ['DAVID', 'GENE'])\n",
    "change_names(apps4, 'clean_first_name', 'JAN', ['clean_last_name'], ['KNOWLER'])\n",
    "change_names(apps4, 'clean_last_name', 'KLAVEMAN', ['clean_last_name'], ['KLAEVEMAN'])\n",
    "change_names(apps4, 'clean_last_name', 'MATHEW', ['clean_last_name'], ['MATTHEW'])\n",
    "\n",
    "apps4.loc[apps4.clean_last_name=='CHESEBRO', ['clean_first_name']] = 'BRUCE'\n",
    "apps4.loc[apps4.clean_last_name=='CHESEBRO', ['clean_middle_name']] = 'WILCOX'\n",
    "apps4.loc[(apps4.clean_last_name=='HEALY') & (apps4.medical_school=='USC KECK'), ['clean_first_name']] = 'MARK'\n",
    "apps4.loc[(apps4.clean_last_name=='HEALY') & (apps4.medical_school=='USC KECK'), ['clean_middle_name']] = 'H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'age', 'application_date', 'application_year', 'application_year_1', 'application_year_2', 'application_year_3', 'associate_program_entered', 'bob', 'ca', 'cc', 'citizenship', 'city', 'clean_college_trans', 'clean_first_initial', 'clean_first_name', 'clean_last_name', 'clean_middle_initial', 'clean_middle_name', 'clean_suffix', 'clinical', 'cord', 'date_of_birth', 'dbs', 'fifth', 'first_name', 'fuzzy_merge_col', 'honor_societies_first', 'honor_societies_fourth', 'honor_societies_second', 'honor_societies_third', 'ic', 'index', 'intern_dates', 'internship_hospital', 'internship_year(s)', 'is_female', 'is_match', 'last_name', 'last_name_counts', 'medical_school', 'medschool_year_grad', 'middle_name', 'nci', 'nei', 'nhi', 'nhli', 'niaid', 'niamd', 'niamdd', 'nichd', 'nichhd', 'nidr', 'niehs', 'nigms', 'nimh', 'nindb', 'ninds', 'oir', 'original_medical_school', 'other', 'person_uuid', 'pharm_ra', 'pi', 'ra', 'raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'raw_uuid_4', 'raw_uuid_5', 'rejected', 'rejection_date', 'res_dates', 'research', 'residency', 'residency_hospital', 'residency_year(s)', 'reviewer', 'sa', 'sixth', 'state', 'teaching', 'undergrad_year_grad', 'undergraduate_school', 'withdrawal', 'year_accepted', 'zip_code']\n",
      "['Unnamed: 0', 'citizenship', 'clean_first_initial', 'clean_first_name', 'clean_last_name', 'clean_middle_initial', 'clean_middle_name', 'clean_suffix', 'count_missing', 'data_source', 'dno', 'dob', 'dup_flag', 'duplicate_dno', 'eod_year', 'eod_year_diff', 'fuzzy_merge_col', 'generation', 'institute', 'intern_dates', 'internship_hospital', 'lab_brch', 'med_school', 'medical_school', 'program', 'res_dates', 'residency', 'residency_hospital', 'source', 'ssn', 'supervisor', 'unknown', 'year_grad']\n",
      "time: 22.4 ms\n"
     ]
    }
   ],
   "source": [
    "print sorted(apps4.columns)\n",
    "print sorted(NIH.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "apps4.loc[apps4.clean_last_name=='LENN', 'clean_first_name'] = 'NICHOLAS'\n",
    "apps4.loc[apps4.clean_last_name=='BRESLOW', 'clean_first_name'] = 'JAN'\n",
    "apps4.loc[apps4.clean_last_name=='BRESLOW', 'clean_middle_name'] = 'LESLIE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "apps4.loc[(apps4.clean_last_name=='NADLER') & (pd.isnull(apps4.clean_first_name)), 'clean_first_name'] = 'LEE'\n",
    "apps4.loc[(apps4.clean_last_name=='NADLER') & (apps4.clean_first_name=='LEE'), 'clean_middle_name'] = 'MARSHALL'\n",
    "apps4.loc[(pd.isnull(apps4.clean_first_name)) & (apps4.clean_last_name=='ROSEN'), 'clean_first_name'] = 'HENRY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 87 ms\n"
     ]
    }
   ],
   "source": [
    "apps4.loc[(apps4.clean_last_name=='NEELON'), 'clean_first_name'] = 'FRANCIS'\n",
    "apps4.loc[(apps4.clean_last_name=='NEELON') , 'clean_middle_name'] = 'ALBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842        JOHN\n",
       "2538    NICHOLAS\n",
       "Name: clean_first_name, dtype: object"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 53.9 ms\n"
     ]
    }
   ],
   "source": [
    "apps4.loc[(apps4.clean_last_name=='NICHOLAS') , 'clean_first_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.1 ms\n"
     ]
    }
   ],
   "source": [
    "NIH.loc[(NIH.clean_last_name=='ALEXANDER') & (NIH.clean_first_name=='JOHN'), 'clean_middle_name'] = 'CHARLES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.6 ms\n"
     ]
    }
   ],
   "source": [
    "NIH.loc[(NIH.clean_last_name=='LEBOWITZ') & (NIH.clean_first_name=='EDWARD ARTHUR'),'clean_middle_name'] = 'ARTHUR'\n",
    "NIH.loc[(NIH.clean_last_name=='LEBOWITZ') & (NIH.clean_first_name=='EDWARD ARTHUR'),'clean_first_name'] = 'EDWARD'\n",
    "NIH.loc[(\n",
    "        NIH.clean_last_name=='LEBOWITZ') & (\n",
    "            NIH.clean_first_name=='EDWARD'), 'medical_school'] = 'ALBERT EINSTEIN COLLEGE OF MEDICINE OF YESHIVA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clean_middle_name, clean_last_name, clean_first_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.4 ms\n"
     ]
    }
   ],
   "source": [
    "NIH.loc[(NIH.clean_last_name=='NEELON'), NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 50.5 ms\n"
     ]
    }
   ],
   "source": [
    "# read in manual matches\n",
    "man = pd.read_excel(os.path.join(CORRECTIONS_DIR, 'manual_dno_matches.xlsx'), index=False).rename(columns={'medical_school': 'dno_medical_school'})\n",
    "man['medical_school'] = man.dno_medical_school.apply(clean_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>ALBERT</td>\n",
       "      <td>NEELON</td>\n",
       "      <td>FRANCIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clean_middle_name clean_last_name clean_first_name\n",
       "3867            ALBERT          NEELON          FRANCIS"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.4 ms\n"
     ]
    }
   ],
   "source": [
    "apps4.loc[apps4.clean_last_name=='NEELON', NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 94)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.2 ms\n"
     ]
    }
   ],
   "source": [
    "t = pd.merge(left=apps4, right=man, on=['clean_last_name', 'clean_middle_name'], how='inner', suffixes=['_x', '_y'])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.4 ms\n"
     ]
    }
   ],
   "source": [
    "t['sim'] = t[['medical_school_x', 'medical_school_y']].apply(get_name_str_sim, axis=1)\n",
    "\n",
    "t['clean_first_name'] = t['clean_first_name_y']\n",
    "\n",
    "t_1 = t.sort_values(['dno', 'sim'], ascending=False).drop_duplicates(['dno'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>dno</th>\n",
       "      <th>medical_school_x</th>\n",
       "      <th>medical_school_y</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clean_middle_name, clean_last_name, clean_first_name, dno, medical_school_x, medical_school_y, sim]\n",
       "Index: []"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.3 ms\n"
     ]
    }
   ],
   "source": [
    "# t[NAME_COLS+['dno', 'medical_school_x', 'medical_school_y', 'sim']]\n",
    "t_1.loc[t_1.duplicated('dno', keep=False), NAME_COLS+['dno', 'medical_school_x', 'medical_school_y', 'sim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.5 ms\n"
     ]
    }
   ],
   "source": [
    "um = man[~man.dno.isin(t_1.dno)]\n",
    "\n",
    "um.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 94)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.6 ms\n"
     ]
    }
   ],
   "source": [
    "t2 = pd.merge(left=apps4, right=um, on=['clean_last_name', 'clean_first_name'], how='inner', suffixes=['_x', '_y'])\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.5 ms\n"
     ]
    }
   ],
   "source": [
    "t2['sim'] = t2[['medical_school_x', 'medical_school_y']].apply(get_name_str_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 96)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.5 ms\n"
     ]
    }
   ],
   "source": [
    "t2['clean_middle_name'] = t2['clean_middle_name_y']\n",
    "\n",
    "t2_1 = t2.sort_values(['dno', 'sim'], ascending=False).drop_duplicates(['dno'], keep='first')\n",
    "t2_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.9 ms\n"
     ]
    }
   ],
   "source": [
    "t3 = pd.concat([t2_1[NAME_COLS+['dno', PERSON_ID]], t_1[NAME_COLS+['dno', PERSON_ID]]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3982, 92)\n",
      "(103, 5)\n",
      "(104, 8)\n",
      "time: 40.5 ms\n"
     ]
    }
   ],
   "source": [
    "man_dno = pd.merge(left=apps4, right=t3, on=PERSON_ID, how='left', suffixes=['_x', '_y'])\n",
    "print man_dno.shape\n",
    "print t3.shape\n",
    "print man.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 53.2 ms\n"
     ]
    }
   ],
   "source": [
    "mask = ~pd.isnull(man_dno.clean_last_name_y)\n",
    "man_dno = man_dno.rename(columns={'clean_last_name_x': 'clean_last_name', 'clean_first_name_x': 'clean_first_name', \n",
    "                       'clean_middle_name_x': 'clean_middle_name'})\n",
    "mask = ~pd.isnull(man_dno.clean_last_name_y)\n",
    "man_dno.loc[mask, 'clean_last_name'] = man_dno.loc[mask, 'clean_last_name_y']\n",
    "mask = ~pd.isnull(man_dno.clean_first_name_y)\n",
    "man_dno.loc[mask, 'clean_first_name'] = man_dno.loc[mask, 'clean_first_name_y']\n",
    "mask = ~pd.isnull(man_dno.clean_middle_name_y)\n",
    "man_dno.loc[mask, 'clean_middle_name'] = man_dno.loc[mask, 'clean_middle_name_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "apps5 = man_dno.loc[pd.isnull(man_dno['dno']), :].drop('dno', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.3 ms\n"
     ]
    }
   ],
   "source": [
    "# remove females from data set\n",
    "female_mask = (NIH.clean_first_name.isin(FEMALE_FIRST_NAMES)| NIH.clean_middle_name.isin(FEMALE_MIDDLE_NAMES))  \n",
    "NIH = NIH.loc[~female_mask, :]\n",
    "\n",
    "female_mask = (apps5.clean_first_name.isin(FEMALE_FIRST_NAMES)| apps5.clean_middle_name.isin(FEMALE_MIDDLE_NAMES))  \n",
    "apps5 = apps5.loc[~female_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "def get_first_letter(str_var):\n",
    "    if pd.isnull(str_var) or str_var=='':\n",
    "        return np.nan\n",
    "    return str_var[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.2 ms\n"
     ]
    }
   ],
   "source": [
    "NIH['clean_first_initial'] = NIH.clean_first_name.apply(get_first_letter)\n",
    "NIH['clean_middle_initial'] = NIH.clean_middle_name.apply(get_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3009, 33)\n",
      "(3878, 91)\n",
      "time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "print NIH.shape\n",
    "print  apps5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.2 ms\n"
     ]
    }
   ],
   "source": [
    "# After cleaning apps2 to match cleaning in Clean NIH Applicant notebook, we try to start merging\n",
    "sims_cols = ['medical_school_sim', 'clean_middle_name_sim', 'clean_first_name_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3013, 122)\n",
      "time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "NIH['fuzzy_merge_col'] = NIH[\n",
    "    ['clean_first_name', 'clean_middle_name', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "apps5['fuzzy_merge_col'] = apps5[\n",
    "    ['clean_first_name', 'clean_middle_name', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "match1 = df_get_closest_matches(apps5, NIH, 'fuzzy_merge_col', suffixes=['_x', '_y']) \n",
    "print match1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "(\"'Series' objects are mutable, thus they cannot be hashed\", u'occurred at index clean_last_name_y')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-7060887f7beb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNIH_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNIH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_last_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatch1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_name_counts_x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_last_name_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapp_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmatch1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_name_counts_y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_last_name_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNIH_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4059\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4155\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4156\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4157\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4158\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-265-7060887f7beb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNIH_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNIH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_last_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatch1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_name_counts_x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_last_name_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapp_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmatch1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_name_counts_y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_last_name_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNIH_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         raise TypeError('{0!r} objects are mutable, thus they cannot be'\n\u001b[0;32m--> 806\u001b[0;31m                         ' hashed'.format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: (\"'Series' objects are mutable, thus they cannot be hashed\", u'occurred at index clean_last_name_y')"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90 ms\n"
     ]
    }
   ],
   "source": [
    "# add last name counter to each\n",
    "app_counter = Counter(apps4.clean_last_name.values)\n",
    "NIH_counter = Counter(NIH.clean_last_name.values)\n",
    "match1['last_name_counts_x'] = match1.clean_last_name_x.apply(lambda x: app_counter[x])\n",
    "match1['last_name_counts_y'] = match1.clean_last_name_y.apply(lambda x: NIH_counter[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_match(row):\n",
    "    # address and application year match\n",
    "    app_eod_year_diff = abs(row['application_year'] - row['eod_year'])\n",
    "    if row['clean_last_name_sim'] < 60 or app_eod_year_diff > 8:\n",
    "        return 0\n",
    "    \n",
    "    # the first and middle name seem to be mixed up in index card data set\n",
    "    mixed_sim1 =  get_name_str_sim(row[['clean_middle_name_x', 'clean_first_name_y']])\n",
    "    mixed_sim2 =  get_name_str_sim(row[['clean_middle_name_y', 'clean_first_name_x']])\n",
    "    \n",
    "    mix_sim = max(mixed_sim1, mixed_sim2)\n",
    "    if pd.isnull(mix_sim):\n",
    "        mix_sim = 0\n",
    "    if (mix_sim > 90) and row['medical_school_sim'] > 80:\n",
    "        return 1\n",
    "    if row['last_name_counts_x'] < 2 and row['last_name_counts_y'] < 2:\n",
    "        return 1\n",
    "    if (mix_sim > 90) and pd.isnull(row['medical_school_sim']) and (app_eod_year_diff < 5):\n",
    "        return 1\n",
    "    if not pd.isnull(row['clean_first_name_sim']) and row['clean_first_name_sim'] < .5:\n",
    "        return 0\n",
    "    # if matching application year and med schools match\n",
    "    if (app_eod_year_diff < 5) and row['medical_school_sim'] > 80:\n",
    "        return 1\n",
    "    # first and middle names match or first\n",
    "    if (app_eod_year_diff < 5) and row['clean_first_name_sim'] > 80:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "feature_dict = {\n",
    "    'clean_first_name': get_name_str_sim,\n",
    "    'clean_middle_name': get_name_str_sim,\n",
    "    'clean_last_name': get_name_str_sim,\n",
    "    'medical_school': get_name_str_sim,\n",
    "}\n",
    "\n",
    "match2 = add_similarity_features(match1, feature_dict, check_match, suffixes=['_x', '_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# match2.loc[(match2.is_match==2), sims_cols+['is_match', 'clean_first_name_x', 'clean_first_name_y',\n",
    "#                         'clean_last_name_x', 'clean_last_name_y','medical_school_x', 'medical_school_y', PERSON_ID, NIH_ID]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select out people who match and make sure each person id and dno only 1x in data set\n",
    "match3 = match2[match2.is_match==1].sort_values(['clean_last_name_x']+sims_cols, ascending=False).dropna(\n",
    "    axis=0, subset=[RAW_CARD_ID])\n",
    "print match3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# match2[match2.clean_last_name_x=='ADLER']\n",
    "NIH[NIH.clean_last_name=='ADLER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_one_match_per_group(df, dedupe_col, sim_cols):\n",
    "    # to merge cols should be a dict the names of the extra cols to merge in\n",
    "    # values should be col names to rename\n",
    "    # sim cols should be name of the columns to use as features\n",
    "    # sim mask should be mask that accounts as actual mask\n",
    "    # dedupe col is name of col to dedupe on\n",
    "\n",
    "    def count_matches(id_list_arr):\n",
    "        # for each id, make sure matched on 1x in data set\n",
    "        # should be applied with rolling apply so takes in a dataframe and must return single value\n",
    "        # unpack already matched ids from string\n",
    "        current_id1 = id_list_arr[-1]\n",
    "        other_matches = id_list_arr[:-1]\n",
    "        is_dup = np.any(other_matches[:] == current_id1)\n",
    "        if is_dup:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # for each uuid, check for duplicates and choose best match based on sim cols\n",
    "    # order of the sim cols should be with most important first\n",
    "    dup_flag = '{}_duplicate'.format(dedupe_col)\n",
    "    df[dup_flag] = 0\n",
    "    df.loc[:, dup_flag] = df[\n",
    "        dedupe_col].expanding(center=False, min_periods=0).apply(func=count_matches)\n",
    "\n",
    "    df_matches = df[df['is_match'] == 1].sort_values([dedupe_col] + sim_cols, ascending=False)\n",
    "    return df_matches.drop_duplicates([dedupe_col], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match4 = filter_one_match_per_group(match3, 'raw_uuid', sims_cols)\n",
    "print match4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match5 = filter_one_match_per_group(match4, NIH_ID, sims_cols)\n",
    "print match5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get nonmatched NIH people and not matched applicants \n",
    "nm_apps = get_nonmatched(apps5, id_colname=RAW_CARD_ID, matched_ids=match5[RAW_CARD_ID].dropna().values)\n",
    "nm_NIH = get_nonmatched(NIH, id_colname=NIH_ID, matched_ids=match5[NIH_ID].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do another round of matching just on last name\n",
    "nm_match1 = df_get_closest_matches(nm_apps, nm_NIH, 'clean_last_name', suffixes=['_x', '_y']) \n",
    "print nm_match1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_match(row):\n",
    "    app_eod_year_diff = abs(row['application_year'] - row['eod_year'])\n",
    "    if app_eod_year_diff > 8:\n",
    "        return 0\n",
    "    \n",
    "    # the first and middle name seem to be mixed up in index card data set\n",
    "    mixed_sim1 =  get_name_str_sim(row[['clean_middle_name_x', 'clean_first_name_y']])\n",
    "    mixed_sim2 =  get_name_str_sim(row[['clean_middle_name_y', 'clean_first_name_x']])\n",
    "    \n",
    "    max_name_sim = max(row['clean_first_name_sim'], row['medical_school_sim'], row['clean_middle_name_sim'])\n",
    "    if max_name_sim < 60:\n",
    "        return 0\n",
    "    mix_sim = max(mixed_sim1, mixed_sim2)\n",
    "    if pd.isnull(mix_sim):\n",
    "        mix_sim = 0\n",
    "    if (mix_sim > 90) and row['medical_school_sim'] > 60:\n",
    "        return 1\n",
    "    if (mix_sim > 90) and pd.isnull(row['medical_school_sim']) and (app_eod_year_diff < 6):\n",
    "        return 1\n",
    "    if not pd.isnull(row['clean_first_name_sim']) and row['clean_first_name_sim'] < 40:\n",
    "        return 0\n",
    "    # if matching application year and med schools match\n",
    "    if (app_eod_year_diff < 6) and row['medical_school_sim'] > 80:\n",
    "        return 1\n",
    "    if not pd.isnull(row['medical_school_sim']) and row['medical_school_sim'] < 40:\n",
    "        return 0\n",
    "    # first and middle names match or first\n",
    "    if (app_eod_year_diff < 6) and row['clean_first_name_sim'] > 80:\n",
    "        return 1\n",
    "    # first and middle names match or first\n",
    "    if (app_eod_year_diff < 6) and row['clean_middle_name_sim'] > 80:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nm_feature_dict = {\n",
    "    'clean_first_name': get_name_str_sim,\n",
    "    'clean_middle_name': get_name_str_sim,\n",
    "    'medical_school': get_name_str_sim,\n",
    "}\n",
    "\n",
    "nm_match2 = add_similarity_features(nm_match1, nm_feature_dict, check_match, suffixes=['_x', '_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nm_match3 = nm_match2.loc[(nm_match2.is_match==1) & (nm_match2.index!='MORTON'), :].reset_index(\n",
    "    drop=False).rename(columns={'index': 'clean_last_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# append matches together\n",
    "match6 = pd.concat([nm_match3, match5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get nonmatched NIH people and not matched applicants \n",
    "nm_apps2 = get_nonmatched(apps5, id_colname=RAW_CARD_ID, matched_ids=match6[RAW_CARD_ID].dropna().values)\n",
    "nm_NIH2 = get_nonmatched(NIH, id_colname=NIH_ID, matched_ids=match6[NIH_ID].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nm_NIH3 = nm_NIH2.loc[\n",
    "    (nm_NIH2.eod_year< 1976) & (\n",
    "        nm_NIH2.eod_year>1963), NAME_COLS+['medical_school', 'eod_year']].sort_values('clean_last_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apps_match = nm_apps2.loc[nm_apps2.clean_last_name.isin(nm_NIH3.clean_last_name.values)]\n",
    "test_merge = pd.merge(left=nm_NIH3, right=apps_match, on='clean_last_name', how='inner').sort_values('clean_last_name')\n",
    "test_merge = test_merge[sorted(test_merge.columns)]\n",
    "if OUTPUT_CSV:\n",
    "    test_merge.to_csv(os.path.join(CORRECTIONS_DIR, 'test_merge_missing_NIH.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match6.loc[pd.isnull(match6.clean_last_name), 'clean_last_name'] =  match6.loc[\n",
    "    pd.isnull(match6.clean_last_name), 'clean_last_name_x']\n",
    "to_drop = [c for c in match6.columns if c.endswith('_sim') or '_counts' in c]\n",
    "match7= match6.drop(to_drop+[\n",
    "        'dup_flag', 'eod_year_diff', 'fuzzy_merge_col_x', 'fuzzy_merge_col_y', 'unknown',\n",
    "        'Unnamed: 0', 'raw_uuid_duplicate', 'dno_duplicate', 'count_missing',\n",
    "                'clean_last_name_x', 'clean_last_name_y', 'is_match'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# consolidate columns in match6\n",
    "match7a = consolidate_merge_cols(match7, ['_x', '_y'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'age', 'application_date', 'application_year', 'application_year_1', 'application_year_2', 'application_year_3', 'associate_program_entered', 'bob', 'ca', 'cc', 'citizenship', 'city', 'clean_college_trans', 'clean_first_initial', 'clean_first_name', 'clean_last_name', 'clean_middle_initial', 'clean_middle_name', 'clean_suffix', 'clinical', 'cord', 'data_source', 'date_of_birth', 'dbs', 'dno', 'dob', 'duplicate_dno', 'eod_year', 'fifth', 'first_name', 'fuzzy_merge_col', 'generation', 'honor_societies_first', 'honor_societies_fourth', 'honor_societies_second', 'honor_societies_third', 'ic', 'index', 'institute', 'intern_dates', 'internship_hospital', 'internship_year(s)', 'is_female', 'is_match', 'lab_brch', 'last_name', 'last_name_counts', 'level_0', 'med_school', 'medical_school', 'medschool_year_grad', 'middle_name', 'nci', 'nei', 'nhi', 'nhli', 'niaid', 'niamd', 'niamdd', 'nichd', 'nichhd', 'nidr', 'niehs', 'nigms', 'nimh', 'nindb', 'ninds', 'oir', 'original_medical_school', 'other', 'person_uuid', 'pharm_ra', 'pi', 'program', 'ra', 'raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'raw_uuid_4', 'raw_uuid_5', 'rejected', 'rejection_date', 'res_dates', 'research', 'residency', 'residency_hospital', 'residency_year(s)', 'reviewer', 'sa', 'sixth', 'source', 'ssn', 'state', 'supervisor', 'teaching', 'undergrad_year_grad', 'undergraduate_school', 'withdrawal', 'year_accepted', 'year_grad', 'zip_code']\n",
      "(3983, 103)\n",
      "time: 47.6 ms\n"
     ]
    }
   ],
   "source": [
    "match8 = pd.concat([\n",
    "        man_dno[~pd.isnull(man_dno['dno'])], match7a, apps4.loc[~apps4[PERSON_ID].isin(match7a[PERSON_ID].values),:]], axis=0)\n",
    "print sorted(match8.columns)\n",
    "print match8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date_of_birth, dob]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.1 ms\n"
     ]
    }
   ],
   "source": [
    "# replace date of birth with dob whenever date of birth missing and dob is not\n",
    "match8.loc[\n",
    "    (pd.isnull(match8['date_of_birth'])) & (~pd.isnull(match8['dob'])), 'date_of_birth'] = match8.loc[\n",
    "        (pd.isnull(match8['date_of_birth'])) & (~pd.isnull(match8['dob'])), 'dob']\n",
    "\n",
    "\n",
    "c1 = 'date_of_birth'\n",
    "c2 = 'dob'\n",
    "match8.loc[(pd.isnull(match8[c1])) & (~pd.isnull(match8[c2])), [c1, c2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'age', 'application_date', 'application_year', 'application_year_1', 'application_year_2', 'application_year_3', 'associate_program_entered', 'bob', 'ca', 'cc', 'citizenship', 'city', 'clean_college_trans', 'clean_first_initial', 'clean_first_name', 'clean_last_name', 'clean_middle_initial', 'clean_middle_name', 'clean_suffix', 'clinical', 'cord', 'data_source', 'date_of_birth', 'dbs', 'dno', 'duplicate_dno', 'eod_year', 'fifth', 'first_name', 'fuzzy_merge_col', 'generation', 'honor_societies_first', 'honor_societies_fourth', 'honor_societies_second', 'honor_societies_third', 'ic', 'index', 'institute', 'intern_dates', 'internship_hospital', 'internship_year(s)', 'is_female', 'is_match', 'lab_brch', 'last_name', 'last_name_counts', 'level_0', 'med_school', 'medical_school', 'medschool_year_grad', 'middle_name', 'nci', 'nei', 'nhi', 'nhli', 'niaid', 'niamd', 'niamdd', 'nichd', 'nichhd', 'nidr', 'niehs', 'nigms', 'nimh', 'nindb', 'ninds', 'oir', 'original_medical_school', 'other', 'person_uuid', 'pharm_ra', 'pi', 'program', 'ra', 'raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'raw_uuid_4', 'raw_uuid_5', 'rejected', 'rejection_date', 'res_dates', 'research', 'residency', 'residency_hospital', 'residency_year(s)', 'reviewer', 'sa', 'sixth', 'source', 'ssn', 'state', 'supervisor', 'teaching', 'undergrad_year_grad', 'undergraduate_school', 'withdrawal', 'year_accepted', 'year_grad', 'zip_code']\n",
      "(3987, 102)\n",
      "time: 16.3 ms\n"
     ]
    }
   ],
   "source": [
    "match9 = match8.drop(['dob'], axis=1)\n",
    "print sorted(match9.columns)\n",
    "print match9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "match9['control_flag'] = 0\n",
    "match9.loc[pd.isnull(match9.dno) & pd.isnull(match9.year_accepted), 'control_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "match9.rename(columns={'res_dates': 'residency_dates', 'intern_dates': 'internship_dates', \n",
    "                      'clean_college_trans': 'clean_college'}, inplace=True)\n",
    "\n",
    "IMPORTANT_COLS = [NIH_ID, PERSON_ID, 'application_year', 'eod_year', 'application_date', 'clean_first_name', 'clean_middle_name', \n",
    "                 'clean_last_name', 'control_flag', 'year_accepted', 'rejected', 'rejection_date', 'clean_college', 'medical_school',\n",
    "                'residency_dates', 'internship_dates']\n",
    "\n",
    "other_cols = sorted([i for i in match9.columns if i not in IMPORTANT_COLS])\n",
    "\n",
    "# order columns so important ones are \n",
    "match10 = match9[IMPORTANT_COLS+other_cols].sort_values(['clean_last_name', 'application_year'])\n",
    "\n",
    "match11 = match10.dropna(subset=[PERSON_ID], axis=0).sort_values(['clean_last_name', 'clean_first_name'])\n",
    "\n",
    "# wide_apps5.to_pickle(os.path.join(APP_DATA_DIR, 'all_apps_plus_NIH_info.p'))\n",
    "match11.to_csv(os.path.join(APP_DATA_DIR, 'fuzzy_all_apps_plus_NIH_info.csv'), index=False)\n",
    "\n",
    "wide_apps_v = match11.loc[(match11.application_year>1960) & (match11.application_year<1976), :].sort_values(\n",
    "    ['clean_last_name', 'application_date'])\n",
    "\n",
    "wide_apps_v.to_pickle(os.path.join(PICKLE_DIR, 'fuzzy_all_apps_plus_NIH_info_vietnam.p'))\n",
    "\n",
    "wide_apps_v.to_csv(os.path.join(APP_DATA_DIR, 'fuzzy_all_apps_plus_NIH_info_vietnam.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>person_uuid</th>\n",
       "      <th>medical_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RICHARD ALAN BENDER</th>\n",
       "      <td>ALAN</td>\n",
       "      <td>BENDER</td>\n",
       "      <td>RICHARD</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>UCLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    clean_middle_name clean_last_name clean_first_name  \\\n",
       "RICHARD ALAN BENDER              ALAN          BENDER          RICHARD   \n",
       "\n",
       "                     person_uuid medical_school  \n",
       "RICHARD ALAN BENDER       2784.0          UCLA   "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.3 ms\n"
     ]
    }
   ],
   "source": [
    "ln = 'BENDER'\n",
    "wide_apps_v.loc[wide_apps_v.clean_last_name==ln, NAME_COLS+[PERSON_ID, 'medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
