{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "from fuzzywuzzy import fuzz\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import string\n",
    "import funcy\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from data_cleaning_functions import (trans_remov_punc, standardize_whitespace, remove_punc, remove_suffix_from_last_name,\n",
    "                                     clean_names, has_award, has_suffix, get_suffix, replace_last_name, \n",
    "                                     is_year_range, str_sim, clean_med_school, clean_std_college_name)\n",
    "\n",
    "from dev import (\n",
    "    APP_DATA_DIR, SUM_STAT_DIR, CARD_DATA_DIR, CORRECTIONS_DIR, AWARDS_KEYWORDS, NAME_COLS, RAW_NAME_COLS, \n",
    "    RAW_CARD_ID, RAW_INDEX_IDS, PERSON_APPLICATION_ID, PERSON_ID, NIH_ID, FEMALE_FIRST_NAMES, FEMALE_MIDDLE_NAMES, \n",
    "    PICKLE_DIR)\n",
    "\n",
    "from merging_functions import *\n",
    "\n",
    "OUTPUT_CSV = True \n",
    "RAW_APPLICANT_DATA_FILENAME = 'raw_applicant_card_data.csv'\n",
    "MISSING_APPDATE_FILENAME = 'index_cards_no_application_date.csv'\n",
    "APP_SPELLING_CORRECTIONS = 'index_card_manual_corrections.xlsx'\n",
    "\n",
    "\n",
    "PERSONAL_INFO = [\n",
    "    'clean_first_name', 'clean_last_name', 'clean_middle_name',\n",
    "    'date_of_birth', 'medical_school', 'clean_college_trans']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/frame.py:2378: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "all_appcards2 = pd.read_csv(os.path.join(CARD_DATA_DIR, RAW_APPLICANT_DATA_FILENAME))\n",
    "\n",
    "# drop all rows with first, last name NA\n",
    "all_app3 = all_appcards2.dropna(subset=['application_date'], how='all')\n",
    "\n",
    "\n",
    "def id_poorlyfmtdates(str_date):\n",
    "    try:\n",
    "        dt = pd.to_datetime(str_date, format='%m/%d/%Y')\n",
    "        return True\n",
    "    except (ValueError, AssertionError):\n",
    "        return False\n",
    "\n",
    "mask = all_app3.application_date.apply(id_poorlyfmtdates)\n",
    "# all_app3.loc[~mask, :]\n",
    "\n",
    "# change '3/31971 to 3/3/1971\n",
    "# change 41/8/1966 to 4/8/1966 \n",
    "all_app3.loc[all_app3.application_date=='3/31971', 'application_date'] = '3/3/1971'\n",
    "all_app3.loc[all_app3.application_date=='41/8/1966', 'application_date'] = '4/8/1966'\n",
    "\n",
    "# convert application date to date object\n",
    "all_app3.loc[:, 'application_date'] = all_app3['application_date'].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "# do the same date check for birth date columns\n",
    "bdate_mask = all_app3.date_of_birth.apply(id_poorlyfmtdates)\n",
    "all_app3.loc[~bdate_mask, ['first_name', 'last_name', 'date_of_birth']]\n",
    "all_app3.loc[(\n",
    "        all_app3.last_name=='Cook') & \n",
    "                  (all_app3.middle_name=='James') & \n",
    "                  (all_app3.first_name.isnull()), 'date_of_birth'] = '1/27/1940'\n",
    "\n",
    "all_app3[NAME_COLS] = all_app3[RAW_NAME_COLS].applymap(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_app3.loc[(all_app3.clean_last_name=='RUBENSTEIN') & (all_app3.clean_middle_name=='ALLAN'), 'application_date'] = pd.to_datetime('1/21/1973')\n",
    "\n",
    "all_app3.loc[(\n",
    "        all_app3.clean_last_name=='ROOT') & \n",
    "                  (all_app3.clean_first_name=='RICHARD'), 'application_date'] = pd.to_datetime('5/23/1963')\n",
    "\n",
    "all_app3.loc[(\n",
    "        all_app3.clean_last_name=='FREIDMAN') & (all_app3.clean_first_name=='STANFORD'), 'application_date'] = pd.to_datetime('01/01/1960')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "all_app3.rename(columns={'medical_school':'original_medical_school'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lraymond/MIT/Azoulay_2016/yellow_berets/yb/local/lib/python2.7/site-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['honor_societies_first', 'honor_societies_fourth', 'honor_societies_second', 'honor_societies_third']\n"
     ]
    }
   ],
   "source": [
    "# deal with suffixes and honors\n",
    "suffix_mask = all_app3.clean_last_name.apply(has_suffix)\n",
    "# all_app_short.loc[suffix_mask, ['clean_last_name', 'clean_first_name', 'clean_middle_name']]\n",
    "\n",
    "# for those last names that seem to have a suffix, pull into seperate column and keep everything last word of last name\n",
    "all_app3.loc[suffix_mask, 'clean_suffix'] = all_app3.loc[suffix_mask, 'clean_last_name'].apply(get_suffix)\n",
    "all_app3.loc[suffix_mask, 'clean_last_name'] = all_app3.loc[suffix_mask, 'clean_last_name'].apply(remove_suffix_from_last_name)\n",
    "\n",
    "# some first names also contain some honors such as 'Pfizer Award' or 'Honor Society'\n",
    "# these should be pulled into the honors and awards columns\n",
    "has_award_fnc = funcy.rpartial(has_award, AWARDS_KEYWORDS)\n",
    "\n",
    "\n",
    "# get a list of all the med school honors columns\n",
    "honors_columns = [c for c in all_app3.columns if 'honor' in c]\n",
    "print honors_columns\n",
    "\n",
    "has_award_mask = all_app3['clean_first_name'].apply(has_award_fnc)\n",
    "\n",
    "all_app3.loc[has_award_mask, 'extra_honor'] = all_app3.loc[has_award_mask, 'clean_first_name']\n",
    "\n",
    "# create column mask for each row where one of the honors columns is blank\n",
    "for hc in honors_columns:\n",
    "    hc_mask = (has_award_mask) & (pd.isnull(all_app3[hc]))\n",
    "    all_app3.loc[hc_mask, hc] = all_app3.loc[hc_mask, 'extra_honor']\n",
    "# check for any columns that already have full honors and cant be filled\n",
    "all_app3.loc[hc_mask, honors_columns].dropna(how='any')\n",
    "\n",
    "# drop extra honor columns\n",
    "all_app4 = all_app3.drop('extra_honor', axis=1)\n",
    "\n",
    "# replace those honors first names with np.nan\n",
    "all_app4.loc[has_award_mask, 'clean_first_name'] = np.nan\n",
    "\n",
    "# for those columns where med school is equal to last name or med_school is a year range, delete\n",
    "med_school_str_sim = funcy.rpartial(str_sim, 'medical_school', 'clean_last_name')\n",
    "all_app4.loc[:, 'school_name_sim'] = all_app4.loc[:, ['clean_last_name', 'medical_school']].apply(med_school_str_sim, axis=1)\n",
    "\n",
    "all_app4.loc[all_app4.school_name_sim > .6, :]\n",
    "\n",
    "all_app4.loc[:, 'clean_college'] = all_app4.undergraduate_school.apply(clean_names)\n",
    "\n",
    "to_remove_college = [\n",
    "    ' AND ', ' AT ', 'THE ', ' COLLGE', 'UNIVERISTY', 'UNIVERWSITY', 'MASSACHUSSETTS', 'JOHN ', 'DE PAUW', 'ASBURY', \n",
    "'DREXEL INSTITUTE OF TECHNOLOGY', 'A B BROWN UNIVERSITY', 'DARTMOUTH MEDICAL SCHOOL', 'RENSSELAER UNIVERSITY', \n",
    "'RENSSELAER POLYTECHNICAL INSTITUTE', ' STE', 'COLLEGE OF HOLY CROSS', 'HOLLY CROSS', 'JOHNSS ',  'BERKLEY',\n",
    "'UC ', 'PITTSBURRGH', 'WESLYN', 'WILLAMS', 'GEORGIA TECH', 'NEW YORK UNIVERSITY UNIV', \n",
    "'UNIVERSITY OF MICHIGAN IS A', 'OHIO', 'STATE UNIVERSITY OF NEW YORK AT BUFFALO']\n",
    "to_replace_college = [\n",
    "    ' ', ' ', ' ', ' COLLEGE', 'UNIVERSITY', 'UNIVERSITY', 'MASSACHUSETTS', 'JOHNS ', 'DEPAUW', 'ASHBURY',\n",
    "    'DREXEL UNIVERSITY', 'BROWN UNIVERSITY', 'DARTMOUTH', 'RENSSELAER POLYTECHNIC INSTITUTE', \n",
    "    'RENSSELAER POLYTECHNIC INSTITUTE', ' STATE', 'HOLY CROSS', 'HOLY CROSS', 'JOHNS ', \n",
    "    ' BERKELEY', 'UNIVERSITY OF CALIFORNIA ', 'PITTSBURGH', 'WESLEYAN', 'WILLIAMS', \n",
    "    'GEORGIA INSTITUTE OF TECHNOLOGY', 'NEW YORK', 'UNIVERSITY OF MICHIGAN', 'OHIO STATE', 'SUNY BUFFALO']\n",
    "\n",
    "clean_college_fnc = funcy.rpartial(clean_std_college_name, to_remove_college, to_replace_college)\n",
    "\n",
    "# make college mispelling and different reference translation table\n",
    "all_app4.loc[:, 'clean_college_trans'] = all_app4.clean_college.apply(clean_college_fnc)\n",
    "\n",
    "all_app4.drop(['clean_college', 'school_name_sim'], axis=1, inplace=True)\n",
    "\n",
    "all_app4.loc[:, 'medical_school'] = all_app4.original_medical_school.apply(funcy.rcompose(clean_names, clean_med_school))\n",
    "\n",
    "all_app4.medical_school.sort_values().unique()\n",
    "\n",
    "all_app4.loc[pd.isnull(all_app4.medical_school), 'medical_school'] = np.nan\n",
    "\n",
    "# need to convert undergrad_year_grad and med_school_grad to numbers to maintain consistency\n",
    "all_app4.loc[:, ['undergrad_year_grad', 'medschool_year_grad']] = all_app4.loc[:, ['undergrad_year_grad', 'medschool_year_grad']].apply(\n",
    "    lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "# now, sort by names, med school, undergrad school, \n",
    "all_app5 = all_app4.sort_values(by=PERSONAL_INFO)\n",
    "\n",
    "# LAST_NAME_MISSPELLINGS = {\n",
    "#         'HOMCY': 'HOMEY', 'DROBIS': 'DROBIN', 'DEFRONZO':'DEFRENZO', \n",
    "#         'BRADEN 3R': 'BRADEN', 'BORKER': 'BORER', 'CASTLES': 'CASTLE',\n",
    "#         'CUONO': 'CUOMO', 'CYRULNIK': 'CYRULINK', 'EISENBATH': 'EISENBARTH', \n",
    "#         'ELLIOTT': 'ELIOT', 'FINKLESTEIN': 'FINKELSTEIN', 'HEINRICK': 'HEINRICH', \n",
    "#         'HERLIKY': 'HERLIHY', 'HIMMELHOCK': 'HIMMELHOCH', 'JANOWSKY': 'JANKOWSKY', \n",
    "#         'KLINENBERG': 'KLINEBERG', 'KORNFELD': 'KORNFIELD', 'NEIDORF': 'NEIDOFT',\n",
    "#         'OLEINICK': 'OLENICK', 'ROSKES': 'ROSKE'\n",
    "# }\n",
    "# removed CUONO, DROBIS, \n",
    "\n",
    "\n",
    "LAST_NAME_MISSPELLINGS = {\n",
    "        'HOMCY': 'HOMEY', \n",
    "        'BRADEN 3R': 'BRADEN', 'BORKER': 'BORER', 'CASTLES': 'CASTLE',\n",
    "        'CYRULNIK': 'CYRULINK', 'EISENBATH': 'EISENBARTH', \n",
    "        'HEINRICK': 'HEINRICH', \n",
    "        'HERLIKY': 'HERLIHY', 'HIMMELHOCK': 'HIMMELHOCH', 'JANOWSKY': 'JANKOWSKY', \n",
    "        'KLINENBERG': 'KLINEBERG', 'KORNFELD': 'KORNFIELD', 'NEIDORF': 'NEIDOFT',\n",
    "        'OLEINICK': 'OLENICK', 'ROSKES': 'ROSKE'\n",
    "}\n",
    "\n",
    "replace_last_name_fnc = funcy.rpartial(replace_last_name, LAST_NAME_MISSPELLINGS)\n",
    "\n",
    "# correct last name mispellings\n",
    "all_app5.loc[:, 'clean_last_name'] = all_app5.loc[:, 'clean_last_name'].apply(replace_last_name_fnc)\n",
    "all_app5.loc[all_app5.clean_last_name=='MORTON', 'clean_first_name'] = 'JOHN'\n",
    "\n",
    "# convert ca column to float62\n",
    "all_app5.loc[:, 'ca'] = all_app5.loc[:, 'ca'].apply(lambda x: pd.to_numeric(x, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_mask = (\n",
    "    (all_app5['clean_first_name'].isin(FEMALE_FIRST_NAMES)))\n",
    "#     | (\n",
    "#         all_app5['clean_middle_name'].isin(FEMALE_MIDDLE_NAMES)))\n",
    "all_app5['is_female'] = 0\n",
    "all_app5.loc[female_mask & ~pd.isnull(all_app5['clean_first_name']), 'is_female'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_app5 = all_app5[all_app5.is_female==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_first_letter(str_var):\n",
    "    if pd.isnull(str_var) or str_var=='':\n",
    "        return np.nan\n",
    "    return str_var[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_names = 'BROWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>medical_school</th>\n",
       "      <th>medschool_grad_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>BEN</td>\n",
       "      <td>MAURICE</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>BRUCE</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>CLARENCE</td>\n",
       "      <td>H</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>EMORY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>DONALD</td>\n",
       "      <td>D</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>UNIVERSITY OF CHICAGO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>EDWARD</td>\n",
       "      <td>MEIGS</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>ERIC</td>\n",
       "      <td>JOEL</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>FRANK</td>\n",
       "      <td>R</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>EDWARD</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>YALE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>KINGSBURY</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>MANUEL</td>\n",
       "      <td>LAWRENCE</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>WAYNE STATE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>STUART</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>PENNSLYVANIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>MURRAY</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>SUNY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>NEIL</td>\n",
       "      <td>C</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>N</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>RALPH</td>\n",
       "      <td>STUART</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>RICHARD</td>\n",
       "      <td>JOEL</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>S</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>COLUMBIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>STICKLER</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>IOWA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>T</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>TEMPLE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>MORRIS</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>TORREY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>VIRGIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>YALE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>WALTER</td>\n",
       "      <td>ARMIN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>DUKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>WILLIS</td>\n",
       "      <td>E</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>VANDERBILT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ALAN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>SUNY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ARMIN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>DUKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>UNIVERSITY OF CHICAGO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>VANDERBILT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EDWARD</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>YALE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GREGORY</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>EMORY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JOEL</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JOEL</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KINGSBURY</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LAWRENCE</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>WAYNE STATE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MAURICE</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>STANFORD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MEIGS</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MEIGS</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MORRIS</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>COLUMBIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STICKLER</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>IOWA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STUART</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>PENNSLYVANIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STUART</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>TEMPLE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>NaN</td>\n",
       "      <td>VIRGIL</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>YALE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>JOHNS HOPKINS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clean_first_name clean_middle_name clean_last_name  \\\n",
       "4073              BEN           MAURICE           BROWN   \n",
       "4043            BRUCE           GREGORY           BROWN   \n",
       "3972         CLARENCE                 H           BROWN   \n",
       "3843           DONALD                 D           BROWN   \n",
       "4126           EDWARD             MEIGS           BROWN   \n",
       "4208             ERIC              JOEL           BROWN   \n",
       "4209            FRANK                 R           BROWN   \n",
       "3999            JAMES              ALAN           BROWN   \n",
       "3973            JAMES            EDWARD           BROWN   \n",
       "4163            JAMES         KINGSBURY           BROWN   \n",
       "3882          KENNETH               NaN           BROWN   \n",
       "4165           MANUEL          LAWRENCE           BROWN   \n",
       "3974          MICHAEL            STUART           BROWN   \n",
       "4074           MURRAY             ALLEN           BROWN   \n",
       "3883             NEIL                 C           BROWN   \n",
       "3915             PAUL                 N           BROWN   \n",
       "4127            RALPH            STUART           BROWN   \n",
       "4019          RICHARD              JOEL           BROWN   \n",
       "3916           ROBERT                 S           BROWN   \n",
       "4020           ROBERT          STICKLER           BROWN   \n",
       "4128           ROBERT                 T           BROWN   \n",
       "3975          STEPHEN            MORRIS           BROWN   \n",
       "3884           TORREY               NaN           BROWN   \n",
       "3938           VIRGIL               NaN           BROWN   \n",
       "4000           WALTER             ARMIN           BROWN   \n",
       "3917           WILLIS                 E           BROWN   \n",
       "300               NaN              ALAN           BROWN   \n",
       "377               NaN             ALLEN           BROWN   \n",
       "301               NaN             ARMIN           BROWN   \n",
       "183               NaN                 C           BROWN   \n",
       "139               NaN                 D           BROWN   \n",
       "218               NaN                 E           BROWN   \n",
       "274               NaN            EDWARD           BROWN   \n",
       "344               NaN           GREGORY           BROWN   \n",
       "273               NaN                 H           BROWN   \n",
       "517               NaN              JOEL           BROWN   \n",
       "320               NaN              JOEL           BROWN   \n",
       "466               NaN         KINGSBURY           BROWN   \n",
       "467               NaN          LAWRENCE           BROWN   \n",
       "375               NaN           MAURICE           BROWN   \n",
       "428               NaN             MEIGS           BROWN   \n",
       "429               NaN             MEIGS           BROWN   \n",
       "276               NaN            MORRIS           BROWN   \n",
       "216               NaN                 N           BROWN   \n",
       "518               NaN                 R           BROWN   \n",
       "217               NaN                 S           BROWN   \n",
       "321               NaN          STICKLER           BROWN   \n",
       "275               NaN            STUART           BROWN   \n",
       "430               NaN            STUART           BROWN   \n",
       "431               NaN                 T           BROWN   \n",
       "239               NaN            VIRGIL           BROWN   \n",
       "376               NaN                 W           BROWN   \n",
       "184               NaN               NaN           BROWN   \n",
       "182               NaN               NaN           BROWN   \n",
       "\n",
       "             medical_school  medschool_grad_year  \n",
       "4073               STANFORD                  NaN  \n",
       "4043          JOHNS HOPKINS                  NaN  \n",
       "3972                  EMORY                  NaN  \n",
       "3843  UNIVERSITY OF CHICAGO                  NaN  \n",
       "4126                HARVARD                  NaN  \n",
       "4208                HARVARD                  NaN  \n",
       "4209             WASHINGTON                  NaN  \n",
       "3999              ROCHESTER                  NaN  \n",
       "3973                   YALE                  NaN  \n",
       "4163          JOHNS HOPKINS                  NaN  \n",
       "3882                    NaN                  NaN  \n",
       "4165            WAYNE STATE                  NaN  \n",
       "3974           PENNSLYVANIA                  NaN  \n",
       "4074                   SUNY                  NaN  \n",
       "3883                 ALBANY                  NaN  \n",
       "3915                    NaN                  NaN  \n",
       "4127          JOHNS HOPKINS                  NaN  \n",
       "4019               STANFORD                  NaN  \n",
       "3916               COLUMBIA                  NaN  \n",
       "4020                   IOWA                  NaN  \n",
       "4128                 TEMPLE                  NaN  \n",
       "3975                HARVARD                  NaN  \n",
       "3884          JOHNS HOPKINS                  NaN  \n",
       "3938                   YALE                  NaN  \n",
       "4000                   DUKE                  NaN  \n",
       "3917             VANDERBILT                  NaN  \n",
       "300               ROCHESTER                  NaN  \n",
       "377                    SUNY                  NaN  \n",
       "301                    DUKE                  NaN  \n",
       "183                  ALBANY                  NaN  \n",
       "139   UNIVERSITY OF CHICAGO                  NaN  \n",
       "218              VANDERBILT                  NaN  \n",
       "274                    YALE                  NaN  \n",
       "344           JOHNS HOPKINS                  NaN  \n",
       "273                   EMORY                  NaN  \n",
       "517                 HARVARD                  NaN  \n",
       "320                STANFORD                  NaN  \n",
       "466           JOHNS HOPKINS                  NaN  \n",
       "467             WAYNE STATE                  NaN  \n",
       "375                STANFORD                  NaN  \n",
       "428                 HARVARD                  NaN  \n",
       "429                 HARVARD                  NaN  \n",
       "276                 HARVARD                  NaN  \n",
       "216                     NaN                  NaN  \n",
       "518              WASHINGTON                  NaN  \n",
       "217                COLUMBIA                  NaN  \n",
       "321                    IOWA                  NaN  \n",
       "275            PENNSLYVANIA                  NaN  \n",
       "430           JOHNS HOPKINS                  NaN  \n",
       "431                  TEMPLE                  NaN  \n",
       "239                    YALE                  NaN  \n",
       "376                 INDIANA                  NaN  \n",
       "184           JOHNS HOPKINS                  NaN  \n",
       "182                     NaN                  NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_app5.loc[all_app5.clean_last_name==last_names, NAME_COLS+['medical_school', 'medschool_grad_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge in manual corrections excel sheet\n",
    "manual_fixes = pd.read_excel(os.path.join(CORRECTIONS_DIR, 'index_card_manual_corrections.xlsx')).rename(\n",
    "    columns={\n",
    "        'clean_medical_school': 'medical_school', \n",
    "        'to_fix_clean_medical_school': 'to_fix_medical_school'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = filter(lambda x: '_year' not in x, manual_fixes.columns)\n",
    "manual_fixes.loc[:, c] = manual_fixes[c].applymap(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manual_fixes\n",
    "# manual_fixes[manual_fixes.clean_last_name=='ARON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 9)\n",
      "(328, 78)\n"
     ]
    }
   ],
   "source": [
    "# for the people who match, consolidate the columns\n",
    "\n",
    "missing_names = pd.merge(\n",
    "    left=all_app5, right=manual_fixes, on=['clean_first_name', 'clean_middle_name', 'clean_last_name', 'medical_school'], how='inner')\n",
    "\n",
    "print manual_fixes.shape\n",
    "print missing_names.shape\n",
    "# consolidate columns\n",
    "for x in ['medical_school', 'clean_first_name', 'clean_middle_name', 'medschool_year_grad']:\n",
    "    mask = ~pd.isnull(missing_names['to_fix_{}'.format(x)])\n",
    "    missing_names.loc[mask, x] = missing_names.loc[mask, 'to_fix_{}'.format(x)]\n",
    "    \n",
    "    \n",
    "# drop extra columns\n",
    "missing_names2 = missing_names.drop(\n",
    "    (c for c in missing_names.columns if c not in all_app5.columns), axis=1).drop_duplicates([RAW_CARD_ID])\n",
    "\n",
    "all_app6  = pd.concat(\n",
    "    [all_app5.loc[~all_app5[RAW_CARD_ID].isin(missing_names2[RAW_CARD_ID]), :], missing_names2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>medical_school</th>\n",
       "      <th>to_fix_clean_first_name</th>\n",
       "      <th>to_fix_clean_middle_name</th>\n",
       "      <th>to_fix_clean_last_name</th>\n",
       "      <th>to_fix_medical_school</th>\n",
       "      <th>to_fix_medschool_year_grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DANFORTH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DANFORTH</td>\n",
       "      <td>NORTHWESTERN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>DAVIE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>C</td>\n",
       "      <td>DAVIE</td>\n",
       "      <td>UNIVERSITY OF ALABAMA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JOHN A</td>\n",
       "      <td>DAVIES</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>PETER</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>DAVIES</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>PETER</td>\n",
       "      <td>RONALD</td>\n",
       "      <td>DEAL</td>\n",
       "      <td>EMORY</td>\n",
       "      <td>DAVEY</td>\n",
       "      <td>RONALD</td>\n",
       "      <td>DEAL</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>DEFRONZO</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>RALPH</td>\n",
       "      <td>A</td>\n",
       "      <td>DEFRENZO</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>DELONG</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>DELONG</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>G</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>DELONG</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>DELONG</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>DELONG</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>MAHLON</td>\n",
       "      <td>R</td>\n",
       "      <td>DELONG</td>\n",
       "      <td>HARVARD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DREWS</td>\n",
       "      <td>COLORADO HEALTH SCIENCES CENTER</td>\n",
       "      <td>GENEVIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DREWS</td>\n",
       "      <td>COLORADO HEALTH SCIENCES CENTER</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>DIEZMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DALE</td>\n",
       "      <td>E</td>\n",
       "      <td>DIETZMAN</td>\n",
       "      <td>VERMONT MEDICAL CENTER</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BAYHI</td>\n",
       "      <td>DE KERNION</td>\n",
       "      <td>LOUISIANA STATE</td>\n",
       "      <td>JEAN</td>\n",
       "      <td>BAYHI</td>\n",
       "      <td>DE KERNION</td>\n",
       "      <td>LOUISIANA STATE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>DALE</td>\n",
       "      <td>DON</td>\n",
       "      <td>DROBIS</td>\n",
       "      <td>PENNSLYVANIA</td>\n",
       "      <td>JEFFREY</td>\n",
       "      <td>DONALD</td>\n",
       "      <td>DROBIN</td>\n",
       "      <td>PENNSLYVANIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ROLFE</td>\n",
       "      <td>DEPPERMAN</td>\n",
       "      <td>PENNSLYVANIA</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>ROLFE</td>\n",
       "      <td>DEPPERMAN</td>\n",
       "      <td>PENNSLYVANIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "      <td>DILIBERTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMANUEL</td>\n",
       "      <td>J</td>\n",
       "      <td>DILIBERTO</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clean_first_name clean_middle_name clean_last_name  \\\n",
       "81               NaN               NaN        DANFORTH   \n",
       "104              NaN                 C           DAVIE   \n",
       "105              NaN            JOHN A          DAVIES   \n",
       "106            PETER            RONALD            DEAL   \n",
       "107              NaN                 A        DEFRONZO   \n",
       "108              NaN            ROBERT          DELONG   \n",
       "109                G            ROBERT          DELONG   \n",
       "110              NaN                 R          DELONG   \n",
       "111              NaN               NaN           DREWS   \n",
       "112              NaN                 E         DIEZMAN   \n",
       "113              NaN             BAYHI      DE KERNION   \n",
       "114             DALE               DON          DROBIS   \n",
       "115              NaN             ROLFE       DEPPERMAN   \n",
       "116                                  J       DILIBERTO   \n",
       "\n",
       "                      medical_school to_fix_clean_first_name  \\\n",
       "81                               NaN                   DAVID   \n",
       "104                              NaN                   JAMES   \n",
       "105                            MIAMI                   PETER   \n",
       "106                            EMORY                   DAVEY   \n",
       "107                          HARVARD                   RALPH   \n",
       "108                          HARVARD                  GEORGE   \n",
       "109                          HARVARD                  GEORGE   \n",
       "110                          HARVARD                  MAHLON   \n",
       "111  COLORADO HEALTH SCIENCES CENTER                GENEVIVE   \n",
       "112                              NaN                    DALE   \n",
       "113                  LOUISIANA STATE                    JEAN   \n",
       "114                     PENNSLYVANIA                 JEFFREY   \n",
       "115                     PENNSLYVANIA                 STEPHEN   \n",
       "116                              NaN                 EMANUEL   \n",
       "\n",
       "    to_fix_clean_middle_name to_fix_clean_last_name  \\\n",
       "81                       NaN               DANFORTH   \n",
       "104                        C                  DAVIE   \n",
       "105                     JOHN                 DAVIES   \n",
       "106                   RONALD                   DEAL   \n",
       "107                        A               DEFRENZO   \n",
       "108                   ROBERT                 DELONG   \n",
       "109                   ROBERT                 DELONG   \n",
       "110                        R                 DELONG   \n",
       "111                      NaN                  DREWS   \n",
       "112                        E               DIETZMAN   \n",
       "113                    BAYHI             DE KERNION   \n",
       "114                   DONALD                 DROBIN   \n",
       "115                    ROLFE              DEPPERMAN   \n",
       "116                        J              DILIBERTO   \n",
       "\n",
       "               to_fix_medical_school  to_fix_medschool_year_grad  \n",
       "81                      NORTHWESTERN                         NaN  \n",
       "104            UNIVERSITY OF ALABAMA                         NaN  \n",
       "105                            MIAMI                         NaN  \n",
       "106                         ARKANSAS                         NaN  \n",
       "107                          HARVARD                         NaN  \n",
       "108                          HARVARD                         NaN  \n",
       "109                          HARVARD                         NaN  \n",
       "110                          HARVARD                         NaN  \n",
       "111  COLORADO HEALTH SCIENCES CENTER                         NaN  \n",
       "112           VERMONT MEDICAL CENTER                         NaN  \n",
       "113                  LOUISIANA STATE                         NaN  \n",
       "114                     PENNSLYVANIA                         NaN  \n",
       "115                     PENNSLYVANIA                         NaN  \n",
       "116                        ROCHESTER                         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_fixes.loc[manual_fixes['clean_last_name'].apply(lambda x: False if pd.isnull(x) else x.startswith('D')), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>medical_school</th>\n",
       "      <th>medschool_year_grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>STUART</td>\n",
       "      <td>WOLFISH</td>\n",
       "      <td>NYU</td>\n",
       "      <td>1973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7738</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOLFISH</td>\n",
       "      <td>NYU</td>\n",
       "      <td>1973.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clean_first_name clean_middle_name clean_last_name medical_school  \\\n",
       "7703             PAUL            STUART         WOLFISH            NYU   \n",
       "7738             PAUL               NaN         WOLFISH            NYU   \n",
       "\n",
       "      medschool_year_grad  \n",
       "7703               1973.0  \n",
       "7738               1973.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_name = 'WOLFISH'\n",
    "\n",
    "\n",
    "# f_name = 'ADAM'\n",
    "# m_name = 'NORMAN'\n",
    "# all_app5.loc[(\n",
    "#         all_app5.clean_first_name==f_name) & (all_app5.clean_middle_name==m_name), NAME_COLS+['medical_school', 'residency_hospital', 'internship_hospital_1']]\n",
    "all_app5.loc[all_app5.clean_last_name==last_name, NAME_COLS+['medical_school', 'residency_hospital', 'internship_hospital_1']]\n",
    "# missing_names.loc[missing_names.clean_last_name==last_name, NAME_COLS+['medical_school']]\n",
    "# manual_fixes.loc[manual_fixes.clean_first_name=='LAWRENCE',  NAME_COLS+['medical_school']]\n",
    "# manual_fixes.loc[manual_fixes.clean_last_name==last_name,  NAME_COLS+['medical_school']]\n",
    "all_app6.loc[all_app6.clean_last_name==last_name,  NAME_COLS+['medical_school', 'medschool_year_grad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_app6['clean_first_initial'] = all_app6.clean_first_name.apply(get_first_letter)\n",
    "all_app6['clean_middle_initial'] = all_app6.clean_middle_name.apply(get_first_letter)\n",
    "all_app6['application_year'] = all_app6.application_date.apply(lambda x: pd.to_datetime(x).year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_app6.loc[(all_app6['application_year'] > 1990) | (all_app6['application_year'] < 1950), 'application_year'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop people with female names and two columns\n",
    "is_female_mask = ((all_app6.clean_first_name.isin(FEMALE_FIRST_NAMES)) | (\n",
    "        all_app6.clean_middle_name.isin(FEMALE_MIDDLE_NAMES)))\n",
    "# RENAME INTERNSHIP HOSPITAL COL\n",
    "all_app7 = all_app6.loc[~is_female_mask, :].drop(['Unnamed: 0',\"daniel's_comments\"], axis=1).rename(\n",
    "    columns={'internship_hospital_1': 'internship_hospital'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into reviewer 1 and 2, and try to match\n",
    "all_app7['fuzzy_merge_col'] = all_app7[\n",
    "    ['clean_first_name', 'clean_middle_name', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "rev2 = df_get_closest_matches(all_app7[all_app7.reviewer==2], all_app7[all_app7.reviewer==1], 'fuzzy_merge_col') \n",
    "\n",
    "\n",
    "feature_dict = {\n",
    "    'clean_first_name': get_name_str_sim,\n",
    "    'clean_middle_name': get_name_str_sim,\n",
    "    'clean_last_name': get_name_str_sim,\n",
    "    'medical_school': get_name_str_sim,\n",
    "    'application_year': get_dt_sim,\n",
    "    'address': get_name_str_sim\n",
    "}\n",
    "\n",
    "rev3 = add_similarity_features(rev2, feature_dict, check_match)\n",
    "\n",
    "rev1_counter = Counter(all_app7[all_app7.reviewer==1].clean_last_name.values)\n",
    "rev2_counter = Counter(all_app7[all_app7.reviewer==2].clean_last_name.values)\n",
    "rev3['last_name_counts_1'] = rev3.clean_last_name_1.apply(lambda x: rev1_counter[x])\n",
    "rev3['last_name_counts_2'] = rev3.clean_last_name_2.apply(lambda x: rev2_counter[x])\n",
    "\n",
    "# now, sort by is_match, similarity scores and only keep 1 uuid from each data set\n",
    "last_name_unique_mask = (\n",
    "    (rev3.last_name_counts_1==1) & (rev3.last_name_counts_2==1) & (\n",
    "        rev3.application_year_sim<4) & (rev3.medical_school_sim > .8))\n",
    "rev3.loc[last_name_unique_mask, 'is_match'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3687.000000\n",
       "mean        0.778953\n",
       "std         0.415008\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: is_match, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev3.is_match.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3687, 155)\n",
      "(3535, 155)\n",
      "                      raw_uuid_1  raw_uuid_3\n",
      "JAMES L SCHERER           7084.0        3493\n",
      "JOHN STONER               7078.0        3487\n",
      "STEPHEN KARAS             5617.0        1971\n",
      "OLIVER WILLIAM JONES      5449.0        1797\n",
      "PAUL HINKES               5308.0        1656\n",
      "MARC A FRADER             4801.0        1134\n",
      "(2847, 157)\n",
      "Empty DataFrame\n",
      "Columns: [raw_uuid_2, raw_uuid_4]\n",
      "Index: []\n",
      "(2845, 159)\n"
     ]
    }
   ],
   "source": [
    "sims_cols = ['medical_school_sim', 'address_sim', 'clean_middle_name_sim', 'clean_first_name_sim']\n",
    "\n",
    "rev4 = rev3.loc[~pd.isnull(rev3.index), :].sort_values([\n",
    "        'raw_uuid_2', 'raw_uuid_1', 'is_match']+sims_cols, ascending=False)\n",
    "print rev3.shape\n",
    "print rev4.shape\n",
    "rev5 = filter_one_match_per_group(rev4, 'raw_uuid_1', {'raw_uuid_2': 'raw_uuid_3'}, sims_cols)\n",
    "print rev5.shape\n",
    "rev6 = filter_one_match_per_group(rev5, 'raw_uuid_2', {'raw_uuid_1': 'raw_uuid_4'}, sims_cols)\n",
    "print rev6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_uuid_2</th>\n",
       "      <th>address_2</th>\n",
       "      <th>age_2</th>\n",
       "      <th>application_date_2</th>\n",
       "      <th>associate_program_entered_2</th>\n",
       "      <th>bob_2</th>\n",
       "      <th>ca_2</th>\n",
       "      <th>cc_2</th>\n",
       "      <th>cord_2</th>\n",
       "      <th>citizenship_2</th>\n",
       "      <th>...</th>\n",
       "      <th>clean_last_name_sim</th>\n",
       "      <th>application_year_sim</th>\n",
       "      <th>address_sim</th>\n",
       "      <th>clean_middle_name_sim</th>\n",
       "      <th>is_match</th>\n",
       "      <th>last_name_counts_1</th>\n",
       "      <th>last_name_counts_2</th>\n",
       "      <th>raw_uuid_1_duplicate</th>\n",
       "      <th>raw_uuid_3</th>\n",
       "      <th>raw_uuid_2_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>447</td>\n",
       "      <td>5710 Chadowes Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      raw_uuid_2           address_2  age_2 application_date_2  \\\n",
       "2486         447  5710 Chadowes Road    NaN         1972-02-25   \n",
       "\n",
       "     associate_program_entered_2  bob_2  ca_2  cc_2  cord_2 citizenship_2  \\\n",
       "2486                         NaN    0.0   1.0   0.0     NaN           NaN   \n",
       "\n",
       "              ...          clean_last_name_sim  application_year_sim  \\\n",
       "2486          ...                        100.0                   0.0   \n",
       "\n",
       "      address_sim clean_middle_name_sim  is_match last_name_counts_1  \\\n",
       "2486        100.0                 100.0         1                  3   \n",
       "\n",
       "     last_name_counts_2  raw_uuid_1_duplicate  raw_uuid_3  \\\n",
       "2486                  3                   0.0         NaN   \n",
       "\n",
       "      raw_uuid_2_duplicate  \n",
       "2486                   0.0  \n",
       "\n",
       "[1 rows x 158 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del rev6['raw_uuid_4']\n",
    "rev6[rev6.clean_last_name_1=='BERG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5696,)\n"
     ]
    }
   ],
   "source": [
    "matched_ids = np.concatenate([\n",
    "        rev6.raw_uuid_1.dropna().unique(), rev6.raw_uuid_2.dropna().unique(), rev6.raw_uuid_3.dropna().unique()], \n",
    "                        axis=0)\n",
    "print matched_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 74)\n",
      "(616, 74)\n"
     ]
    }
   ],
   "source": [
    "# try to merge on middle initial and clean last name\n",
    "\n",
    "unmatched_r1 = get_nonmatched(all_app7[all_app7.reviewer==1], matched_ids, 'raw_uuid')\n",
    "unmatched_r2 = get_nonmatched(all_app7[all_app7.reviewer==2], matched_ids, 'raw_uuid')\n",
    "\n",
    "unmatched_r1['fuzzy_merge_col'] = unmatched_r1[\n",
    "    ['clean_middle_initial', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "unmatched_r2['fuzzy_merge_col'] = unmatched_r2[\n",
    "    ['clean_middle_initial', 'clean_last_name']].apply(create_str_merge, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rev2_counter = Counter(unmatched_r2.clean_last_name.values)\n",
    "rev1_counter = Counter(unmatched_r1.clean_last_name.values)\n",
    "\n",
    "match_round2 = df_get_closest_matches(unmatched_r2, unmatched_r1, 'fuzzy_merge_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "middle_last3 = add_similarity_features(match_round2, feature_dict, check_match)\n",
    "\n",
    "middle_last3['last_name_counts_1'] = middle_last3.clean_last_name_1.apply(lambda x: rev1_counter[x])\n",
    "middle_last3['last_name_counts_2'] = middle_last3.clean_last_name_2.apply(lambda x: rev2_counter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, sort by is_match, similarity scores and only keep 1 uuid from each data set\n",
    "last_name_unique_mask = (\n",
    "    (middle_last3.last_name_counts_1==1) & (middle_last3.last_name_counts_2==1) & (\n",
    "        middle_last3.application_year_sim<2) & (middle_last3.medical_school_sim > .8))\n",
    "middle_last3.loc[last_name_unique_mask, 'is_match'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 155)\n",
      "(866, 155)\n",
      "Empty DataFrame\n",
      "Columns: [raw_uuid_1, raw_uuid_3]\n",
      "Index: []\n",
      "(556, 157)\n",
      "Empty DataFrame\n",
      "Columns: [raw_uuid_2, raw_uuid_4]\n",
      "Index: []\n",
      "(556, 159)\n"
     ]
    }
   ],
   "source": [
    "middle_last4 = middle_last3.loc[~pd.isnull(middle_last3.index), :].sort_values([\n",
    "        'raw_uuid_2', 'raw_uuid_1', 'is_match']+sims_cols, ascending=False)\n",
    "print middle_last3.shape\n",
    "print middle_last4.shape\n",
    "middle_last5 = filter_one_match_per_group(middle_last4, 'raw_uuid_1', {'raw_uuid_2': 'raw_uuid_3'}, sims_cols)\n",
    "print middle_last5.shape\n",
    "middle_last6 = filter_one_match_per_group(middle_last5, 'raw_uuid_2', {'raw_uuid_1': 'raw_uuid_4'}, sims_cols)\n",
    "print middle_last6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_uuid_1</th>\n",
       "      <th>raw_uuid_2</th>\n",
       "      <th>raw_uuid_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [raw_uuid_1, raw_uuid_2, raw_uuid_3]\n",
       "Index: []"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_last6.loc[~pd.isnull(middle_last6.raw_uuid_4),['raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6808,)\n"
     ]
    }
   ],
   "source": [
    "matched_ids = np.concatenate([\n",
    "        rev6.raw_uuid_1.dropna().unique(), rev6.raw_uuid_2.dropna().unique(), rev6.raw_uuid_3.dropna().unique(), \n",
    "        middle_last6.raw_uuid_1.dropna().unique(), middle_last6.raw_uuid_2.dropna().unique(), middle_last6.raw_uuid_3.dropna().unique()], \n",
    "                        axis=0)\n",
    "print matched_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749, 73)\n"
     ]
    }
   ],
   "source": [
    "# people who don't match on first or last\n",
    "all_app7a = all_app7.drop('fuzzy_merge_col', axis=1)\n",
    "unmatched = get_nonmatched(all_app7a, matched_ids, 'raw_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'age', 'application_date', 'associate_program_entered', 'bob', 'ca', 'cc', 'citizenship', 'city', 'clean_college_trans', 'clean_first_initial', 'clean_first_name', 'clean_last_name', 'clean_middle_initial', 'clean_middle_name', 'clean_suffix', 'clinical', 'cord', 'date_of_birth', 'dbs', 'fifth', 'first_name', 'honor_societies_first', 'honor_societies_fourth', 'honor_societies_second', 'honor_societies_third', 'ic', 'internship_hospital', 'internship_year(s)', 'is_female', 'last_name', 'last_name_counts', 'medical_school', 'medschool_year_grad', 'middle_name', 'nci', 'nei', 'nhi', 'nhli', 'niaid', 'niamd', 'niamdd', 'nichd', 'nichhd', 'nidr', 'niehs', 'nigms', 'nimh', 'nindb', 'ninds', 'oir', 'original_medical_school', 'other', 'pharm_ra', 'pi', 'ra', 'rejected', 'rejection_date', 'research', 'residency_hospital', 'residency_type', 'residency_year(s)', 'reviewer', 'sa', 'sixth', 'state', 'teaching', 'undergrad_year_grad', 'undergraduate_school', 'withdrawal', 'year_accepted', 'zip_code']\n"
     ]
    }
   ],
   "source": [
    "matches = pd.concat([rev6, middle_last6], axis=0).drop(['raw_uuid_1_duplicate', 'raw_uuid_2_duplicate'], axis=1)\n",
    "matches1 = consolidate_merge_cols(matches, ['_1', '_2'], ['application_year', 'raw_uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# append people by reviewer 3 and people not matched but reviewed by reviewer 1 or 2\n",
    "full_matches = pd.concat([matches1, unmatched],\n",
    "                      axis=0, ignore_index=True).sort_values(\n",
    "                            ['clean_last_name', 'clean_middle_name', 'clean_first_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_matches1 = full_matches.drop([c for c in full_matches.columns if c.endswith('_sim') or '_counts' in c or c.endswith('_duplicate')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_sim</th>\n",
       "      <th>age</th>\n",
       "      <th>application_date</th>\n",
       "      <th>application_year</th>\n",
       "      <th>application_year_1</th>\n",
       "      <th>application_year_2</th>\n",
       "      <th>application_year_sim</th>\n",
       "      <th>associate_program_entered</th>\n",
       "      <th>bob</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>sa</th>\n",
       "      <th>sixth</th>\n",
       "      <th>state</th>\n",
       "      <th>teaching</th>\n",
       "      <th>undergrad_year_grad</th>\n",
       "      <th>undergraduate_school</th>\n",
       "      <th>withdrawal</th>\n",
       "      <th>year_accepted</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [address, address_sim, age, application_date, application_year, application_year_1, application_year_2, application_year_sim, associate_program_entered, bob, ca, cc, citizenship, city, clean_college_trans, clean_first_initial, clean_first_name, clean_first_name_sim, clean_last_name, clean_last_name_sim, clean_middle_initial, clean_middle_name, clean_middle_name_sim, clean_suffix, clinical, cord, date_of_birth, dbs, fifth, first_name, honor_societies_first, honor_societies_fourth, honor_societies_second, honor_societies_third, ic, internship_hospital, internship_year(s), is_female, is_match, last_name, last_name_counts, medical_school, medical_school_sim, medschool_year_grad, middle_name, nci, nei, nhi, nhli, niaid, niamd, niamdd, nichd, nichhd, nidr, niehs, nigms, nimh, nindb, ninds, oir, original_medical_school, other, pharm_ra, pi, ra, raw_uuid, raw_uuid_1, raw_uuid_2, raw_uuid_3, raw_uuid_4, rejected, rejection_date, research, residency_hospital, residency_type, residency_year(s), reviewer, sa, sixth, state, teaching, undergrad_year_grad, undergraduate_school, withdrawal, year_accepted, zip_code]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 87 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_matches[~pd.isnull(full_matches.raw_uuid_4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_year</th>\n",
       "      <th>application_year_1</th>\n",
       "      <th>application_year_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [application_year, application_year_1, application_year_2]\n",
       "Index: []"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate data from application year\n",
    "full_matches1.loc[pd.isnull(full_matches1.application_year), 'application_year'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.application_year), 'application_year_2'] \n",
    "full_matches1.loc[pd.isnull(full_matches1.application_year), 'application_year'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.application_year), 'application_year_1'] \n",
    "\n",
    "full_matches1.loc[pd.isnull(full_matches1.application_year_1), 'application_year_1'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.application_year_1), 'application_year_2'] \n",
    "\n",
    "full_matches1.loc[full_matches1.application_year_1==full_matches1.application_year_2, ]\n",
    "full_matches1.loc[~pd.isnull(full_matches1.application_year_2), ]\n",
    "\n",
    "dup_app_year_mask= full_matches1.application_year==full_matches1.application_year_2\n",
    "full_matches1.loc[dup_app_year_mask, 'application_year_2'] = np.nan\n",
    "\n",
    "dup_app_year_mask= full_matches1.application_year_1==full_matches1.application_year_2\n",
    "full_matches1.loc[dup_app_year_mask, 'application_year_2'] = np.nan\n",
    "\n",
    "dup_app_year_mask= full_matches1.application_year==full_matches1.application_year_1\n",
    "full_matches1.loc[dup_app_year_mask, 'application_year_1'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "full_matches1.loc[~pd.isnull(full_matches1.application_year_2), ['application_year', 'application_year_1', 'application_year_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_uuid</th>\n",
       "      <th>raw_uuid_1</th>\n",
       "      <th>raw_uuid_2</th>\n",
       "      <th>raw_uuid_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [raw_uuid, raw_uuid_1, raw_uuid_2, raw_uuid_3]\n",
       "Index: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove uuid dups\n",
    "\n",
    "full_matches1.loc[pd.isnull(full_matches1.raw_uuid), 'raw_uuid'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.raw_uuid), 'raw_uuid_2'] \n",
    "full_matches1.loc[pd.isnull(full_matches1.raw_uuid), 'raw_uuid'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.raw_uuid), 'raw_uuid_1'] \n",
    "\n",
    "full_matches1.loc[pd.isnull(full_matches1.raw_uuid_1), 'raw_uuid_1'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.raw_uuid_1), 'raw_uuid_2'] \n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid==full_matches1.raw_uuid_2\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_2'] = np.nan\n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid_1==full_matches1.raw_uuid_2\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_2'] = np.nan\n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid==full_matches1.raw_uuid_1\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_1'] = np.nan\n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid==full_matches1.raw_uuid_3\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_3'] = np.nan\n",
    "# full_matches1.loc[full_matches1.raw_uuid_1==full_matches1.raw_uuid_2, ['raw_uuid_1', 'raw_uuid_2']]\n",
    "full_matches1.loc[~pd.isnull(full_matches1.raw_uuid_3), ['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches2 = full_matches1.drop(['raw_uuid_2', 'raw_uuid_3', 'application_year_2', 'raw_uuid_4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del all_app3, all_appcards2, all_app4, all_app5, all_app6, all_app7a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_matches2['fuzzy_merge_col'] = full_matches2[\n",
    "    ['clean_middle_initial', 'clean_last_name', 'medical_school']].apply(create_str_merge, axis=1)\n",
    "\n",
    "last_name_counter = Counter(full_matches2.clean_last_name)\n",
    "full_matches2.loc[:, 'last_name_counts'] = full_matches2.apply(\n",
    "    lambda x: last_name_counter[x['clean_last_name']], axis=1)\n",
    "\n",
    "possible_dups = full_matches2[full_matches2['last_name_counts']>1].sort_values(\n",
    "    ['clean_last_name', 'clean_middle_name', 'medical_school', 'city', 'application_year'])\n",
    "\n",
    "people_match = df_get_closest_matches(possible_dups, possible_dups, 'fuzzy_merge_col', suffixes=['_x', '_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 154)\n"
     ]
    }
   ],
   "source": [
    "# for people with the same information, drop from the data set\n",
    "same_person_mask = (\n",
    "        (people_match.raw_uuid_x==people_match.raw_uuid_y) & (people_match.raw_uuid_1_x==people_match.raw_uuid_1_y))\n",
    "\n",
    "# need to add a second mask for people who have only 1 uuid\n",
    "same_person_mask2 = (\n",
    "        (people_match.raw_uuid_x==people_match.raw_uuid_y) & (pd.isnull(people_match.raw_uuid_1_x)) &\n",
    "            (pd.isnull(people_match.raw_uuid_1_y)))\n",
    "\n",
    "people_match2 = people_match[~(same_person_mask | same_person_mask2)]\n",
    "print people_match2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOW, need to redo the merging process, but merge in based on same people, not just same application year\n",
    "def check_similar(row):\n",
    "        # address and application year match\n",
    "    if row['application_year_sim'] > 3:\n",
    "        return 0\n",
    "    if row['medical_school_sim'] > 80 and row['clean_middle_name_sim'] > 60:\n",
    "        return 1\n",
    "    if row['medical_school_sim'] > 80 and row['clean_first_name_sim'] > 60:\n",
    "        return 1\n",
    "    if row['address_sim'] > 60 and row['medical_school_sim'] > 80 and (\n",
    "            pd.isnull(row['clean_first_name_sim']) or row['clean_first_name_sim'] > 80) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people_match3 = add_similarity_features(people_match2, feature_dict, check_similar, suffixes=['_x', '_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_match</th>\n",
       "      <th>clean_first_name_sim</th>\n",
       "      <th>clean_middle_initial_x</th>\n",
       "      <th>clean_first_name_x</th>\n",
       "      <th>medical_school_sim</th>\n",
       "      <th>clean_middle_name_x</th>\n",
       "      <th>clean_middle_name_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C ALEXANDER DUKE</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>C</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C ALEXANDER DUKE</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>C</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>C</td>\n",
       "      <td>CHARLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S ALPERT HARVARD</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>S</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>100.0</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>STEPHEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S ALPERT HARVARD</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>S</td>\n",
       "      <td>JOSEPH</td>\n",
       "      <td>100.0</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>STEPHEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  is_match  clean_first_name_sim clean_middle_initial_x  \\\n",
       "C ALEXANDER DUKE         1                 100.0                      C   \n",
       "C ALEXANDER DUKE         1                 100.0                      C   \n",
       "S ALPERT HARVARD         1                 100.0                      S   \n",
       "S ALPERT HARVARD         1                 100.0                      S   \n",
       "\n",
       "                 clean_first_name_x  medical_school_sim clean_middle_name_x  \\\n",
       "C ALEXANDER DUKE               JOHN               100.0             CHARLES   \n",
       "C ALEXANDER DUKE               JOHN               100.0                   C   \n",
       "S ALPERT HARVARD             JOSEPH               100.0             STEPHEN   \n",
       "S ALPERT HARVARD             JOSEPH               100.0             STEPHEN   \n",
       "\n",
       "                 clean_middle_name_y  \n",
       "C ALEXANDER DUKE                   C  \n",
       "C ALEXANDER DUKE             CHARLES  \n",
       "S ALPERT HARVARD             STEPHEN  \n",
       "S ALPERT HARVARD             STEPHEN  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_match3.loc[people_match3.clean_last_name_x.isin(['ALEXANDER', 'ALPERT']), \n",
    "                  ['is_match', 'clean_first_name_sim', \n",
    "                   'clean_middle_initial_x', 'clean_first_name_x', 'medical_school_sim', 'clean_middle_name_x', 'clean_middle_name_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 162)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_match4 = people_match3[people_match3['is_match']==1].reset_index().drop_duplicates(subset='index',keep='first')\n",
    "people_match4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'age', 'application_date', 'associate_program_entered', 'bob', 'ca', 'cc', 'citizenship', 'city', 'clean_college_trans', 'clean_first_initial', 'clean_first_name', 'clean_last_name', 'clean_middle_initial', 'clean_middle_name', 'clean_suffix', 'clinical', 'cord', 'date_of_birth', 'dbs', 'fifth', 'first_name', 'honor_societies_first', 'honor_societies_fourth', 'honor_societies_second', 'honor_societies_third', 'ic', 'internship_hospital', 'internship_year(s)', 'is_female', 'is_match', 'last_name', 'medical_school', 'medschool_year_grad', 'middle_name', 'nci', 'nei', 'nhi', 'nhli', 'niaid', 'niamd', 'niamdd', 'nichd', 'nichhd', 'nidr', 'niehs', 'nigms', 'nimh', 'nindb', 'ninds', 'oir', 'original_medical_school', 'other', 'pharm_ra', 'pi', 'ra', 'rejected', 'rejection_date', 'research', 'residency_hospital', 'residency_type', 'residency_year(s)', 'reviewer', 'sa', 'sixth', 'state', 'teaching', 'undergrad_year_grad', 'undergraduate_school', 'withdrawal', 'year_accepted', 'zip_code', 'last_name_counts']\n"
     ]
    }
   ],
   "source": [
    "people_match5 = consolidate_merge_cols(people_match4, ['_x', '_y'], ['application_year', 'application_year_1', 'raw_uuid', 'raw_uuid_1'])\n",
    "people_match6 = people_match5.drop([c for c in full_matches.columns if c.endswith('_sim') or '_counts' in c or c.endswith('_duplicate')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# consolidate uuid columns\n",
    "people_match6['raw_uuid'] = people_match6['raw_uuid_x']\n",
    "people_match6['raw_uuid_1'] = people_match6['raw_uuid_1_x']\n",
    "people_match6['raw_uuid_2'] = np.nan\n",
    "people_match6['raw_uuid_3'] = np.nan\n",
    "\n",
    "fill_in_y = (\n",
    "    (people_match6.raw_uuid_y!=people_match6.raw_uuid_x) & (people_match6.raw_uuid_y!=people_match6.raw_uuid_1))\n",
    "\n",
    "people_match6.loc[fill_in_y, 'raw_uuid_2'] = people_match6.loc[fill_in_y, 'raw_uuid_y']\n",
    "\n",
    "fill_in_y_1 = (\n",
    "    (people_match6.raw_uuid_1_y!=people_match6.raw_uuid) & (people_match6.raw_uuid_1_y!=people_match6.raw_uuid_1) &\n",
    "        (people_match6.raw_uuid_1_y!=people_match6.raw_uuid_2))\n",
    "\n",
    "people_match6.loc[fill_in_y_1, 'raw_uuid_3'] = people_match6.loc[fill_in_y_1, 'raw_uuid_1_y']\n",
    "\n",
    "people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_1'] = people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_3']\n",
    "people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_1'] = people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_2']\n",
    "\n",
    "people_match6.loc[people_match6.raw_uuid_1==people_match6.raw_uuid_3, 'raw_uuid_3'] = np.nan\n",
    "\n",
    "# drop all uuidds except for i, 2, 2\n",
    "UUID_COLS = ['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3']\n",
    "\n",
    "people_match7 = people_match6.drop(['raw_uuid_x', 'raw_uuid_y', 'raw_uuid_1_x', 'raw_uuid_1_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# consolidate_app_year columns\n",
    "# consolidate uuid columns\n",
    "people_match7['application_year'] = people_match7['application_year_x']\n",
    "people_match7['application_year_1'] = people_match7['application_year_1_x']\n",
    "people_match7['application_year_2'] = np.nan\n",
    "people_match7['application_year_3'] = np.nan\n",
    "\n",
    "fill_in_y = (\n",
    "    (people_match7.application_year_y!=people_match7.application_year_x) & (people_match7.application_year_y!=people_match7.application_year_1))\n",
    "\n",
    "people_match7.loc[fill_in_y, 'application_year_2'] = people_match7.loc[fill_in_y, 'application_year_y']\n",
    "\n",
    "fill_in_y_1 = (\n",
    "    (people_match7.application_year_1_y!=people_match7.application_year) & (people_match7.application_year_1_y!=people_match7.application_year_1) &\n",
    "        (people_match7.application_year_1_y!=people_match7.application_year_2))\n",
    "\n",
    "people_match7.loc[fill_in_y_1, 'application_year_3'] = people_match7.loc[fill_in_y_1, 'application_year_1_y']\n",
    "\n",
    "people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_1'] = people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_3']\n",
    "people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_1'] = people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_2']\n",
    "\n",
    "people_match7.loc[people_match7.application_year_1==people_match7.application_year_3, 'application_year_3'] = np.nan\n",
    "people_match7.loc[people_match7.application_year_2==people_match7.application_year_3, 'application_year_3'] = np.nan\n",
    "people_match7.loc[people_match7.application_year_1==people_match7.application_year_2, 'application_year_2'] = np.nan\n",
    "\n",
    "# drop all uuidds except for i, 2, 2\n",
    "APPLICATION_YEAR_COLS = ['application_year', 'application_year_1']\n",
    "\n",
    "people_match8 = people_match7.drop(['application_year_2', 'application_year_3', 'application_year_x', 'application_year_y', 'application_year_1_x', 'application_year_1_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_year_x</th>\n",
       "      <th>application_year_1_x</th>\n",
       "      <th>application_year_y</th>\n",
       "      <th>application_year_1_y</th>\n",
       "      <th>clean_last_name_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALEXANDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPERT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     application_year_x  application_year_1_x  application_year_y  \\\n",
       "54               1971.0                   NaN              1971.0   \n",
       "216              1969.0                   NaN              1968.0   \n",
       "\n",
       "     application_year_1_y clean_last_name_x  \n",
       "54                    NaN         ALEXANDER  \n",
       "216                   NaN            ALPERT  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_match4.loc[people_match6.clean_last_name.isin(['ALEXANDER', 'ALPERT']), [\n",
    "        'application_year_x', 'application_year_1_x', 'application_year_y', 'application_year_1_y', 'clean_last_name_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>is_match</th>\n",
       "      <th>address</th>\n",
       "      <th>age</th>\n",
       "      <th>application_date</th>\n",
       "      <th>associate_program_entered</th>\n",
       "      <th>bob</th>\n",
       "      <th>ca</th>\n",
       "      <th>cc</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>...</th>\n",
       "      <th>undergraduate_school</th>\n",
       "      <th>withdrawal</th>\n",
       "      <th>year_accepted</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>raw_uuid</th>\n",
       "      <th>raw_uuid_1</th>\n",
       "      <th>raw_uuid_2</th>\n",
       "      <th>raw_uuid_3</th>\n",
       "      <th>application_year</th>\n",
       "      <th>application_year_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>C ALEXANDER DUKE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1416 Beal Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971-03-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3802.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>S ALPERT HARVARD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92 Curtis Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6295.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1968.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  is_match           address  age application_date  \\\n",
       "54   C ALEXANDER DUKE       1.0  1416 Beal Street  NaN       1971-03-11   \n",
       "216  S ALPERT HARVARD       1.0  92 Curtis Street  NaN       1969-01-01   \n",
       "\n",
       "    associate_program_entered  bob   ca   cc citizenship         ...          \\\n",
       "54                        NaN  0.0  1.0  0.0         NaN         ...           \n",
       "216                       NaN  0.0  1.0  1.0         NaN         ...           \n",
       "\n",
       "    undergraduate_school withdrawal year_accepted zip_code raw_uuid  \\\n",
       "54       Duke University        0.0        1973.0      NaN     96.0   \n",
       "216      Yale University       -9.0           NaN   2144.0     62.0   \n",
       "\n",
       "    raw_uuid_1 raw_uuid_2 raw_uuid_3  application_year  application_year_1  \n",
       "54      3802.0       95.0     3800.0            1971.0                 NaN  \n",
       "216     6295.0       63.0     3758.0            1969.0              1968.0  \n",
       "\n",
       "[2 rows x 79 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_match8.loc[people_match8.clean_last_name.isin(['ALEXANDER', 'ALPERT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add back to main data set\n",
    "multi_apps_ids = np.concatenate([\n",
    "        people_match8.raw_uuid.dropna().unique(), people_match8.raw_uuid_1.dropna().unique(), \n",
    "        people_match8.raw_uuid_2.dropna().unique(), people_match8.raw_uuid_3.dropna().unique()], \n",
    "                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3888, 78)\n"
     ]
    }
   ],
   "source": [
    "one_app = get_nonmatched(full_matches2, multi_apps_ids, 'raw_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4019, 81)\n"
     ]
    }
   ],
   "source": [
    "full_apps = pd.concat([one_app, people_match8], axis=0).sort_values(NAME_COLS+UUID_COLS)\n",
    "print full_apps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups1 = full_apps[full_apps.duplicated(['clean_last_name', 'clean_first_initial', 'clean_middle_initial', 'medical_school'], keep='first')].sort_values('clean_last_name')\n",
    "dups2 = full_apps[full_apps.duplicated(['clean_last_name', 'clean_first_initial', 'clean_middle_initial', 'medical_school'], keep='last')].sort_values('clean_last_name')\n",
    "dups2 = dups2[['clean_last_name', 'clean_first_name', 'clean_first_initial', 'medical_school', 'raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'application_year', 'application_year_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups3 = dups2.rename(columns={'raw_uuid': 'raw_uuid_4', 'raw_uuid_1': 'raw_uuid_5', 'raw_uuid_2': 'raw_uuid_6',\n",
    "                             'raw_uuid_3': 'raw_uuid_7', 'application_year': 'application_year_2', \n",
    "                              'application_year_1': 'application_year_3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups4 = pd.merge(left=dups1, right=dups3, on=['clean_last_name', 'clean_first_initial', 'medical_school'], how='inner')\n",
    "dups4.loc[:, ['raw_uuid', 'raw_uuid_4', 'raw_uuid_1', 'raw_uuid_5', 'raw_uuid_2', 'raw_uuid_6',\n",
    "                             'raw_uuid_3', 'raw_uuid_7', 'application_year', 'application_year_2', \n",
    "                              'application_year_1', 'application_year_3']]\n",
    "dups4.loc[pd.isnull(dups4.application_year_1), 'application_year_1'] =  dups4.loc[\n",
    "    pd.isnull(dups4.application_year_1), 'application_year_3'] \n",
    "dups4.loc[pd.isnull(dups4.application_year_1), 'application_year_1'] =  dups4.loc[\n",
    "    pd.isnull(dups4.application_year_1), 'application_year_2']\n",
    "dup_years = dups4.application_year_1==dups4.application_year_2\n",
    "dups4.loc[dup_years, 'application_year_2'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups5 = dups4.join(dups4[['raw_uuid', 'raw_uuid_4', 'raw_uuid_1', 'raw_uuid_5', 'raw_uuid_2', 'raw_uuid_6',\n",
    "                             'raw_uuid_3', 'raw_uuid_7']].apply(get_unique_vals, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups6 = dups5.rename(columns=dict(zip(range(6), ['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'raw_uuid_4',\n",
    "                             'raw_uuid_5'])))\n",
    "sorted(dups6.columns)\n",
    "dups6 = dups5[['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'raw_uuid_4',\n",
    "                'raw_uuid_5', 'clean_last_name', 'clean_first_initial', 'medical_school', \n",
    "                   'application_year', 'application_year_2', \n",
    "                              'application_year_1',  'application_year_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_dups = full_apps[\n",
    "    ~full_apps.duplicated(\n",
    "        ['clean_last_name', 'clean_first_initial', 'clean_middle_initial', 'medical_school'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps1 = pd.concat([not_dups, dups6], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "full_apps1.index.name = PERSON_ID\n",
    "print PERSON_ID in full_apps1.columns\n",
    "full_apps2 = full_apps1.reset_index(drop=False)\n",
    "# .rename(columns={'index': PERSON_ID})\n",
    "# sorted(full_apps2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>person_uuid</th>\n",
       "      <th>medical_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ALAN</td>\n",
       "      <td>JAY</td>\n",
       "      <td>AXELROD</td>\n",
       "      <td>37</td>\n",
       "      <td>ILLINOIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AXELROD</td>\n",
       "      <td>709</td>\n",
       "      <td>HARVARD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clean_first_name clean_middle_name clean_last_name  person_uuid  \\\n",
       "37              ALAN               JAY         AXELROD           37   \n",
       "709            DAVID               NaN         AXELROD          709   \n",
       "\n",
       "    medical_school  \n",
       "37        ILLINOIS  \n",
       "709        HARVARD  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_name='AXELROD'\n",
    "full_apps2.loc[full_apps2.clean_last_name==last_name, NAME_COLS+[PERSON_ID, 'medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>medical_school</th>\n",
       "      <th>to_fix_clean_first_name</th>\n",
       "      <th>to_fix_clean_middle_name</th>\n",
       "      <th>to_fix_clean_last_name</th>\n",
       "      <th>to_fix_medical_school</th>\n",
       "      <th>to_fix_medschool_year_grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [clean_first_name, clean_middle_name, clean_last_name, medical_school, to_fix_clean_first_name, to_fix_clean_middle_name, to_fix_clean_last_name, to_fix_medical_school, to_fix_medschool_year_grad]\n",
       "Index: []"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_fixes.loc[manual_fixes.clean_last_name==last_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>medical_school</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>BER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARON</td>\n",
       "      <td>NYU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            clean_first_name clean_middle_name clean_last_name medical_school\n",
       "person_uuid                                                                  \n",
       "293                      BER               NaN            ARON            NYU"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_apps1.loc[full_apps1.clean_last_name=='ARON', NAME_COLS+['medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to csv\n",
    "full_apps2.to_csv(os.path.join(APP_DATA_DIR, 'index_cards_deduped_fuzzy.csv'), index=False)\n",
    "full_apps2.to_pickle(os.path.join(PICKLE_DIR, 'index_cards_deduped_fuzzy.p'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# also write out original raw index card (pre merge data set)\n",
    "all_app7.to_csv(os.path.join(APP_DATA_DIR, 'index_cards_raw.csv'), idnex=False)\n",
    "all_app7.to_pickle(os.path.join(PICKLE_DIR, 'index_cards_raw.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "      <th>person_uuid</th>\n",
       "      <th>medical_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>F</td>\n",
       "      <td>ALTMAN</td>\n",
       "      <td>599</td>\n",
       "      <td>PITTSBURGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>LEONARD</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>ALTMAN</td>\n",
       "      <td>2109</td>\n",
       "      <td>HARVARD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clean_first_name clean_middle_name clean_last_name  person_uuid  \\\n",
       "599             DAVID                 F          ALTMAN          599   \n",
       "2109          LEONARD           CHARLES          ALTMAN         2109   \n",
       "\n",
       "     medical_school  \n",
       "599      PITTSBURGH  \n",
       "2109        HARVARD  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_name='ALTMAN'\n",
    "\n",
    "full_apps2.loc[full_apps2.clean_last_name==last_name, NAME_COLS+[PERSON_ID, 'medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do some sanity checks on the data\n",
    "all_last_names = set(all_app7.clean_last_name.values)\n",
    "merged_last_names = set(full_apps.clean_last_name.values)\n",
    "diff_names = all_last_names - merged_last_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['MACLOWRY', 'STABENAU', 'HARRIN', 'GARFIN', 'PENDERGAST', 'DEFRONZO', 'ROBINS', 'COLBERG', 'CHESEBRO', 'MOND', 'COLLIN', 'GLASSROTH', 'COSTANTIN', 'FRIEDLANDER', 'SCHUTZ', 'DAVISON', 'SARAL', 'KEISER', 'FINKLESTEIN', 'EILER', 'EISCH', 'DIEZMAN', 'KINNEY', 'KETOVER', 'FREY', 'HEIBY', 'BEAK', 'HERSH', 'LURIA', 'BRADEN', 'KEBIAN', 'CUONO', 'STEVENS', 'ARNSON', 'GREELEY', 'HUNT', 'LIST', 'DROBIS', 'STAMPER', 'BULKEY', 'BENETT'])\n"
     ]
    }
   ],
   "source": [
    "print diff_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3'] ['application_year', 'application_year_1']\n"
     ]
    }
   ],
   "source": [
    "print UUID_COLS, APPLICATION_YEAR_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_ppl = all_app7.loc[all_app7.clean_last_name.isin(diff_names), NAME_COLS+['raw_uuid', 'application_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_ids = all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_first_name</th>\n",
       "      <th>clean_middle_name</th>\n",
       "      <th>clean_last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ALAN</td>\n",
       "      <td>N</td>\n",
       "      <td>ANDERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>ARTHUR</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>FRIENDLANDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>BART</td>\n",
       "      <td>PETER</td>\n",
       "      <td>KENTOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>BRUCE</td>\n",
       "      <td>WILCOX</td>\n",
       "      <td>CHESEBRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>CHARLES</td>\n",
       "      <td>BOSETTI</td>\n",
       "      <td>CUOMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>CLAUDE</td>\n",
       "      <td>CLAUDE</td>\n",
       "      <td>BENNETT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>DALE</td>\n",
       "      <td>E</td>\n",
       "      <td>DIETZMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>ALEC</td>\n",
       "      <td>STEVENSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>BEAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>DONALD</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>GREENLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>DONALD</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>ELLER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>ELVIN</td>\n",
       "      <td>LURA</td>\n",
       "      <td>KUNNEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>EVAN</td>\n",
       "      <td>M</td>\n",
       "      <td>HERSHFIELD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>GREGORY</td>\n",
       "      <td>BARTLETT</td>\n",
       "      <td>BULKLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>KEIMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>HOWARD</td>\n",
       "      <td>JAY</td>\n",
       "      <td>EISEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>D</td>\n",
       "      <td>MAC LOWRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>E</td>\n",
       "      <td>COLDBERG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>JACOB</td>\n",
       "      <td>MONO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>R</td>\n",
       "      <td>STABERMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>RICHARD</td>\n",
       "      <td>HELBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FINKELSTEIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>JEFFERY</td>\n",
       "      <td>P</td>\n",
       "      <td>FVEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>JEFFREY</td>\n",
       "      <td>DONALD</td>\n",
       "      <td>DROBIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>JEFFREY</td>\n",
       "      <td>LEONARD</td>\n",
       "      <td>GLASSROBTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>WILLIS</td>\n",
       "      <td>KEBABIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAVIDSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>LE ROY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONSTANTIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>LEONARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCHULTZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>MARTIN</td>\n",
       "      <td>JAY</td>\n",
       "      <td>LVRIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>MORRIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAMPFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>NOEL</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>LISTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>RALPH</td>\n",
       "      <td>A</td>\n",
       "      <td>DEFRENZO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>REIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>CHAPLIN</td>\n",
       "      <td>COLLINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>D</td>\n",
       "      <td>HUNTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>SANDER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROBINSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>STEVEN</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>GARFINKEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>THOMAS</td>\n",
       "      <td>SHILOR</td>\n",
       "      <td>HARBIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>PENDERGRAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRADEN R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clean_first_name clean_middle_name clean_last_name\n",
       "86               ALAN                 N        ANDERSON\n",
       "1167           ARTHUR           MICHAEL    FRIENDLANDER\n",
       "1947             BART             PETER        KENTOVER\n",
       "605             BRUCE            WILCOX        CHESEBRE\n",
       "766           CHARLES           BOSETTI           CUOMO\n",
       "246            CLAUDE            CLAUDE         BENNETT\n",
       "850              DALE                 E        DIETZMAN\n",
       "3656            DAVID              ALEC       STEVENSON\n",
       "217             DAVID           MICHAEL            BEAR\n",
       "1431           DONALD             ALLEN        GREENLEY\n",
       "949            DONALD            MARTIN           ELLER\n",
       "2099            ELVIN              LURA          KUNNEY\n",
       "1634             EVAN                 M      HERSHFIELD\n",
       "491           GREGORY          BARTLETT         BULKLEY\n",
       "1929            HARRY            ROBERT          KEIMER\n",
       "936            HOWARD               JAY           EISEN\n",
       "2346            JAMES                 D       MAC LOWRY\n",
       "680             JAMES                 E        COLDBERG\n",
       "2609            JAMES             JACOB            MONO\n",
       "3619            JAMES                 R       STABERMAN\n",
       "1601            JAMES           RICHARD           HELBY\n",
       "1067            JAMES               NaN     FINKELSTEIN\n",
       "1184          JEFFERY                 P            FVEY\n",
       "889           JEFFREY            DONALD          DROBIN\n",
       "1291          JEFFREY           LEONARD      GLASSROBTH\n",
       "1926             JOHN            WILLIS        KEBABIAN\n",
       "789              JOHN               NaN        DAVIDSON\n",
       "705            LE ROY               NaN      CONSTANTIN\n",
       "3361          LEONARD               NaN         SCHULTZ\n",
       "2340           MARTIN               JAY           LVRIA\n",
       "3624           MORRIS               NaN        STAMPFER\n",
       "2275             NOEL             DAVID          LISTER\n",
       "816             RALPH                 A        DEFRENZO\n",
       "3296             REIN               NaN           SARAI\n",
       "689            ROBERT           CHAPLIN         COLLINS\n",
       "1756           ROBERT                 D          HUNTER\n",
       "3119           SANDER               NaN        ROBINSON\n",
       "1211           STEVEN            ROBERT       GARFINKEL\n",
       "1544           THOMAS            SHILOR          HARBIN\n",
       "2859          WILLIAM         JEFFERSON     PENDERGRAST\n",
       "401           WILLIAM               NaN        BRADEN R"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_apps.loc[full_apps.raw_uuid.isin(missing_ppl.raw_uuid) | full_apps.raw_uuid_1.isin(missing_ppl.raw_uuid), NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
