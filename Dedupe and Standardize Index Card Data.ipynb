{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "from fuzzywuzzy import fuzz\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import string\n",
    "import funcy\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from data_cleaning_functions import (trans_remov_punc, standardize_whitespace, remove_punc, remove_suffix_from_last_name,\n",
    "                                     clean_names, has_award, has_suffix, get_suffix, replace_last_name, \n",
    "                                     is_year_range, str_sim, clean_med_school, clean_std_college_name)\n",
    "\n",
    "from dev import (\n",
    "    APP_DATA_DIR, SUM_STAT_DIR, CARD_DATA_DIR, CORRECTIONS_DIR, AWARDS_KEYWORDS, NAME_COLS, RAW_NAME_COLS, \n",
    "    RAW_CARD_ID, RAW_INDEX_IDS, PERSON_APPLICATION_ID, PERSON_ID, NIH_ID, FEMALE_FIRST_NAMES,\n",
    "    PICKLE_DIR)\n",
    "\n",
    "from merging_functions import *\n",
    "\n",
    "OUTPUT_CSV = False \n",
    "RAW_APPLICANT_DATA_FILENAME = 'raw_applicant_card_data.csv'\n",
    "MISSING_APPDATE_FILENAME = 'index_cards_no_application_date.csv'\n",
    "APP_SPELLING_CORRECTIONS = 'index_card_manual_corrections.xlsx'\n",
    "\n",
    "\n",
    "PERSONAL_INFO = [\n",
    "    'clean_first_name', 'clean_last_name', 'clean_middle_name',\n",
    "    'date_of_birth', 'medical_school', 'clean_college_trans']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_appcards2 = pd.read_csv(os.path.join(CARD_DATA_DIR, RAW_APPLICANT_DATA_FILENAME))\n",
    "\n",
    "# drop all rows with first, last name NA\n",
    "all_app3 = all_appcards2.dropna(subset=['application_date'], how='all')\n",
    "\n",
    "\n",
    "def id_poorlyfmtdates(str_date):\n",
    "    try:\n",
    "        dt = pd.to_datetime(str_date, format='%m/%d/%Y')\n",
    "        return True\n",
    "    except (ValueError, AssertionError):\n",
    "        return False\n",
    "\n",
    "mask = all_app3.application_date.apply(id_poorlyfmtdates)\n",
    "# all_app3.loc[~mask, :]\n",
    "\n",
    "# change '3/31971 to 3/3/1971\n",
    "# change 41/8/1966 to 4/8/1966 \n",
    "all_app3.loc[all_app3.application_date=='3/31971', 'application_date'] = '3/3/1971'\n",
    "all_app3.loc[all_app3.application_date=='41/8/1966', 'application_date'] = '4/8/1966'\n",
    "\n",
    "# convert application date to date object\n",
    "all_app3.loc[:, 'application_date'] = all_app3['application_date'].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "# do the same date check for birth date columns\n",
    "bdate_mask = all_app3.date_of_birth.apply(id_poorlyfmtdates)\n",
    "all_app3.loc[~bdate_mask, ['first_name', 'last_name', 'date_of_birth']]\n",
    "all_app3.loc[(\n",
    "        all_app3.last_name=='Cook') & \n",
    "                  (all_app3.middle_name=='James') & \n",
    "                  (all_app3.first_name.isnull()), 'date_of_birth'] = '1/27/1940'\n",
    "\n",
    "all_app3[NAME_COLS] = all_app3[RAW_NAME_COLS].applymap(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_app3.loc[all_app3.last_name=='Hoffman', NAME_COLS+['first_name', 'last_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_app3.loc[(all_app3.clean_last_name=='RUBENSTEIN') & (all_app3.clean_middle_name=='ALLAN'), 'application_date'] = pd.to_datetime('1/21/1973')\n",
    "\n",
    "all_app3.loc[(\n",
    "        all_app3.clean_last_name=='ROOT') & \n",
    "                  (all_app3.clean_first_name=='RICHARD'), 'application_date'] = pd.to_datetime('5/23/1963')\n",
    "\n",
    "all_app3.loc[(\n",
    "        all_app3.clean_last_name=='FREIDMAN') & (all_app3.clean_first_name=='STANFORD'), 'application_date'] = pd.to_datetime('01/01/1960')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_app3.rename(columns={'medical_school':'original_medical_school'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# deal with suffixes and honors\n",
    "suffix_mask = all_app3.clean_last_name.apply(has_suffix)\n",
    "# all_app_short.loc[suffix_mask, ['clean_last_name', 'clean_first_name', 'clean_middle_name']]\n",
    "\n",
    "# for those last names that seem to have a suffix, pull into seperate column and keep everything last word of last name\n",
    "all_app3.loc[suffix_mask, 'clean_suffix'] = all_app3.loc[suffix_mask, 'clean_last_name'].apply(get_suffix)\n",
    "all_app3.loc[suffix_mask, 'clean_last_name'] = all_app3.loc[suffix_mask, 'clean_last_name'].apply(remove_suffix_from_last_name)\n",
    "\n",
    "# some first names also contain some honors such as 'Pfizer Award' or 'Honor Society'\n",
    "# these should be pulled into the honors and awards columns\n",
    "has_award_fnc = funcy.rpartial(has_award, AWARDS_KEYWORDS)\n",
    "\n",
    "\n",
    "# get a list of all the med school honors columns\n",
    "honors_columns = [c for c in all_app3.columns if 'honor' in c]\n",
    "print honors_columns\n",
    "\n",
    "has_award_mask = all_app3['clean_first_name'].apply(has_award_fnc)\n",
    "\n",
    "all_app3.loc[has_award_mask, 'extra_honor'] = all_app3.loc[has_award_mask, 'clean_first_name']\n",
    "\n",
    "# create column mask for each row where one of the honors columns is blank\n",
    "for hc in honors_columns:\n",
    "    hc_mask = (has_award_mask) & (pd.isnull(all_app3[hc]))\n",
    "    all_app3.loc[hc_mask, hc] = all_app3.loc[hc_mask, 'extra_honor']\n",
    "# check for any columns that already have full honors and cant be filled\n",
    "all_app3.loc[hc_mask, honors_columns].dropna(how='any')\n",
    "\n",
    "# drop extra honor columns\n",
    "all_app4 = all_app3.drop('extra_honor', axis=1)\n",
    "\n",
    "# replace those honors first names with np.nan\n",
    "all_app4.loc[has_award_mask, 'clean_first_name'] = np.nan\n",
    "\n",
    "# for those columns where med school is equal to last name or med_school is a year range, delete\n",
    "med_school_str_sim = funcy.rpartial(str_sim, 'medical_school', 'clean_last_name')\n",
    "all_app4.loc[:, 'school_name_sim'] = all_app4.loc[:, ['clean_last_name', 'medical_school']].apply(med_school_str_sim, axis=1)\n",
    "\n",
    "all_app4.loc[all_app4.school_name_sim > .6, :]\n",
    "\n",
    "all_app4.loc[:, 'clean_college'] = all_app4.undergraduate_school.apply(clean_names)\n",
    "\n",
    "to_remove_college = [\n",
    "    ' AND ', ' AT ', 'THE ', ' COLLGE', 'UNIVERISTY', 'UNIVERWSITY', 'MASSACHUSSETTS', 'JOHN ', 'DE PAUW', 'ASBURY', \n",
    "'DREXEL INSTITUTE OF TECHNOLOGY', 'A B BROWN UNIVERSITY', 'DARTMOUTH MEDICAL SCHOOL', 'RENSSELAER UNIVERSITY', \n",
    "'RENSSELAER POLYTECHNICAL INSTITUTE', ' STE', 'COLLEGE OF HOLY CROSS', 'HOLLY CROSS', 'JOHNSS ',  'BERKLEY',\n",
    "'UC ', 'PITTSBURRGH', 'WESLYN', 'WILLAMS', 'GEORGIA TECH', 'NEW YORK UNIVERSITY UNIV', \n",
    "'UNIVERSITY OF MICHIGAN IS A', 'OHIO', 'STATE UNIVERSITY OF NEW YORK AT BUFFALO']\n",
    "to_replace_college = [\n",
    "    ' ', ' ', ' ', ' COLLEGE', 'UNIVERSITY', 'UNIVERSITY', 'MASSACHUSETTS', 'JOHNS ', 'DEPAUW', 'ASHBURY',\n",
    "    'DREXEL UNIVERSITY', 'BROWN UNIVERSITY', 'DARTMOUTH', 'RENSSELAER POLYTECHNIC INSTITUTE', \n",
    "    'RENSSELAER POLYTECHNIC INSTITUTE', ' STATE', 'HOLY CROSS', 'HOLY CROSS', 'JOHNS ', \n",
    "    ' BERKELEY', 'UNIVERSITY OF CALIFORNIA ', 'PITTSBURGH', 'WESLEYAN', 'WILLIAMS', \n",
    "    'GEORGIA INSTITUTE OF TECHNOLOGY', 'NEW YORK', 'UNIVERSITY OF MICHIGAN', 'OHIO STATE', 'SUNY BUFFALO']\n",
    "\n",
    "clean_college_fnc = funcy.rpartial(clean_std_college_name, to_remove_college, to_replace_college)\n",
    "\n",
    "# make college mispelling and different reference translation table\n",
    "all_app4.loc[:, 'clean_college_trans'] = all_app4.clean_college.apply(clean_college_fnc)\n",
    "\n",
    "all_app4.drop(['clean_college', 'school_name_sim'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_app4.loc[:, 'medical_school'] = all_app4.original_medical_school.apply(clean_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set 'other' values to null\n",
    "all_app4.loc[all_app4.medical_school=='OTHER', 'medical_school'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# need to convert undergrad_year_grad and med_school_grad to numbers to maintain consistency\n",
    "all_app4.loc[:, ['undergrad_year_grad', 'medschool_year_grad']] = all_app4.loc[:, ['undergrad_year_grad', 'medschool_year_grad']].apply(\n",
    "    lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "# now, sort by names, med school, undergrad school, \n",
    "all_app5 = all_app4.sort_values(by=PERSONAL_INFO)\n",
    "\n",
    "# LAST_NAME_MISSPELLINGS = {\n",
    "#         'HOMCY': 'HOMEY', 'DROBIS': 'DROBIN', 'DEFRONZO':'DEFRENZO', \n",
    "#         'BRADEN 3R': 'BRADEN', 'BORKER': 'BORER', 'CASTLES': 'CASTLE',\n",
    "#         'CUONO': 'CUOMO', 'CYRULNIK': 'CYRULINK', 'EISENBATH': 'EISENBARTH', \n",
    "#         'ELLIOTT': 'ELIOT', 'FINKLESTEIN': 'FINKELSTEIN', 'HEINRICK': 'HEINRICH', \n",
    "#         'HERLIKY': 'HERLIHY', 'HIMMELHOCK': 'HIMMELHOCH', 'JANOWSKY': 'JANKOWSKY', \n",
    "#         'KLINENBERG': 'KLINEBERG', 'KORNFELD': 'KORNFIELD', 'NEIDORF': 'NEIDOFT',\n",
    "#         'OLEINICK': 'OLENICK', 'ROSKES': 'ROSKE'\n",
    "# }\n",
    "# removed CUONO, DROBIS, \n",
    "\n",
    "\n",
    "LAST_NAME_MISSPELLINGS = {\n",
    "        'HOMCY': 'HOMEY', \n",
    "        'BRADEN 3R': 'BRADEN', 'BORKER': 'BORER', 'CASTLES': 'CASTLE',\n",
    "        'CYRULNIK': 'CYRULINK', 'EISENBATH': 'EISENBARTH', \n",
    "        'HEINRICK': 'HEINRICH', \n",
    "        'HERLIKY': 'HERLIHY', 'HIMMELHOCK': 'HIMMELHOCH', 'JANOWSKY': 'JANKOWSKY', \n",
    "        'KLINENBERG': 'KLINEBERG', 'KORNFELD': 'KORNFIELD', 'NEIDORF': 'NEIDOFT',\n",
    "        'OLEINICK': 'OLENICK', 'ROSKES': 'ROSKE'\n",
    "}\n",
    "\n",
    "replace_last_name_fnc = funcy.rpartial(replace_last_name, LAST_NAME_MISSPELLINGS)\n",
    "\n",
    "# correct last name mispellings\n",
    "all_app5.loc[:, 'clean_last_name'] = all_app5.loc[:, 'clean_last_name'].apply(replace_last_name_fnc)\n",
    "all_app5.loc[all_app5.clean_last_name=='MORTON', 'clean_first_name'] = 'JOHN'\n",
    "\n",
    "# convert ca column to float62\n",
    "all_app5.loc[:, 'ca'] = all_app5.loc[:, 'ca'].apply(lambda x: pd.to_numeric(x, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "female_mask = (\n",
    "    (all_app5['clean_first_name'].isin(FEMALE_FIRST_NAMES)))\n",
    "#     | (\n",
    "#         all_app5['clean_middle_name'].isin(FEMALE_MIDDLE_NAMES)))\n",
    "all_app5['is_female'] = 0\n",
    "all_app5.loc[female_mask & ~pd.isnull(all_app5['clean_first_name']), 'is_female'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_first_letter(str_var):\n",
    "    if pd.isnull(str_var) or str_var=='':\n",
    "        return np.nan\n",
    "    return str_var[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_names = ['RIPLEY', 'HAYWOOD', 'HAYWARD', 'PERPICH', 'BRADEN', 'BRADEN R', 'BULKEY', 'CHESEBRE', 'DIEZMAN']\n",
    "\n",
    "all_app5.loc[all_app5.clean_last_name.isin(last_names), NAME_COLS +['medical_school', 'medschool_grad_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge in manual corrections excel sheet\n",
    "manual_fixes = pd.read_excel(os.path.join(CORRECTIONS_DIR, 'index_card_manual_corrections.xlsx')).rename(\n",
    "    columns={\n",
    "        'clean_medical_school': 'medical_school', \n",
    "        'to_fix_clean_medical_school': 'to_fix_medical_school'}).drop('Unnamed: 9', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = filter(lambda x: '_year' not in x, manual_fixes.columns)\n",
    "manual_fixes.loc[:, c] = manual_fixes[c].applymap(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manual_fixes.loc[manual_fixes.medical_school=='CHICAGO', 'medical_school'] = 'UNIVERSITY OF CHICAGO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "manual_fixes.loc[manual_fixes.clean_first_name==' ', 'clean_first_name'] = np.nan\n",
    "manual_fixes.loc[manual_fixes.clean_middle_name==' ', 'clean_middle_name'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_names = pd.merge(\n",
    "    left=all_app5, right=manual_fixes, on=[\n",
    "        'clean_first_name', 'clean_middle_name', 'clean_last_name'], how='inner', suffixes=['_1', '_2'])\n",
    "missing_names['med_sim'] = missing_names[['medical_school_1', 'medical_school_2']].apply(\n",
    "    lambda x: get_name_str_sim(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_names1 = missing_names.sort_values(\n",
    "    'med_sim', ascending=False).drop_duplicates(NAME_COLS).drop(['medical_school_2', 'med_sim'], axis=1)\n",
    "missing_names1 = missing_names1.rename(columns={'medical_school_1': 'medical_school'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manual_fixes.loc[manual_fixes.clean_last_name=='HOFFMAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for the people who match, consolidate the columns\n",
    "\n",
    "# missing_names = pd.merge(\n",
    "#     left=all_app5, right=manual_fixes, on=['clean_first_name', 'clean_middle_name', 'clean_last_name', 'medical_school'], how='inner')\n",
    "\n",
    "print manual_fixes.shape\n",
    "print missing_names1.shape\n",
    "\n",
    "missing_names1A = missing_names1.rename(columns={\n",
    "            'clean_first_name': 'old_first',\n",
    "            'clean_middle_name': 'old_middle',\n",
    "            'clean_last_name': 'old_last'}) \n",
    "missing_names1B = missing_names1A.rename(columns={\n",
    "            'to_fix_clean_first_name': 'clean_first_name', \n",
    "            'to_fix_clean_middle_name': 'clean_middle_name', \n",
    "            'to_fix_clean_last_name': 'clean_last_name'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_names1B.loc[missing_names1B.clean_last_name.isin(['ELLER', 'EILER']), NAME_COLS]\n",
    "# missing_names.loc[missing_names.clean_last_name.isin(['ELLER', 'EILER']), NAME_COLS+['to_fix_clean_last_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop extra columns\n",
    "missing_names2 = missing_names1B.drop(\n",
    "    (c for c in missing_names1B.columns if c not in all_app5.columns), axis=1).drop_duplicates([RAW_CARD_ID])\n",
    "\n",
    "all_app6  = pd.concat(\n",
    "    [all_app5.loc[~all_app5[RAW_CARD_ID].isin(missing_names2[RAW_CARD_ID]), :], missing_names2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_app5.loc[(\n",
    "#         all_app5.clean_last_name.isin(mf.clean_last_name)) & (\n",
    "#         all_app5.clean_middle_name.isin(mf.clean_middle_name)), NAME_COLS+['medical_school']].to_csv('test.csv')\n",
    "all_app5.loc[(\n",
    "        all_app5.clean_last_name == 'HAYWARD'), NAME_COLS+['medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mf = manual_fixes.loc[~manual_fixes.to_fix_clean_last_name.isin(missing_names2.clean_last_name), NAME_COLS+['medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_name = 'ELLER'\n",
    "\n",
    "# f_name = 'ADAM'\n",
    "# m_name = 'NORMAN'\n",
    "# all_app5.loc[(\n",
    "#         all_app5.clean_first_name==f_name) & (all_app5.clean_middle_name==m_name), NAME_COLS+['medical_school', 'residency_hospital', 'internship_hospital_1']]\n",
    "all_app5.loc[all_app5.clean_last_name==last_name, NAME_COLS+['medical_school', 'residency_hospital', 'internship_hospital_1']]\n",
    "all_app6.loc[all_app6.clean_last_name==last_name, NAME_COLS+['medical_school', 'residency_hospital', 'internship_hospital_1']]\n",
    "# missing_names.loc[missing_names.clean_last_name==last_name, NAME_COLS+['medical_school']]\n",
    "# manual_fixes.loc[manual_fixes.clean_first_name=='LAWRENCE',  NAME_COLS+['medical_school']]\n",
    "# manual_fixes.loc[manual_fixes.clean_last_name==last_name,  NAME_COLS+['medical_school']]\n",
    "# all_app6.loc[all_app6.clean_last_name==last_name,  NAME_COLS+['medical_school', 'medschool_year_grad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_app6['clean_first_initial'] = all_app6.clean_first_name.apply(get_first_letter)\n",
    "all_app6['clean_middle_initial'] = all_app6.clean_middle_name.apply(get_first_letter)\n",
    "all_app6['application_year'] = all_app6.application_date.apply(lambda x: pd.to_datetime(x).year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_app6.loc[(all_app6['application_year'] > 1990) | (all_app6['application_year'] < 1950), 'application_year'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop people with female names and two columns\n",
    "is_female_mask = (all_app6.clean_first_name.isin(FEMALE_FIRST_NAMES))\n",
    "all_app6['is_female'] = 0\n",
    "all_app6.loc[is_female_mask, 'is_female'] = 1\n",
    "# RENAME INTERNSHIP HOSPITAL COL\n",
    "all_app7 = all_app6.drop(['Unnamed: 0',\"daniel's_comments\"], axis=1).rename(\n",
    "    columns={'internship_hospital_1': 'internship_hospital'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split into reviewer 1 and 2, and try to match\n",
    "all_app7['fuzzy_merge_col'] = all_app7[\n",
    "    ['clean_first_name', 'clean_middle_name', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "rev2 = df_get_closest_matches(all_app7[all_app7.reviewer==2], all_app7[all_app7.reviewer==1], 'fuzzy_merge_col') \n",
    "\n",
    "\n",
    "feature_dict = {\n",
    "    'clean_first_name': get_name_str_sim,\n",
    "    'clean_middle_name': get_name_str_sim,\n",
    "    'clean_last_name': get_name_str_sim,\n",
    "    'medical_school': get_name_str_sim,\n",
    "    'application_year': get_dt_sim,\n",
    "    'address': get_name_str_sim\n",
    "}\n",
    "\n",
    "rev3 = add_similarity_features(rev2, feature_dict, check_match)\n",
    "\n",
    "rev1_counter = Counter(all_app7[all_app7.reviewer==1].clean_last_name.values)\n",
    "rev2_counter = Counter(all_app7[all_app7.reviewer==2].clean_last_name.values)\n",
    "rev3['last_name_counts_1'] = rev3.clean_last_name_1.apply(lambda x: rev1_counter[x])\n",
    "rev3['last_name_counts_2'] = rev3.clean_last_name_2.apply(lambda x: rev2_counter[x])\n",
    "\n",
    "# now, sort by is_match, similarity scores and only keep 1 uuid from each data set\n",
    "last_name_unique_mask = (\n",
    "    (rev3.last_name_counts_1==1) & (rev3.last_name_counts_2==1) & (\n",
    "        rev3.application_year_sim<4) & (rev3.medical_school_sim > .8))\n",
    "rev3.loc[last_name_unique_mask, 'is_match'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rev3.is_match.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sims_cols = ['medical_school_sim', 'address_sim', 'clean_middle_name_sim', 'clean_first_name_sim']\n",
    "\n",
    "rev4 = rev3.loc[~pd.isnull(rev3.index), :].sort_values([\n",
    "        'raw_uuid_2', 'raw_uuid_1', 'is_match']+sims_cols, ascending=False)\n",
    "print rev3.shape\n",
    "print rev4.shape\n",
    "rev5 = filter_one_match_per_group(rev4, 'raw_uuid_1', {'raw_uuid_2': 'raw_uuid_3'}, sims_cols)\n",
    "print rev5.shape\n",
    "rev6 = filter_one_match_per_group(rev5, 'raw_uuid_2', {'raw_uuid_1': 'raw_uuid_4'}, sims_cols)\n",
    "print rev6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# del rev6['raw_uuid_4']\n",
    "rev6.loc[rev6.clean_last_name_1=='LEVINE', 'clean_first_name_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matched_ids = np.concatenate([\n",
    "        rev6.raw_uuid_1.dropna().unique(), rev6.raw_uuid_2.dropna().unique(), rev6.raw_uuid_3.dropna().unique()], \n",
    "                        axis=0)\n",
    "print matched_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try to merge on middle initial and clean last name\n",
    "\n",
    "unmatched_r1 = get_nonmatched(all_app7[all_app7.reviewer==1], matched_ids, 'raw_uuid')\n",
    "unmatched_r2 = get_nonmatched(all_app7[all_app7.reviewer==2], matched_ids, 'raw_uuid')\n",
    "\n",
    "unmatched_r1['fuzzy_merge_col'] = unmatched_r1[\n",
    "    ['clean_middle_initial', 'clean_last_name']].apply(create_str_merge, axis=1)\n",
    "unmatched_r2['fuzzy_merge_col'] = unmatched_r2[\n",
    "    ['clean_middle_initial', 'clean_last_name']].apply(create_str_merge, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rev2_counter = Counter(unmatched_r2.clean_last_name.values)\n",
    "rev1_counter = Counter(unmatched_r1.clean_last_name.values)\n",
    "\n",
    "match_round2 = df_get_closest_matches(unmatched_r2, unmatched_r1, 'fuzzy_merge_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "middle_last3 = add_similarity_features(match_round2, feature_dict, check_match)\n",
    "\n",
    "middle_last3['last_name_counts_1'] = middle_last3.clean_last_name_1.apply(lambda x: rev1_counter[x])\n",
    "middle_last3['last_name_counts_2'] = middle_last3.clean_last_name_2.apply(lambda x: rev2_counter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now, sort by is_match, similarity scores and only keep 1 uuid from each data set\n",
    "last_name_unique_mask = (\n",
    "    (middle_last3.last_name_counts_1==1) & (middle_last3.last_name_counts_2==1) & (\n",
    "        middle_last3.application_year_sim<2) & (middle_last3.medical_school_sim > .8))\n",
    "middle_last3.loc[last_name_unique_mask, 'is_match'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "middle_last4 = middle_last3.loc[~pd.isnull(middle_last3.index), :].sort_values([\n",
    "        'raw_uuid_2', 'raw_uuid_1', 'is_match']+sims_cols, ascending=False)\n",
    "print middle_last3.shape\n",
    "print middle_last4.shape\n",
    "middle_last5 = filter_one_match_per_group(middle_last4, 'raw_uuid_1', {'raw_uuid_2': 'raw_uuid_3'}, sims_cols)\n",
    "print middle_last5.shape\n",
    "middle_last6 = filter_one_match_per_group(middle_last5, 'raw_uuid_2', {'raw_uuid_1': 'raw_uuid_4'}, sims_cols)\n",
    "print middle_last6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "middle_last6.loc[~pd.isnull(middle_last6.raw_uuid_4),['raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "middle_last6.loc[middle_last6.clean_last_name_1=='LEVINE', sims_cols +[\n",
    " 'clean_first_name_1', 'clean_middle_name_1','clean_middle_name_2', 'clean_first_name_2']]\n",
    "# matches.loc[matches.clean_last_name=='LEVINE', 'clean_first_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matched_ids = np.concatenate([\n",
    "        rev6.raw_uuid_1.dropna().unique(), rev6.raw_uuid_2.dropna().unique(), rev6.raw_uuid_3.dropna().unique(), \n",
    "        middle_last6.raw_uuid_1.dropna().unique(), middle_last6.raw_uuid_2.dropna().unique(), middle_last6.raw_uuid_3.dropna().unique()], \n",
    "                        axis=0)\n",
    "print matched_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# people who don't match on first or last\n",
    "all_app7a = all_app7.drop('fuzzy_merge_col', axis=1)\n",
    "unmatched = get_nonmatched(all_app7a, matched_ids, 'raw_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matches = pd.concat([rev6, middle_last6], axis=0).drop(['raw_uuid_1_duplicate', 'raw_uuid_2_duplicate'], axis=1)\n",
    "matches1 = consolidate_merge_cols(matches, ['_1', '_2'], ['application_year', 'raw_uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# append people by reviewer 3 and people not matched but reviewed by reviewer 1 or 2\n",
    "full_matches = pd.concat([matches1, unmatched],\n",
    "                      axis=0, ignore_index=True).sort_values(\n",
    "                            ['clean_last_name', 'clean_middle_name', 'clean_first_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_matches1 = full_matches.drop([c for c in full_matches.columns if c.endswith('_sim') or '_counts' in c or c.endswith('_duplicate')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_matches[~pd.isnull(full_matches.raw_uuid_4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove duplicate data from application year\n",
    "full_matches1.loc[pd.isnull(full_matches1.application_year), 'application_year'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.application_year), 'application_year_2'] \n",
    "full_matches1.loc[pd.isnull(full_matches1.application_year), 'application_year'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.application_year), 'application_year_1'] \n",
    "\n",
    "full_matches1.loc[pd.isnull(full_matches1.application_year_1), 'application_year_1'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.application_year_1), 'application_year_2'] \n",
    "\n",
    "full_matches1.loc[full_matches1.application_year_1==full_matches1.application_year_2, ]\n",
    "full_matches1.loc[~pd.isnull(full_matches1.application_year_2), ]\n",
    "\n",
    "dup_app_year_mask= full_matches1.application_year==full_matches1.application_year_2\n",
    "full_matches1.loc[dup_app_year_mask, 'application_year_2'] = np.nan\n",
    "\n",
    "dup_app_year_mask= full_matches1.application_year_1==full_matches1.application_year_2\n",
    "full_matches1.loc[dup_app_year_mask, 'application_year_2'] = np.nan\n",
    "\n",
    "dup_app_year_mask= full_matches1.application_year==full_matches1.application_year_1\n",
    "full_matches1.loc[dup_app_year_mask, 'application_year_1'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "full_matches1.loc[~pd.isnull(full_matches1.application_year_2), ['application_year', 'application_year_1', 'application_year_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove uuid dups\n",
    "\n",
    "full_matches1.loc[pd.isnull(full_matches1.raw_uuid), 'raw_uuid'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.raw_uuid), 'raw_uuid_2'] \n",
    "full_matches1.loc[pd.isnull(full_matches1.raw_uuid), 'raw_uuid'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.raw_uuid), 'raw_uuid_1'] \n",
    "\n",
    "full_matches1.loc[pd.isnull(full_matches1.raw_uuid_1), 'raw_uuid_1'] = full_matches1.loc[\n",
    "    pd.isnull(full_matches1.raw_uuid_1), 'raw_uuid_2'] \n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid==full_matches1.raw_uuid_2\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_2'] = np.nan\n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid_1==full_matches1.raw_uuid_2\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_2'] = np.nan\n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid==full_matches1.raw_uuid_1\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_1'] = np.nan\n",
    "\n",
    "dup_uuid_mask= full_matches1.raw_uuid==full_matches1.raw_uuid_3\n",
    "full_matches1.loc[dup_uuid_mask, 'raw_uuid_3'] = np.nan\n",
    "# full_matches1.loc[full_matches1.raw_uuid_1==full_matches1.raw_uuid_2, ['raw_uuid_1', 'raw_uuid_2']]\n",
    "full_matches1.loc[~pd.isnull(full_matches1.raw_uuid_3), ['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_matches2 = full_matches1.drop(['raw_uuid_2', 'raw_uuid_3', 'application_year_2', 'raw_uuid_4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problem_names = ['PRZYBYLA', 'EILER', 'ELLER', 'BUCKLEY', 'BUKLEY', 'PERPICH', 'DIEZMAN', 'DIETZMAN', 'BRADEN R', \n",
    "                'GLASSBROTH', 'CHESEBRE', 'CHESEBRO', 'COLLIN', 'COLLINS', 'KETOVER', 'KENTOVER', 'BRADEN R', \n",
    "                'KNOWLER', 'SARAI', 'SARAL', 'COLDBERG', 'GOLDBERG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_matches2.loc[full_matches2.clean_last_name.isin(problem_names), NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# del all_app3, all_appcards2, all_app4, all_app5, all_app6, all_app7a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_matches2['fuzzy_merge_col'] = full_matches2[\n",
    "    ['clean_middle_initial', 'clean_last_name', 'medical_school']].apply(create_str_merge, axis=1)\n",
    "\n",
    "last_name_counter = Counter(full_matches2.clean_last_name)\n",
    "full_matches2.loc[:, 'last_name_counts'] = full_matches2.apply(\n",
    "    lambda x: last_name_counter[x['clean_last_name']], axis=1)\n",
    "\n",
    "possible_dups = full_matches2[full_matches2['last_name_counts']>1].sort_values(\n",
    "    ['clean_last_name', 'clean_middle_name', 'medical_school', 'city', 'application_year'])\n",
    "\n",
    "people_match = df_get_closest_matches(possible_dups, possible_dups, 'fuzzy_merge_col', suffixes=['_x', '_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for people with the same information, drop from the data set\n",
    "same_person_mask = (\n",
    "        (people_match.raw_uuid_x==people_match.raw_uuid_y) & (people_match.raw_uuid_1_x==people_match.raw_uuid_1_y))\n",
    "\n",
    "# need to add a second mask for people who have only 1 uuid\n",
    "same_person_mask2 = (\n",
    "        (people_match.raw_uuid_x==people_match.raw_uuid_y) & (pd.isnull(people_match.raw_uuid_1_x)) &\n",
    "            (pd.isnull(people_match.raw_uuid_1_y)))\n",
    "\n",
    "people_match2 = people_match[~(same_person_mask | same_person_mask2)]\n",
    "print people_match2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NOW, need to redo the merging process, but merge in based on same people, not just same application year\n",
    "def check_similar(row):\n",
    "        # address and application year match\n",
    "    if row['application_year_sim'] > 3:\n",
    "        return 0\n",
    "    if row['medical_school_sim'] > 80 and row['clean_middle_name_sim'] > 60:\n",
    "        return 1\n",
    "    if row['medical_school_sim'] > 80 and row['clean_first_name_sim'] > 60:\n",
    "        return 1\n",
    "    if row['address_sim'] > 60 and row['medical_school_sim'] > 80 and (\n",
    "            pd.isnull(row['clean_first_name_sim']) or row['clean_first_name_sim'] > 80) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "people_match3 = add_similarity_features(people_match2, feature_dict, check_similar, suffixes=['_x', '_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "people_match3.loc[people_match3.clean_last_name_x.isin(['ALEXANDER', 'ALPERT']), \n",
    "                  ['is_match', 'clean_first_name_sim', \n",
    "                   'clean_middle_initial_x', 'clean_first_name_x','clean_first_name_y', 'medical_school_sim', 'clean_middle_name_x', 'clean_middle_name_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "people_match4 = people_match3[people_match3['is_match']==1].reset_index().drop_duplicates(subset='index',keep='first')\n",
    "people_match4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "people_match5 = consolidate_merge_cols(people_match4, ['_x', '_y'], ['application_year', 'application_year_1', 'raw_uuid', 'raw_uuid_1'])\n",
    "people_match6 = people_match5.drop([c for c in full_matches.columns if c.endswith('_sim') or '_counts' in c or c.endswith('_duplicate')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# consolidate uuid columns\n",
    "people_match6['raw_uuid'] = people_match6['raw_uuid_x']\n",
    "people_match6['raw_uuid_1'] = people_match6['raw_uuid_1_x']\n",
    "people_match6['raw_uuid_2'] = np.nan\n",
    "people_match6['raw_uuid_3'] = np.nan\n",
    "\n",
    "fill_in_y = (\n",
    "    (people_match6.raw_uuid_y!=people_match6.raw_uuid_x) & (people_match6.raw_uuid_y!=people_match6.raw_uuid_1))\n",
    "\n",
    "people_match6.loc[fill_in_y, 'raw_uuid_2'] = people_match6.loc[fill_in_y, 'raw_uuid_y']\n",
    "\n",
    "fill_in_y_1 = (\n",
    "    (people_match6.raw_uuid_1_y!=people_match6.raw_uuid) & (people_match6.raw_uuid_1_y!=people_match6.raw_uuid_1) &\n",
    "        (people_match6.raw_uuid_1_y!=people_match6.raw_uuid_2))\n",
    "\n",
    "people_match6.loc[fill_in_y_1, 'raw_uuid_3'] = people_match6.loc[fill_in_y_1, 'raw_uuid_1_y']\n",
    "\n",
    "people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_1'] = people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_3']\n",
    "people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_1'] = people_match6.loc[pd.isnull(people_match6.raw_uuid_1), 'raw_uuid_2']\n",
    "\n",
    "people_match6.loc[people_match6.raw_uuid_1==people_match6.raw_uuid_3, 'raw_uuid_3'] = np.nan\n",
    "\n",
    "# drop all uuidds except for i, 2, 2\n",
    "UUID_COLS = ['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3']\n",
    "\n",
    "people_match7 = people_match6.drop(['raw_uuid_x', 'raw_uuid_y', 'raw_uuid_1_x', 'raw_uuid_1_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# consolidate_app_year columns\n",
    "# consolidate uuid columns\n",
    "people_match7['application_year'] = people_match7['application_year_x']\n",
    "people_match7['application_year_1'] = people_match7['application_year_1_x']\n",
    "people_match7['application_year_2'] = np.nan\n",
    "people_match7['application_year_3'] = np.nan\n",
    "\n",
    "fill_in_y = (\n",
    "    (people_match7.application_year_y!=people_match7.application_year_x) & (people_match7.application_year_y!=people_match7.application_year_1))\n",
    "\n",
    "people_match7.loc[fill_in_y, 'application_year_2'] = people_match7.loc[fill_in_y, 'application_year_y']\n",
    "\n",
    "fill_in_y_1 = (\n",
    "    (people_match7.application_year_1_y!=people_match7.application_year) & (people_match7.application_year_1_y!=people_match7.application_year_1) &\n",
    "        (people_match7.application_year_1_y!=people_match7.application_year_2))\n",
    "\n",
    "people_match7.loc[fill_in_y_1, 'application_year_3'] = people_match7.loc[fill_in_y_1, 'application_year_1_y']\n",
    "\n",
    "people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_1'] = people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_3']\n",
    "people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_1'] = people_match7.loc[pd.isnull(people_match7.application_year_1), 'application_year_2']\n",
    "\n",
    "people_match7.loc[people_match7.application_year_1==people_match7.application_year_3, 'application_year_3'] = np.nan\n",
    "people_match7.loc[people_match7.application_year_2==people_match7.application_year_3, 'application_year_3'] = np.nan\n",
    "people_match7.loc[people_match7.application_year_1==people_match7.application_year_2, 'application_year_2'] = np.nan\n",
    "\n",
    "# drop all uuidds except for i, 2, 2\n",
    "APPLICATION_YEAR_COLS = ['application_year', 'application_year_1']\n",
    "\n",
    "people_match8 = people_match7.drop(['application_year_2', 'application_year_3', 'application_year_x', 'application_year_y', 'application_year_1_x', 'application_year_1_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "people_match4.loc[people_match6.clean_last_name.isin(['ALEXANDER', 'ALPERT']), [\n",
    "        'application_year_x', 'application_year_1_x', 'application_year_y', 'application_year_1_y', 'clean_last_name_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "people_match8.loc[people_match8.clean_last_name.isin(['HERSH', 'ALPERT']), NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add back to main data set\n",
    "multi_apps_ids = np.concatenate([\n",
    "        people_match8.raw_uuid.dropna().unique(), people_match8.raw_uuid_1.dropna().unique(), \n",
    "        people_match8.raw_uuid_2.dropna().unique(), people_match8.raw_uuid_3.dropna().unique()], \n",
    "                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "one_app = get_nonmatched(full_matches2, multi_apps_ids, 'raw_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_apps = pd.concat([one_app, people_match8], axis=0).sort_values(NAME_COLS+UUID_COLS)\n",
    "print full_apps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dups1 = full_apps[full_apps.duplicated(['clean_last_name', 'clean_first_initial', 'clean_middle_initial', 'medical_school'], keep='first')].sort_values('clean_last_name')\n",
    "dups2 = full_apps[full_apps.duplicated(['clean_last_name', 'clean_first_initial', 'clean_middle_initial', 'medical_school'], keep='last')].sort_values('clean_last_name')\n",
    "dups2 = dups2[['clean_last_name', 'clean_first_name', 'clean_first_initial', 'medical_school', 'raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'application_year', 'application_year_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dups3 = dups2.rename(columns={'raw_uuid': 'raw_uuid_4', 'raw_uuid_1': 'raw_uuid_5', 'raw_uuid_2': 'raw_uuid_6',\n",
    "                             'raw_uuid_3': 'raw_uuid_7', 'application_year': 'application_year_2', \n",
    "                              'application_year_1': 'application_year_3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dups4 = pd.merge(left=dups1, right=dups3, on=['clean_last_name', 'clean_first_initial', 'medical_school'], how='inner')\n",
    "dups4.loc[:, ['raw_uuid', 'raw_uuid_4', 'raw_uuid_1', 'raw_uuid_5', 'raw_uuid_2', 'raw_uuid_6',\n",
    "                             'raw_uuid_3', 'raw_uuid_7', 'application_year', 'application_year_2', \n",
    "                              'application_year_1', 'application_year_3']]\n",
    "dups4.loc[pd.isnull(dups4.application_year_1), 'application_year_1'] =  dups4.loc[\n",
    "    pd.isnull(dups4.application_year_1), 'application_year_3'] \n",
    "dups4.loc[pd.isnull(dups4.application_year_1), 'application_year_1'] =  dups4.loc[\n",
    "    pd.isnull(dups4.application_year_1), 'application_year_2']\n",
    "dup_years = dups4.application_year_1==dups4.application_year_2\n",
    "dups4.loc[dup_years, 'application_year_2'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dups5 = dups4.join(dups4[['raw_uuid', 'raw_uuid_4', 'raw_uuid_1', 'raw_uuid_5', 'raw_uuid_2', 'raw_uuid_6',\n",
    "                             'raw_uuid_3', 'raw_uuid_7']].apply(get_unique_vals, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dups6 = dups5.rename(columns=dict(zip(range(6), ['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'raw_uuid_4',\n",
    "                             'raw_uuid_5'])))\n",
    "sorted(dups6.columns)\n",
    "dups6 = dups5[['raw_uuid', 'raw_uuid_1', 'raw_uuid_2', 'raw_uuid_3', 'raw_uuid_4',\n",
    "                'raw_uuid_5', 'clean_last_name', 'clean_first_initial', 'medical_school', \n",
    "                   'application_year', 'application_year_2', \n",
    "                              'application_year_1',  'application_year_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "not_dups = full_apps[\n",
    "    ~full_apps.duplicated(\n",
    "        ['clean_last_name', 'clean_first_initial', 'clean_middle_initial', 'medical_school'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_apps1 = pd.concat([not_dups, dups6], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print full_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_last_names = set(all_app7.clean_last_name.values)\n",
    "merged_last_names = set(full_apps.clean_last_name.values)\n",
    "diff_names = all_last_names - merged_last_names\n",
    "print diff_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(full_apps1.columns) - set(all_app7a.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to add back in people who were dropped after renaming columns to match full_apps1\n",
    "missing_ppl = all_app7a.loc[(\n",
    "        all_app7a.clean_last_name.isin(diff_names)) & (~pd.isnull(all_app7a.clean_first_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps1A = pd.concat([\n",
    "        full_apps1, missing_ppl], axis=0).reset_index(drop=True).drop(['index', 'is_match', 'last_name_counts', \n",
    "                                                           'fuzzy_merge_col'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps1A['medical_school'] = full_apps1A.medical_school.apply(clean_med_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_apps1A.index.name = PERSON_ID\n",
    "print PERSON_ID in full_apps1A.columns\n",
    "full_apps2 = full_apps1A.reset_index(drop=False).sort_values(NAME_COLS+['medical_school']).drop_duplicates(NAME_COLS)\n",
    "# .rename(columns={'index': PERSON_ID})\n",
    "# sorted(full_apps2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps2.loc[full_apps2.medical_school=='VIRGINIA', ['medical_school', 'original_medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_drops = full_apps2.loc[(pd.isnull(full_apps2.clean_first_name)&pd.isnull(full_apps2.clean_middle_name))].clean_last_name.values \n",
    "\n",
    "# full_apps2.loc[full_apps2.duplicated(NAME_COLS, keep=False), NAME_COLS+['medical_school']].clean_last_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_drop = ['BURNBAUM', 'DEPPERMAN', 'DEPPERMANN', 'LIST', 'STEWART', 'STEVENS', 'PERPICH', 'BUCKLEY', 'COLLIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lname= 'LIST'\n",
    "not_dups.loc[not_dups.clean_last_name==lname, NAME_COLS+['medical_school']]\n",
    "one_app.loc[one_app.clean_last_name==lname, NAME_COLS+['medical_school']]\n",
    "full_matches2.loc[full_matches2.clean_last_name==lname, NAME_COLS+['medical_school']]\n",
    "full_apps1.loc[full_apps1.clean_last_name==lname, NAME_COLS+['medical_school']]\n",
    "full_apps2.loc[full_apps2.clean_last_name.isin(to_drop), NAME_COLS+['medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "full_apps2['to_drop'] = 0\n",
    "full_apps2.loc[:, 'to_drop'] = full_apps2[['clean_first_name', 'clean_last_name']].apply(lambda x: pd.isnull(x[0])\n",
    "                                                                                           and x[1] in(to_drop), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = Counter(full_apps2.clean_last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps2.loc[full_apps2.clean_last_name=='DEPPERMAN', 'to_drop'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps2['counts'] = full_apps2.clean_last_name.apply(lambda x: c[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible_drops = full_apps2.loc[\n",
    "    (pd.isnull(full_apps2.clean_first_name)&pd.isnull(full_apps2.clean_middle_name) & (full_apps2.counts > 1)), 'person_uuid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps2.loc[full_apps2.person_uuid.isin(possible_drops), 'to_drop'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps2.loc[full_apps2.clean_last_name=='BURNBAUM', NAME_COLS+['application_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps2.loc[full_apps2.to_drop==1,  NAME_COLS+['application_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_apps3 = full_apps2.loc[full_apps2.to_drop==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write to csv\n",
    "full_apps3.to_csv(os.path.join(APP_DATA_DIR, 'index_cards_deduped_fuzzy.csv'), index=False)\n",
    "full_apps3.to_pickle(os.path.join(PICKLE_DIR, 'index_cards_deduped_fuzzy.p'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# also write out original raw index card (pre merge data set)\n",
    "all_app7.to_csv(os.path.join(APP_DATA_DIR, 'index_cards_raw.csv'), index=False)\n",
    "all_app7.to_pickle(os.path.join(PICKLE_DIR, 'index_cards_raw.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_name='HERSH'\n",
    "\n",
    "full_apps2.loc[full_apps2.clean_last_name==last_name, NAME_COLS+[PERSON_ID, 'medical_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do some sanity checks on the data\n",
    "all_last_names = set(all_app7.clean_last_name.values)\n",
    "merged_last_names = set(full_apps2.clean_last_name.values)\n",
    "diff_names = all_last_names - merged_last_names\n",
    "print diff_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print UUID_COLS, APPLICATION_YEAR_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_ppl = all_app7.loc[all_app7.clean_last_name.isin(diff_names), NAME_COLS+['raw_uuid', 'application_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_apps.loc[full_apps.raw_uuid.isin(missing_ppl.raw_uuid) | full_apps.raw_uuid_1.isin(missing_ppl.raw_uuid), NAME_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_app7.loc[all_app7.clean_last_name=='CHISARI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
